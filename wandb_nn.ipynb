{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wandb_nn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YojXM8bA_d9F",
        "9VCnvgHf-utG",
        "hfF-hTD8WiR1",
        "iDuC0_MIXnGF",
        "gaP_EKGzhrEh",
        "bI0v7p0sQwD7"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10dimensions/wandb_nn/blob/master/wandb_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2LFlDEd-5bO",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQgWFhGLytBb",
        "colab_type": "code",
        "outputId": "e38b5d52-a48f-4a72-c1ff-0762cba32b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "! git clone https://github.com/lukas/ml-class"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ml-class'...\n",
            "remote: Enumerating objects: 103, done.\u001b[K\n",
            "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 8971 (delta 36), reused 72 (delta 21), pack-reused 8868\u001b[K\n",
            "Receiving objects: 100% (8971/8971), 136.37 MiB | 26.61 MiB/s, done.\n",
            "Resolving deltas: 100% (2131/2131), done.\n",
            "Checking out files: 100% (5553/5553), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekrIxdK1zXoI",
        "colab_type": "code",
        "outputId": "034f8ec2-46cf-45f9-9568-bbaa300da388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%cd /content/ml-class\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ml-class\n",
            "examples  LICENSE  projects  README.md\trequirements.txt  videos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2biPLvmJ0CEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTuKxecT0wyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wandb\n",
        "\n",
        "!wandb login 39011b0b79a9067f7ffdab0b8223dc33e75b8801"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzmwYS6H3K6y",
        "colab_type": "code",
        "outputId": "8f782cc2-1cd1-4fb6-bff3-7d96de0e9363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd videos/intro"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ml-class/videos/intro\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "885EfLomRNlq",
        "colab_type": "code",
        "outputId": "4a4f95f4-2142-4fa0-cd8a-6d0ae2358ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mlp.py\t\t      perceptron-logistic.py\t  perceptron-single.py\n",
            "mnist.png\t      perceptron-normalize.py\n",
            "perceptron-linear.py  perceptron-single-fixed.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAK-7Z3cRu12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt install emacs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YojXM8bA_d9F",
        "colab_type": "text"
      },
      "source": [
        "# Single-Layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dteoI4gn_iFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VCnvgHf-utG",
        "colab_type": "text"
      },
      "source": [
        "# Multi-Layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPVOni0DsvIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat perceptron-linear.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZXTEB9quz0z",
        "colab_type": "code",
        "outputId": "c2833229-b8a5-47f3-d0ab-6015d32dc25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "# logging code\n",
        "run = wandb.init()\n",
        "config = run.config\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.astype(\"float\")\n",
        "X_train /= 255.\n",
        "\n",
        "X_test = X_test.astype(\"float\")\n",
        "X_test /= 255.\n",
        "\n",
        "img_width = X_train.shape[1]\n",
        "img_height = X_train.shape[2]\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "labels = range(10)\n",
        "\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "# create model\n",
        "model=Sequential()\n",
        "model.add(Flatten(input_shape=(img_width,img_height)))\n",
        "\n",
        "#additional layer\n",
        "#model.add(Dense(config.hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))       #activation = \"softmax\", improve accuracy\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',    # loss func = mse, categorical cross-entropy\n",
        "                metrics=['accuracy'])                               # optimizer = config.optimizer\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test),\n",
        "                    callbacks=[WandbCallback(labels=labels, data_type=\"image\")])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/10dimensions/ml-class-videos_intro\" target=\"_blank\">https://app.wandb.ai/10dimensions/ml-class-videos_intro</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/10dimensions/ml-class-videos_intro/runs/qvjc6myb\" target=\"_blank\">https://app.wandb.ai/10dimensions/ml-class-videos_intro/runs/qvjc6myb</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.4688 - acc: 0.8765 - val_loss: 0.3067 - val_acc: 0.9160\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.3039 - acc: 0.9154 - val_loss: 0.2902 - val_acc: 0.9194\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.2833 - acc: 0.9204 - val_loss: 0.2736 - val_acc: 0.9237\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.2733 - acc: 0.9244 - val_loss: 0.2681 - val_acc: 0.9251\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.2662 - acc: 0.9261 - val_loss: 0.2678 - val_acc: 0.9260\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.2615 - acc: 0.9272 - val_loss: 0.2653 - val_acc: 0.9270\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.2578 - acc: 0.9282 - val_loss: 0.2678 - val_acc: 0.9268\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.2549 - acc: 0.9292 - val_loss: 0.2622 - val_acc: 0.9281\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.2525 - acc: 0.9299 - val_loss: 0.2616 - val_acc: 0.9281\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.2503 - acc: 0.9304 - val_loss: 0.2646 - val_acc: 0.9267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f72636ea908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4567f2bf-234e-4c35-8a4d-3ecc426ec64f",
        "id": "aq8mt_-0-i_R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfF-hTD8WiR1",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahlR4W_xXIG3",
        "colab_type": "code",
        "outputId": "bc3f86d2-03ec-4fab-a7b8-bd6dd5748493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%cd videos/cnn/\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ml-class/videos/cnn\n",
            "cnn.py\tconv-demo.py  fashion.py  puppy.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-VLairGX7oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat cnn.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKpuntHiZ7uG",
        "colab_type": "code",
        "outputId": "42c93faa-d9aa-428f-9905-87046eff8154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
        "from keras.utils import np_utils\n",
        "from wandb.keras import WandbCallback\n",
        "import wandb\n",
        "\n",
        "run = wandb.init(project=\"ml_class_cnn\")\n",
        "config = run.config\n",
        "config.img_width = 28\n",
        "config.img_height = 28\n",
        "config.first_layer_conv_width = 3\n",
        "config.first_layer_conv_height = 3\n",
        "config.dense_layer_size = 100\n",
        "config.epochs = 10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_train /= 255.\n",
        "X_test = X_test.astype('float32')\n",
        "X_test /= 255.\n",
        "\n",
        "#reshape input data\n",
        "X_train = X_train.reshape(X_train.shape[0], config.img_width, config.img_height, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], config.img_width, config.img_height, 1)\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "labels=range(10)\n",
        "\n",
        "# build model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,\n",
        "    (config.first_layer_conv_width, config.first_layer_conv_height),\n",
        "    input_shape=(28, 28,1),\n",
        "    activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(config.dense_layer_size, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "        epochs=config.epochs,\n",
        "        callbacks=[WandbCallback(data_type=\"image\")])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://app.wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a>.<br/>\n",
              "                    Couldn't load entity due to error: Can't connect to network to query entity from API key\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               540900    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 542,230\n",
            "Trainable params: 542,230\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 21s 352us/step - loss: 0.2526 - acc: 0.9236 - val_loss: 0.0763 - val_acc: 0.9750\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 14s 232us/step - loss: 0.1153 - acc: 0.9657 - val_loss: 0.0528 - val_acc: 0.9816\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.0896 - acc: 0.9729 - val_loss: 0.0412 - val_acc: 0.9853\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0771 - acc: 0.9767 - val_loss: 0.0449 - val_acc: 0.9852\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.0677 - acc: 0.9787 - val_loss: 0.0445 - val_acc: 0.9843\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0582 - acc: 0.9812 - val_loss: 0.0393 - val_acc: 0.9860\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.0561 - acc: 0.9824 - val_loss: 0.0381 - val_acc: 0.9867\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0503 - acc: 0.9843 - val_loss: 0.0356 - val_acc: 0.9885\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0473 - acc: 0.9849 - val_loss: 0.0362 - val_acc: 0.9874\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.0420 - acc: 0.9867 - val_loss: 0.0398 - val_acc: 0.9872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6fd254dbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDuC0_MIXnGF",
        "colab_type": "text"
      },
      "source": [
        "# Auto-encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgah6uIyXrOC",
        "colab_type": "code",
        "outputId": "437277d1-85a2-4a48-b3d9-129435642016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%cd /content/ml-class/videos/autoencoder/\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ml-class/videos/autoencoder\n",
            "autoencoder_cnn.py  denoising_autoencoder.py\n",
            "autoencoder.py\t    run_autoencoder.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EAY8P3qa-c7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat autoencoder.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPrQNtG9cdf4",
        "colab_type": "code",
        "outputId": "542e45f3-c51c-4079-c890-271bf0b2337e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "source": [
        "from keras.layers import Input, Dense, Flatten, Reshape\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.callbacks import Callback\n",
        "import numpy as np\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "run = wandb.init(project=\"ml_class_autoenc\")\n",
        "config = run.config\n",
        "\n",
        "config.encoding_dim = 32\n",
        "config.epochs = 10\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "model.add(Dense(config.encoding_dim, activation='relu'))\n",
        "model.add(Dense(28*28, activation='sigmoid'))\n",
        "model.add(Reshape((28,28)))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# For visualization\n",
        "class Images(Callback):\n",
        "      def on_epoch_end(self, epoch, logs):\n",
        "            indices = np.random.randint(self.validation_data[0].shape[0], size=8)\n",
        "            test_data = self.validation_data[0][indices]\n",
        "            pred_data = self.model.predict(test_data)\n",
        "            run.history.row.update({\n",
        "                  \"examples\": [\n",
        "                        wandb.Image(np.hstack([data, pred_data[i]]), caption=str(i))\n",
        "                        for i, data in enumerate(test_data)]\n",
        "            })\n",
        "\n",
        "model.summary()\n",
        "model.fit(x_train, x_train,\n",
        "                epochs=config.epochs,\n",
        "                validation_data=(x_test, x_test), \n",
        "          callbacks=[Images(), WandbCallback()])\n",
        "\n",
        "\n",
        "model.save('auto.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/10dimensions/ml_class_autoenc\" target=\"_blank\">https://app.wandb.ai/10dimensions/ml_class_autoenc</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/10dimensions/ml_class_autoenc/runs/j310lwki\" target=\"_blank\">https://app.wandb.ai/10dimensions/ml_class_autoenc/runs/j310lwki</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 784)               25872     \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 28, 28)            0         \n",
            "=================================================================\n",
            "Total params: 50,992\n",
            "Trainable params: 50,992\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 135us/step - loss: 0.0325 - val_loss: 0.0162\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0134 - val_loss: 0.0113\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.0112 - val_loss: 0.0105\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 134us/step - loss: 0.0107 - val_loss: 0.0103\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0105 - val_loss: 0.0101\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.0104 - val_loss: 0.0100\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0103 - val_loss: 0.0100\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.0103 - val_loss: 0.0099\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.0102 - val_loss: 0.0100\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0102 - val_loss: 0.0099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaP_EKGzhrEh",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGQd-N1bhx9v",
        "colab_type": "code",
        "outputId": "695818ac-9206-4f05-b15c-ded567773622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd videos/text-classifier/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ml-class/videos/text-classifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW-ZxNJiii9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "more tweets.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1F1kIiSjD3s",
        "colab_type": "code",
        "outputId": "13f3045f-56f3-4757-a987-a18e4f30dd4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Quick example of loading our data into variables\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Puts tweets into a data frame\n",
        "df = pd.read_csv('tweets.csv')\n",
        "\n",
        "# Selects the first column from our data frame\n",
        "target = df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
        "\n",
        "# Selects the third column from our data frame\n",
        "text = df['tweet_text']\n",
        "\n",
        "print(len(text))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppraztT5AJoa",
        "colab_type": "text"
      },
      "source": [
        "**Feature Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ9pzBRRj8yR",
        "colab_type": "code",
        "outputId": "5032079e-0f8b-454a-83eb-dcaac68c3665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "# First attempt at feature extraction\n",
        "# Leads to an error, can you tell why?\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('tweets.csv')\n",
        "target = df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
        "text = df['tweet_text']\n",
        "\n",
        "# what did we do here?\n",
        "fixed_text = text[pd.notnull(text)]\n",
        "fixed_target = target[pd.notnull(text)]\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect=CountVectorizer()\n",
        "count_vect.fit(fixed_text)\n",
        "\n",
        "# turns the text into a sparse matrix\n",
        "counts = count_vect.transform(fixed_text)\n",
        "\n",
        "my_counts = count_vect.transform([\"love that iphone!\", \"HATE that iphone\"])\n",
        "print(my_counts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 4573)\t1\n",
            "  (0, 5169)\t1\n",
            "  (0, 8560)\t1\n",
            "  (1, 3975)\t1\n",
            "  (1, 4573)\t1\n",
            "  (1, 8560)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5n1pYE4AMfk",
        "colab_type": "text"
      },
      "source": [
        "**Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODXsvXFD_tVZ",
        "colab_type": "code",
        "outputId": "89b38e22-b0a0-460e-f3fa-8639e1d7a613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Get a pandas DataFrame object of all the data in the csv file:\n",
        "df = pd.read_csv('tweets.csv')\n",
        "\n",
        "# Get pandas Series object of the \"tweet text\" column:\n",
        "text = df['tweet_text']\n",
        "\n",
        "# Get pandas Series object of the \"emotion\" column:\n",
        "target = df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
        "\n",
        "# Remove the blank rows from the series:\n",
        "target = target[pd.notnull(text)]\n",
        "text = text[pd.notnull(text)]\n",
        "\n",
        "# Perform feature extraction:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "count_vect.fit(text)\n",
        "counts = count_vect.transform(text)\n",
        "\n",
        "# Train with this data with a Naive Bayes classifier:\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb = MultinomialNB()\n",
        "nb.fit(counts, target)\n",
        "\n",
        "#Try the classifier\n",
        "print(nb.predict(count_vect.transform(['i hate my iphone'])))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Negative emotion']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7JYeINQ_1Te",
        "colab_type": "code",
        "outputId": "dcc49eff-eb7e-4fc0-ea47-d06d89acee1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(nb.predict(count_vect.transform(['i love my iphone'])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Positive emotion']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI0v7p0sQwD7",
        "colab_type": "text"
      },
      "source": [
        "# RNN/Time-Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PDDpUToQ3xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/ml-class/videos/time-series/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bXo0aKBS6QT",
        "colab_type": "code",
        "outputId": "3d85196f-982f-4aef-aef8-2060cf2efbeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!wandb login 39011b0b79a9067f7ffdab0b8223dc33e75b8801"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFqVdJbdU9jL",
        "colab_type": "code",
        "outputId": "da0d4ef8-a6d1-43b8-b7e6-47e457c3dc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import LSTM, SimpleRNN, Dropout\n",
        "from keras.callbacks import LambdaCallback\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "import plotutil\n",
        "from plotutil import PlotCallback\n",
        "\n",
        "wandb.init(\"ml_class_rnn\")\n",
        "config = wandb.config\n",
        "\n",
        "config.repeated_predictions = False\n",
        "config.look_back = 20\n",
        "\n",
        "def load_data(data_type=\"airline\"):\n",
        "    if data_type == \"flu\":\n",
        "        df = pd.read_csv('flusearches.csv')\n",
        "        data = df.flu.astype('float32').values\n",
        "    elif data_type == \"airline\":\n",
        "        df = pd.read_csv('international-airline-passengers.csv')\n",
        "        data = df.passengers.astype('float32').values\n",
        "    elif data_type == \"sin\":\n",
        "        df = pd.read_csv('sin.csv')\n",
        "        data = df.sin.astype('float32').values\n",
        "    return data\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-config.look_back-1):\n",
        "        a = dataset[i:(i+config.look_back)]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + config.look_back])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "data = load_data()\n",
        "    \n",
        "# normalize data to between 0 and 1\n",
        "max_val = max(data)\n",
        "min_val = min(data)\n",
        "data=(data-min_val)/(max_val-min_val)\n",
        "\n",
        "# split into train and test sets\n",
        "split = int(len(data) * 0.70)\n",
        "train = data[:split]\n",
        "test = data[split:]\n",
        "\n",
        "trainX, trainY = create_dataset(train)\n",
        "testX, testY = create_dataset(test)\n",
        "\n",
        "trainX = trainX[:, :, np.newaxis]\n",
        "testX = testX[:, :, np.newaxis]\n",
        "\n",
        "# create and fit the RNN\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(config.look_back,1 )))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=1000, batch_size=10, validation_data=(testX, testY),  callbacks=[WandbCallback(), PlotCallback(trainX, trainY, testX, testY, config.look_back)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/10dimensions/ml-class-videos_time-series\" target=\"_blank\">https://app.wandb.ai/10dimensions/ml-class-videos_time-series</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/10dimensions/ml-class-videos_time-series/runs/n87tthsr\" target=\"_blank\">https://app.wandb.ai/10dimensions/ml-class-videos_time-series/runs/n87tthsr</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 79 samples, validate on 23 samples\n",
            "Epoch 1/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.3502\n",
            "Epoch 2/1000\n",
            "79/79 [==============================] - 0s 518us/step - loss: 0.0511 - val_loss: 0.2641\n",
            "Epoch 3/1000\n",
            "79/79 [==============================] - 0s 598us/step - loss: 0.0379 - val_loss: 0.2076\n",
            "Epoch 4/1000\n",
            "79/79 [==============================] - 0s 554us/step - loss: 0.0310 - val_loss: 0.1669\n",
            "Epoch 5/1000\n",
            "79/79 [==============================] - 0s 597us/step - loss: 0.0263 - val_loss: 0.1421\n",
            "Epoch 6/1000\n",
            "79/79 [==============================] - 0s 448us/step - loss: 0.0239 - val_loss: 0.1278\n",
            "Epoch 7/1000\n",
            "79/79 [==============================] - 0s 790us/step - loss: 0.0228 - val_loss: 0.1195\n",
            "Epoch 8/1000\n",
            "79/79 [==============================] - 0s 543us/step - loss: 0.0222 - val_loss: 0.1154\n",
            "Epoch 9/1000\n",
            "79/79 [==============================] - 0s 568us/step - loss: 0.0219 - val_loss: 0.1131\n",
            "Epoch 10/1000\n",
            "79/79 [==============================] - 0s 475us/step - loss: 0.0218 - val_loss: 0.1111\n",
            "Epoch 11/1000\n",
            "79/79 [==============================] - 0s 573us/step - loss: 0.0215 - val_loss: 0.1108\n",
            "Epoch 12/1000\n",
            "79/79 [==============================] - 0s 445us/step - loss: 0.0213 - val_loss: 0.1089\n",
            "Epoch 13/1000\n",
            "79/79 [==============================] - 0s 449us/step - loss: 0.0210 - val_loss: 0.1080\n",
            "Epoch 14/1000\n",
            "79/79 [==============================] - 0s 470us/step - loss: 0.0208 - val_loss: 0.1074\n",
            "Epoch 15/1000\n",
            "79/79 [==============================] - 0s 426us/step - loss: 0.0205 - val_loss: 0.1065\n",
            "Epoch 16/1000\n",
            "79/79 [==============================] - 0s 435us/step - loss: 0.0203 - val_loss: 0.1050\n",
            "Epoch 17/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 0.0201 - val_loss: 0.1034\n",
            "Epoch 18/1000\n",
            "79/79 [==============================] - 0s 554us/step - loss: 0.0198 - val_loss: 0.1020\n",
            "Epoch 19/1000\n",
            "79/79 [==============================] - 0s 541us/step - loss: 0.0196 - val_loss: 0.1009\n",
            "Epoch 20/1000\n",
            "79/79 [==============================] - 0s 454us/step - loss: 0.0195 - val_loss: 0.0989\n",
            "Epoch 21/1000\n",
            "79/79 [==============================] - 0s 587us/step - loss: 0.0192 - val_loss: 0.0976\n",
            "Epoch 22/1000\n",
            "79/79 [==============================] - 0s 715us/step - loss: 0.0189 - val_loss: 0.0969\n",
            "Epoch 23/1000\n",
            "79/79 [==============================] - 0s 535us/step - loss: 0.0187 - val_loss: 0.0962\n",
            "Epoch 24/1000\n",
            "79/79 [==============================] - 0s 541us/step - loss: 0.0184 - val_loss: 0.0946\n",
            "Epoch 25/1000\n",
            "79/79 [==============================] - 0s 656us/step - loss: 0.0182 - val_loss: 0.0935\n",
            "Epoch 26/1000\n",
            "79/79 [==============================] - 0s 495us/step - loss: 0.0180 - val_loss: 0.0918\n",
            "Epoch 27/1000\n",
            "79/79 [==============================] - 0s 471us/step - loss: 0.0177 - val_loss: 0.0902\n",
            "Epoch 28/1000\n",
            "79/79 [==============================] - 0s 528us/step - loss: 0.0175 - val_loss: 0.0894\n",
            "Epoch 29/1000\n",
            "79/79 [==============================] - 0s 445us/step - loss: 0.0172 - val_loss: 0.0881\n",
            "Epoch 30/1000\n",
            "79/79 [==============================] - 0s 497us/step - loss: 0.0170 - val_loss: 0.0865\n",
            "Epoch 31/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 0.0168 - val_loss: 0.0852\n",
            "Epoch 32/1000\n",
            "79/79 [==============================] - 0s 579us/step - loss: 0.0166 - val_loss: 0.0842\n",
            "Epoch 33/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 0.0164 - val_loss: 0.0834\n",
            "Epoch 34/1000\n",
            "79/79 [==============================] - 0s 698us/step - loss: 0.0162 - val_loss: 0.0820\n",
            "Epoch 35/1000\n",
            "79/79 [==============================] - 0s 518us/step - loss: 0.0160 - val_loss: 0.0814\n",
            "Epoch 36/1000\n",
            "79/79 [==============================] - 0s 513us/step - loss: 0.0157 - val_loss: 0.0798\n",
            "Epoch 37/1000\n",
            "79/79 [==============================] - 0s 590us/step - loss: 0.0155 - val_loss: 0.0785\n",
            "Epoch 38/1000\n",
            "79/79 [==============================] - 0s 478us/step - loss: 0.0153 - val_loss: 0.0774\n",
            "Epoch 39/1000\n",
            "79/79 [==============================] - 0s 462us/step - loss: 0.0151 - val_loss: 0.0764\n",
            "Epoch 40/1000\n",
            "79/79 [==============================] - 0s 667us/step - loss: 0.0150 - val_loss: 0.0750\n",
            "Epoch 41/1000\n",
            "79/79 [==============================] - 0s 507us/step - loss: 0.0147 - val_loss: 0.0739\n",
            "Epoch 42/1000\n",
            "79/79 [==============================] - 0s 448us/step - loss: 0.0146 - val_loss: 0.0732\n",
            "Epoch 43/1000\n",
            "79/79 [==============================] - 0s 582us/step - loss: 0.0143 - val_loss: 0.0721\n",
            "Epoch 44/1000\n",
            "79/79 [==============================] - 0s 404us/step - loss: 0.0141 - val_loss: 0.0710\n",
            "Epoch 45/1000\n",
            "79/79 [==============================] - 0s 723us/step - loss: 0.0139 - val_loss: 0.0700\n",
            "Epoch 46/1000\n",
            "79/79 [==============================] - 0s 558us/step - loss: 0.0137 - val_loss: 0.0690\n",
            "Epoch 47/1000\n",
            "79/79 [==============================] - 0s 455us/step - loss: 0.0135 - val_loss: 0.0678\n",
            "Epoch 48/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 0.0134 - val_loss: 0.0668\n",
            "Epoch 49/1000\n",
            "79/79 [==============================] - 0s 438us/step - loss: 0.0133 - val_loss: 0.0660\n",
            "Epoch 50/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 0.0130 - val_loss: 0.0650\n",
            "Epoch 51/1000\n",
            "79/79 [==============================] - 0s 462us/step - loss: 0.0128 - val_loss: 0.0639\n",
            "Epoch 52/1000\n",
            "79/79 [==============================] - 0s 489us/step - loss: 0.0126 - val_loss: 0.0630\n",
            "Epoch 53/1000\n",
            "79/79 [==============================] - 0s 584us/step - loss: 0.0125 - val_loss: 0.0621\n",
            "Epoch 54/1000\n",
            "79/79 [==============================] - 0s 594us/step - loss: 0.0123 - val_loss: 0.0612\n",
            "Epoch 55/1000\n",
            "79/79 [==============================] - 0s 440us/step - loss: 0.0121 - val_loss: 0.0603\n",
            "Epoch 56/1000\n",
            "79/79 [==============================] - 0s 452us/step - loss: 0.0120 - val_loss: 0.0594\n",
            "Epoch 57/1000\n",
            "79/79 [==============================] - 0s 545us/step - loss: 0.0118 - val_loss: 0.0585\n",
            "Epoch 58/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 0.0116 - val_loss: 0.0577\n",
            "Epoch 59/1000\n",
            "79/79 [==============================] - 0s 577us/step - loss: 0.0115 - val_loss: 0.0568\n",
            "Epoch 60/1000\n",
            "79/79 [==============================] - 0s 495us/step - loss: 0.0114 - val_loss: 0.0559\n",
            "Epoch 61/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 0.0112 - val_loss: 0.0551\n",
            "Epoch 62/1000\n",
            "79/79 [==============================] - 0s 421us/step - loss: 0.0110 - val_loss: 0.0543\n",
            "Epoch 63/1000\n",
            "79/79 [==============================] - 0s 620us/step - loss: 0.0109 - val_loss: 0.0535\n",
            "Epoch 64/1000\n",
            "79/79 [==============================] - 0s 598us/step - loss: 0.0107 - val_loss: 0.0527\n",
            "Epoch 65/1000\n",
            "79/79 [==============================] - 0s 502us/step - loss: 0.0106 - val_loss: 0.0520\n",
            "Epoch 66/1000\n",
            "79/79 [==============================] - 0s 464us/step - loss: 0.0105 - val_loss: 0.0512\n",
            "Epoch 67/1000\n",
            "79/79 [==============================] - 0s 473us/step - loss: 0.0103 - val_loss: 0.0504\n",
            "Epoch 68/1000\n",
            "79/79 [==============================] - 0s 517us/step - loss: 0.0102 - val_loss: 0.0496\n",
            "Epoch 69/1000\n",
            "79/79 [==============================] - 0s 498us/step - loss: 0.0100 - val_loss: 0.0489\n",
            "Epoch 70/1000\n",
            "79/79 [==============================] - 0s 561us/step - loss: 0.0099 - val_loss: 0.0481\n",
            "Epoch 71/1000\n",
            "79/79 [==============================] - 0s 483us/step - loss: 0.0097 - val_loss: 0.0475\n",
            "Epoch 72/1000\n",
            "79/79 [==============================] - 0s 519us/step - loss: 0.0096 - val_loss: 0.0467\n",
            "Epoch 73/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 0.0095 - val_loss: 0.0460\n",
            "Epoch 74/1000\n",
            "79/79 [==============================] - 0s 494us/step - loss: 0.0094 - val_loss: 0.0453\n",
            "Epoch 75/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 0.0092 - val_loss: 0.0446\n",
            "Epoch 76/1000\n",
            "79/79 [==============================] - 0s 427us/step - loss: 0.0091 - val_loss: 0.0439\n",
            "Epoch 77/1000\n",
            "79/79 [==============================] - 0s 463us/step - loss: 0.0090 - val_loss: 0.0433\n",
            "Epoch 78/1000\n",
            "79/79 [==============================] - 0s 435us/step - loss: 0.0089 - val_loss: 0.0426\n",
            "Epoch 79/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 0.0088 - val_loss: 0.0419\n",
            "Epoch 80/1000\n",
            "79/79 [==============================] - 0s 416us/step - loss: 0.0087 - val_loss: 0.0412\n",
            "Epoch 81/1000\n",
            "79/79 [==============================] - 0s 529us/step - loss: 0.0085 - val_loss: 0.0406\n",
            "Epoch 82/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 0.0084 - val_loss: 0.0401\n",
            "Epoch 83/1000\n",
            "79/79 [==============================] - 0s 439us/step - loss: 0.0083 - val_loss: 0.0395\n",
            "Epoch 84/1000\n",
            "79/79 [==============================] - 0s 479us/step - loss: 0.0082 - val_loss: 0.0387\n",
            "Epoch 85/1000\n",
            "79/79 [==============================] - 0s 457us/step - loss: 0.0081 - val_loss: 0.0382\n",
            "Epoch 86/1000\n",
            "79/79 [==============================] - 0s 526us/step - loss: 0.0080 - val_loss: 0.0376\n",
            "Epoch 87/1000\n",
            "79/79 [==============================] - 0s 452us/step - loss: 0.0079 - val_loss: 0.0370\n",
            "Epoch 88/1000\n",
            "79/79 [==============================] - 0s 649us/step - loss: 0.0078 - val_loss: 0.0364\n",
            "Epoch 89/1000\n",
            "79/79 [==============================] - 0s 626us/step - loss: 0.0077 - val_loss: 0.0360\n",
            "Epoch 90/1000\n",
            "79/79 [==============================] - 0s 487us/step - loss: 0.0076 - val_loss: 0.0353\n",
            "Epoch 91/1000\n",
            "79/79 [==============================] - 0s 489us/step - loss: 0.0075 - val_loss: 0.0347\n",
            "Epoch 92/1000\n",
            "79/79 [==============================] - 0s 408us/step - loss: 0.0074 - val_loss: 0.0341\n",
            "Epoch 93/1000\n",
            "79/79 [==============================] - 0s 421us/step - loss: 0.0073 - val_loss: 0.0337\n",
            "Epoch 94/1000\n",
            "79/79 [==============================] - 0s 421us/step - loss: 0.0072 - val_loss: 0.0332\n",
            "Epoch 95/1000\n",
            "79/79 [==============================] - 0s 488us/step - loss: 0.0071 - val_loss: 0.0327\n",
            "Epoch 96/1000\n",
            "79/79 [==============================] - 0s 496us/step - loss: 0.0070 - val_loss: 0.0321\n",
            "Epoch 97/1000\n",
            "79/79 [==============================] - 0s 510us/step - loss: 0.0069 - val_loss: 0.0316\n",
            "Epoch 98/1000\n",
            "79/79 [==============================] - 0s 493us/step - loss: 0.0068 - val_loss: 0.0312\n",
            "Epoch 99/1000\n",
            "79/79 [==============================] - 0s 478us/step - loss: 0.0068 - val_loss: 0.0307\n",
            "Epoch 100/1000\n",
            "79/79 [==============================] - 0s 550us/step - loss: 0.0067 - val_loss: 0.0303\n",
            "Epoch 101/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 0.0066 - val_loss: 0.0298\n",
            "Epoch 102/1000\n",
            "79/79 [==============================] - 0s 531us/step - loss: 0.0065 - val_loss: 0.0292\n",
            "Epoch 103/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 0.0065 - val_loss: 0.0288\n",
            "Epoch 104/1000\n",
            "79/79 [==============================] - 0s 528us/step - loss: 0.0065 - val_loss: 0.0286\n",
            "Epoch 105/1000\n",
            "79/79 [==============================] - 0s 502us/step - loss: 0.0063 - val_loss: 0.0280\n",
            "Epoch 106/1000\n",
            "79/79 [==============================] - 0s 458us/step - loss: 0.0062 - val_loss: 0.0275\n",
            "Epoch 107/1000\n",
            "79/79 [==============================] - 0s 436us/step - loss: 0.0061 - val_loss: 0.0271\n",
            "Epoch 108/1000\n",
            "79/79 [==============================] - 0s 417us/step - loss: 0.0061 - val_loss: 0.0266\n",
            "Epoch 109/1000\n",
            "79/79 [==============================] - 0s 466us/step - loss: 0.0060 - val_loss: 0.0263\n",
            "Epoch 110/1000\n",
            "79/79 [==============================] - 0s 433us/step - loss: 0.0060 - val_loss: 0.0260\n",
            "Epoch 111/1000\n",
            "79/79 [==============================] - 0s 512us/step - loss: 0.0059 - val_loss: 0.0253\n",
            "Epoch 112/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 0.0058 - val_loss: 0.0249\n",
            "Epoch 113/1000\n",
            "79/79 [==============================] - 0s 493us/step - loss: 0.0057 - val_loss: 0.0246\n",
            "Epoch 114/1000\n",
            "79/79 [==============================] - 0s 457us/step - loss: 0.0057 - val_loss: 0.0243\n",
            "Epoch 115/1000\n",
            "79/79 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0239\n",
            "Epoch 116/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 0.0055 - val_loss: 0.0237\n",
            "Epoch 117/1000\n",
            "79/79 [==============================] - 0s 448us/step - loss: 0.0055 - val_loss: 0.0231\n",
            "Epoch 118/1000\n",
            "79/79 [==============================] - 0s 446us/step - loss: 0.0054 - val_loss: 0.0228\n",
            "Epoch 119/1000\n",
            "79/79 [==============================] - 0s 488us/step - loss: 0.0054 - val_loss: 0.0224\n",
            "Epoch 120/1000\n",
            "79/79 [==============================] - 0s 586us/step - loss: 0.0053 - val_loss: 0.0222\n",
            "Epoch 121/1000\n",
            "79/79 [==============================] - 0s 432us/step - loss: 0.0053 - val_loss: 0.0218\n",
            "Epoch 122/1000\n",
            "79/79 [==============================] - 0s 533us/step - loss: 0.0052 - val_loss: 0.0215\n",
            "Epoch 123/1000\n",
            "79/79 [==============================] - 0s 465us/step - loss: 0.0052 - val_loss: 0.0211\n",
            "Epoch 124/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 0.0051 - val_loss: 0.0207\n",
            "Epoch 125/1000\n",
            "79/79 [==============================] - 0s 462us/step - loss: 0.0051 - val_loss: 0.0206\n",
            "Epoch 126/1000\n",
            "79/79 [==============================] - 0s 471us/step - loss: 0.0050 - val_loss: 0.0202\n",
            "Epoch 127/1000\n",
            "79/79 [==============================] - 0s 452us/step - loss: 0.0049 - val_loss: 0.0200\n",
            "Epoch 128/1000\n",
            "79/79 [==============================] - 0s 474us/step - loss: 0.0048 - val_loss: 0.0196\n",
            "Epoch 129/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 0.0048 - val_loss: 0.0192\n",
            "Epoch 130/1000\n",
            "79/79 [==============================] - 0s 416us/step - loss: 0.0048 - val_loss: 0.0190\n",
            "Epoch 131/1000\n",
            "79/79 [==============================] - 0s 416us/step - loss: 0.0047 - val_loss: 0.0187\n",
            "Epoch 132/1000\n",
            "79/79 [==============================] - 0s 466us/step - loss: 0.0047 - val_loss: 0.0186\n",
            "Epoch 133/1000\n",
            "79/79 [==============================] - 0s 443us/step - loss: 0.0046 - val_loss: 0.0181\n",
            "Epoch 134/1000\n",
            "79/79 [==============================] - 0s 499us/step - loss: 0.0046 - val_loss: 0.0179\n",
            "Epoch 135/1000\n",
            "79/79 [==============================] - 0s 419us/step - loss: 0.0046 - val_loss: 0.0177\n",
            "Epoch 136/1000\n",
            "79/79 [==============================] - 0s 482us/step - loss: 0.0045 - val_loss: 0.0174\n",
            "Epoch 137/1000\n",
            "79/79 [==============================] - 0s 400us/step - loss: 0.0045 - val_loss: 0.0172\n",
            "Epoch 138/1000\n",
            "79/79 [==============================] - 0s 604us/step - loss: 0.0044 - val_loss: 0.0170\n",
            "Epoch 139/1000\n",
            "79/79 [==============================] - 0s 534us/step - loss: 0.0044 - val_loss: 0.0166\n",
            "Epoch 140/1000\n",
            "79/79 [==============================] - 0s 518us/step - loss: 0.0043 - val_loss: 0.0164\n",
            "Epoch 141/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 0.0043 - val_loss: 0.0162\n",
            "Epoch 142/1000\n",
            "79/79 [==============================] - 0s 545us/step - loss: 0.0042 - val_loss: 0.0160\n",
            "Epoch 143/1000\n",
            "79/79 [==============================] - 0s 467us/step - loss: 0.0042 - val_loss: 0.0157\n",
            "Epoch 144/1000\n",
            "79/79 [==============================] - 0s 415us/step - loss: 0.0042 - val_loss: 0.0155\n",
            "Epoch 145/1000\n",
            "79/79 [==============================] - 0s 415us/step - loss: 0.0041 - val_loss: 0.0153\n",
            "Epoch 146/1000\n",
            "79/79 [==============================] - 0s 497us/step - loss: 0.0041 - val_loss: 0.0151\n",
            "Epoch 147/1000\n",
            "79/79 [==============================] - 0s 479us/step - loss: 0.0041 - val_loss: 0.0148\n",
            "Epoch 148/1000\n",
            "79/79 [==============================] - 0s 477us/step - loss: 0.0040 - val_loss: 0.0147\n",
            "Epoch 149/1000\n",
            "79/79 [==============================] - 0s 453us/step - loss: 0.0040 - val_loss: 0.0145\n",
            "Epoch 150/1000\n",
            "79/79 [==============================] - 0s 531us/step - loss: 0.0039 - val_loss: 0.0143\n",
            "Epoch 151/1000\n",
            "79/79 [==============================] - 0s 439us/step - loss: 0.0039 - val_loss: 0.0141\n",
            "Epoch 152/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 0.0039 - val_loss: 0.0139\n",
            "Epoch 153/1000\n",
            "79/79 [==============================] - 0s 496us/step - loss: 0.0038 - val_loss: 0.0137\n",
            "Epoch 154/1000\n",
            "79/79 [==============================] - 0s 406us/step - loss: 0.0038 - val_loss: 0.0136\n",
            "Epoch 155/1000\n",
            "79/79 [==============================] - 0s 445us/step - loss: 0.0038 - val_loss: 0.0133\n",
            "Epoch 156/1000\n",
            "79/79 [==============================] - 0s 470us/step - loss: 0.0038 - val_loss: 0.0132\n",
            "Epoch 157/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 0.0037 - val_loss: 0.0130\n",
            "Epoch 158/1000\n",
            "79/79 [==============================] - 0s 408us/step - loss: 0.0037 - val_loss: 0.0128\n",
            "Epoch 159/1000\n",
            "79/79 [==============================] - 0s 489us/step - loss: 0.0037 - val_loss: 0.0126\n",
            "Epoch 160/1000\n",
            "79/79 [==============================] - 0s 533us/step - loss: 0.0036 - val_loss: 0.0125\n",
            "Epoch 161/1000\n",
            "79/79 [==============================] - 0s 554us/step - loss: 0.0037 - val_loss: 0.0125\n",
            "Epoch 162/1000\n",
            "79/79 [==============================] - 0s 576us/step - loss: 0.0036 - val_loss: 0.0122\n",
            "Epoch 163/1000\n",
            "79/79 [==============================] - 0s 461us/step - loss: 0.0036 - val_loss: 0.0120\n",
            "Epoch 164/1000\n",
            "79/79 [==============================] - 0s 409us/step - loss: 0.0035 - val_loss: 0.0119\n",
            "Epoch 165/1000\n",
            "79/79 [==============================] - 0s 493us/step - loss: 0.0035 - val_loss: 0.0117\n",
            "Epoch 166/1000\n",
            "79/79 [==============================] - 0s 477us/step - loss: 0.0035 - val_loss: 0.0116\n",
            "Epoch 167/1000\n",
            "79/79 [==============================] - 0s 551us/step - loss: 0.0035 - val_loss: 0.0115\n",
            "Epoch 168/1000\n",
            "79/79 [==============================] - 0s 462us/step - loss: 0.0034 - val_loss: 0.0113\n",
            "Epoch 169/1000\n",
            "79/79 [==============================] - 0s 397us/step - loss: 0.0034 - val_loss: 0.0112\n",
            "Epoch 170/1000\n",
            "79/79 [==============================] - 0s 517us/step - loss: 0.0034 - val_loss: 0.0111\n",
            "Epoch 171/1000\n",
            "79/79 [==============================] - 0s 411us/step - loss: 0.0034 - val_loss: 0.0109\n",
            "Epoch 172/1000\n",
            "79/79 [==============================] - 0s 467us/step - loss: 0.0034 - val_loss: 0.0108\n",
            "Epoch 173/1000\n",
            "79/79 [==============================] - 0s 674us/step - loss: 0.0033 - val_loss: 0.0106\n",
            "Epoch 174/1000\n",
            "79/79 [==============================] - 0s 412us/step - loss: 0.0033 - val_loss: 0.0105\n",
            "Epoch 175/1000\n",
            "79/79 [==============================] - 0s 419us/step - loss: 0.0033 - val_loss: 0.0104\n",
            "Epoch 176/1000\n",
            "79/79 [==============================] - 0s 408us/step - loss: 0.0033 - val_loss: 0.0103\n",
            "Epoch 177/1000\n",
            "79/79 [==============================] - 0s 431us/step - loss: 0.0032 - val_loss: 0.0102\n",
            "Epoch 178/1000\n",
            "79/79 [==============================] - 0s 463us/step - loss: 0.0032 - val_loss: 0.0101\n",
            "Epoch 179/1000\n",
            "79/79 [==============================] - 0s 489us/step - loss: 0.0032 - val_loss: 0.0100\n",
            "Epoch 180/1000\n",
            "79/79 [==============================] - 0s 522us/step - loss: 0.0032 - val_loss: 0.0098\n",
            "Epoch 181/1000\n",
            "79/79 [==============================] - 0s 488us/step - loss: 0.0032 - val_loss: 0.0097\n",
            "Epoch 182/1000\n",
            "79/79 [==============================] - 0s 489us/step - loss: 0.0032 - val_loss: 0.0096\n",
            "Epoch 183/1000\n",
            "79/79 [==============================] - 0s 551us/step - loss: 0.0031 - val_loss: 0.0095\n",
            "Epoch 184/1000\n",
            "79/79 [==============================] - 0s 426us/step - loss: 0.0031 - val_loss: 0.0094\n",
            "Epoch 185/1000\n",
            "79/79 [==============================] - 0s 525us/step - loss: 0.0031 - val_loss: 0.0093\n",
            "Epoch 186/1000\n",
            "79/79 [==============================] - 0s 597us/step - loss: 0.0031 - val_loss: 0.0092\n",
            "Epoch 187/1000\n",
            "79/79 [==============================] - 0s 422us/step - loss: 0.0030 - val_loss: 0.0091\n",
            "Epoch 188/1000\n",
            "79/79 [==============================] - 0s 446us/step - loss: 0.0030 - val_loss: 0.0090\n",
            "Epoch 189/1000\n",
            "79/79 [==============================] - 0s 535us/step - loss: 0.0031 - val_loss: 0.0090\n",
            "Epoch 190/1000\n",
            "79/79 [==============================] - 0s 511us/step - loss: 0.0030 - val_loss: 0.0088\n",
            "Epoch 191/1000\n",
            "79/79 [==============================] - 0s 473us/step - loss: 0.0030 - val_loss: 0.0088\n",
            "Epoch 192/1000\n",
            "79/79 [==============================] - 0s 482us/step - loss: 0.0030 - val_loss: 0.0087\n",
            "Epoch 193/1000\n",
            "79/79 [==============================] - 0s 395us/step - loss: 0.0030 - val_loss: 0.0086\n",
            "Epoch 194/1000\n",
            "79/79 [==============================] - 0s 479us/step - loss: 0.0029 - val_loss: 0.0085\n",
            "Epoch 195/1000\n",
            "79/79 [==============================] - 0s 485us/step - loss: 0.0029 - val_loss: 0.0084\n",
            "Epoch 196/1000\n",
            "79/79 [==============================] - 0s 562us/step - loss: 0.0029 - val_loss: 0.0083\n",
            "Epoch 197/1000\n",
            "79/79 [==============================] - 0s 492us/step - loss: 0.0029 - val_loss: 0.0083\n",
            "Epoch 198/1000\n",
            "79/79 [==============================] - 0s 458us/step - loss: 0.0029 - val_loss: 0.0082\n",
            "Epoch 199/1000\n",
            "79/79 [==============================] - 0s 648us/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 200/1000\n",
            "79/79 [==============================] - 0s 469us/step - loss: 0.0029 - val_loss: 0.0080\n",
            "Epoch 201/1000\n",
            "79/79 [==============================] - 0s 422us/step - loss: 0.0028 - val_loss: 0.0080\n",
            "Epoch 202/1000\n",
            "79/79 [==============================] - 0s 519us/step - loss: 0.0028 - val_loss: 0.0079\n",
            "Epoch 203/1000\n",
            "79/79 [==============================] - 0s 432us/step - loss: 0.0028 - val_loss: 0.0078\n",
            "Epoch 204/1000\n",
            "79/79 [==============================] - 0s 460us/step - loss: 0.0028 - val_loss: 0.0077\n",
            "Epoch 205/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 0.0028 - val_loss: 0.0077\n",
            "Epoch 206/1000\n",
            "79/79 [==============================] - 0s 452us/step - loss: 0.0028 - val_loss: 0.0076\n",
            "Epoch 207/1000\n",
            "79/79 [==============================] - 0s 420us/step - loss: 0.0028 - val_loss: 0.0076\n",
            "Epoch 208/1000\n",
            "79/79 [==============================] - 0s 422us/step - loss: 0.0028 - val_loss: 0.0075\n",
            "Epoch 209/1000\n",
            "79/79 [==============================] - 0s 435us/step - loss: 0.0028 - val_loss: 0.0075\n",
            "Epoch 210/1000\n",
            "79/79 [==============================] - 0s 436us/step - loss: 0.0027 - val_loss: 0.0074\n",
            "Epoch 211/1000\n",
            "79/79 [==============================] - 0s 493us/step - loss: 0.0027 - val_loss: 0.0073\n",
            "Epoch 212/1000\n",
            "79/79 [==============================] - 0s 435us/step - loss: 0.0027 - val_loss: 0.0072\n",
            "Epoch 213/1000\n",
            "79/79 [==============================] - 0s 450us/step - loss: 0.0027 - val_loss: 0.0072\n",
            "Epoch 214/1000\n",
            "79/79 [==============================] - 0s 502us/step - loss: 0.0027 - val_loss: 0.0072\n",
            "Epoch 215/1000\n",
            "79/79 [==============================] - 0s 460us/step - loss: 0.0027 - val_loss: 0.0072\n",
            "Epoch 216/1000\n",
            "79/79 [==============================] - 0s 523us/step - loss: 0.0027 - val_loss: 0.0070\n",
            "Epoch 217/1000\n",
            "79/79 [==============================] - 0s 527us/step - loss: 0.0027 - val_loss: 0.0070\n",
            "Epoch 218/1000\n",
            "79/79 [==============================] - 0s 490us/step - loss: 0.0027 - val_loss: 0.0070\n",
            "Epoch 219/1000\n",
            "79/79 [==============================] - 0s 440us/step - loss: 0.0027 - val_loss: 0.0069\n",
            "Epoch 220/1000\n",
            "79/79 [==============================] - 0s 446us/step - loss: 0.0026 - val_loss: 0.0068\n",
            "Epoch 221/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 0.0026 - val_loss: 0.0068\n",
            "Epoch 222/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 0.0027 - val_loss: 0.0068\n",
            "Epoch 223/1000\n",
            "79/79 [==============================] - 0s 417us/step - loss: 0.0026 - val_loss: 0.0066\n",
            "Epoch 224/1000\n",
            "79/79 [==============================] - 0s 492us/step - loss: 0.0026 - val_loss: 0.0066\n",
            "Epoch 225/1000\n",
            "79/79 [==============================] - 0s 405us/step - loss: 0.0026 - val_loss: 0.0065\n",
            "Epoch 226/1000\n",
            "79/79 [==============================] - 0s 516us/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 227/1000\n",
            "79/79 [==============================] - 0s 583us/step - loss: 0.0026 - val_loss: 0.0065\n",
            "Epoch 228/1000\n",
            "79/79 [==============================] - 0s 506us/step - loss: 0.0025 - val_loss: 0.0064\n",
            "Epoch 229/1000\n",
            "79/79 [==============================] - 0s 465us/step - loss: 0.0025 - val_loss: 0.0064\n",
            "Epoch 230/1000\n",
            "79/79 [==============================] - 0s 455us/step - loss: 0.0025 - val_loss: 0.0064\n",
            "Epoch 231/1000\n",
            "79/79 [==============================] - 0s 405us/step - loss: 0.0025 - val_loss: 0.0063\n",
            "Epoch 232/1000\n",
            "79/79 [==============================] - 0s 523us/step - loss: 0.0025 - val_loss: 0.0063\n",
            "Epoch 233/1000\n",
            "79/79 [==============================] - 0s 473us/step - loss: 0.0025 - val_loss: 0.0062\n",
            "Epoch 234/1000\n",
            "79/79 [==============================] - 0s 690us/step - loss: 0.0025 - val_loss: 0.0062\n",
            "Epoch 235/1000\n",
            "79/79 [==============================] - 0s 536us/step - loss: 0.0025 - val_loss: 0.0061\n",
            "Epoch 236/1000\n",
            "79/79 [==============================] - 0s 464us/step - loss: 0.0025 - val_loss: 0.0061\n",
            "Epoch 237/1000\n",
            "79/79 [==============================] - 0s 490us/step - loss: 0.0025 - val_loss: 0.0060\n",
            "Epoch 238/1000\n",
            "79/79 [==============================] - 0s 403us/step - loss: 0.0025 - val_loss: 0.0060\n",
            "Epoch 239/1000\n",
            "79/79 [==============================] - 0s 417us/step - loss: 0.0025 - val_loss: 0.0060\n",
            "Epoch 240/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 0.0024 - val_loss: 0.0060\n",
            "Epoch 241/1000\n",
            "79/79 [==============================] - 0s 405us/step - loss: 0.0024 - val_loss: 0.0059\n",
            "Epoch 242/1000\n",
            "79/79 [==============================] - 0s 565us/step - loss: 0.0024 - val_loss: 0.0059\n",
            "Epoch 243/1000\n",
            "79/79 [==============================] - 0s 433us/step - loss: 0.0024 - val_loss: 0.0058\n",
            "Epoch 244/1000\n",
            "79/79 [==============================] - 0s 435us/step - loss: 0.0024 - val_loss: 0.0058\n",
            "Epoch 245/1000\n",
            "79/79 [==============================] - 0s 548us/step - loss: 0.0024 - val_loss: 0.0058\n",
            "Epoch 246/1000\n",
            "79/79 [==============================] - 0s 478us/step - loss: 0.0024 - val_loss: 0.0058\n",
            "Epoch 247/1000\n",
            "79/79 [==============================] - 0s 513us/step - loss: 0.0024 - val_loss: 0.0057\n",
            "Epoch 248/1000\n",
            "79/79 [==============================] - 0s 491us/step - loss: 0.0024 - val_loss: 0.0057\n",
            "Epoch 249/1000\n",
            "79/79 [==============================] - 0s 401us/step - loss: 0.0024 - val_loss: 0.0057\n",
            "Epoch 250/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 0.0024 - val_loss: 0.0056\n",
            "Epoch 251/1000\n",
            "79/79 [==============================] - 0s 415us/step - loss: 0.0024 - val_loss: 0.0056\n",
            "Epoch 252/1000\n",
            "79/79 [==============================] - 0s 466us/step - loss: 0.0023 - val_loss: 0.0056\n",
            "Epoch 253/1000\n",
            "79/79 [==============================] - 0s 435us/step - loss: 0.0023 - val_loss: 0.0055\n",
            "Epoch 254/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 0.0023 - val_loss: 0.0055\n",
            "Epoch 255/1000\n",
            "79/79 [==============================] - 0s 487us/step - loss: 0.0023 - val_loss: 0.0055\n",
            "Epoch 256/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 0.0023 - val_loss: 0.0055\n",
            "Epoch 257/1000\n",
            "79/79 [==============================] - 0s 426us/step - loss: 0.0023 - val_loss: 0.0054\n",
            "Epoch 258/1000\n",
            "79/79 [==============================] - 0s 474us/step - loss: 0.0023 - val_loss: 0.0055\n",
            "Epoch 259/1000\n",
            "79/79 [==============================] - 0s 554us/step - loss: 0.0023 - val_loss: 0.0054\n",
            "Epoch 260/1000\n",
            "79/79 [==============================] - 0s 476us/step - loss: 0.0023 - val_loss: 0.0053\n",
            "Epoch 261/1000\n",
            "79/79 [==============================] - 0s 560us/step - loss: 0.0023 - val_loss: 0.0053\n",
            "Epoch 262/1000\n",
            "79/79 [==============================] - 0s 449us/step - loss: 0.0023 - val_loss: 0.0053\n",
            "Epoch 263/1000\n",
            "79/79 [==============================] - 0s 447us/step - loss: 0.0023 - val_loss: 0.0053\n",
            "Epoch 264/1000\n",
            "79/79 [==============================] - 0s 541us/step - loss: 0.0023 - val_loss: 0.0053\n",
            "Epoch 265/1000\n",
            "79/79 [==============================] - 0s 503us/step - loss: 0.0023 - val_loss: 0.0052\n",
            "Epoch 266/1000\n",
            "79/79 [==============================] - 0s 446us/step - loss: 0.0023 - val_loss: 0.0052\n",
            "Epoch 267/1000\n",
            "79/79 [==============================] - 0s 411us/step - loss: 0.0023 - val_loss: 0.0052\n",
            "Epoch 268/1000\n",
            "79/79 [==============================] - 0s 407us/step - loss: 0.0023 - val_loss: 0.0052\n",
            "Epoch 269/1000\n",
            "79/79 [==============================] - 0s 469us/step - loss: 0.0022 - val_loss: 0.0051\n",
            "Epoch 270/1000\n",
            "79/79 [==============================] - 0s 457us/step - loss: 0.0022 - val_loss: 0.0051\n",
            "Epoch 271/1000\n",
            "79/79 [==============================] - 0s 497us/step - loss: 0.0022 - val_loss: 0.0051\n",
            "Epoch 272/1000\n",
            "79/79 [==============================] - 0s 424us/step - loss: 0.0022 - val_loss: 0.0051\n",
            "Epoch 273/1000\n",
            "79/79 [==============================] - 0s 474us/step - loss: 0.0022 - val_loss: 0.0051\n",
            "Epoch 274/1000\n",
            "79/79 [==============================] - 0s 551us/step - loss: 0.0022 - val_loss: 0.0051\n",
            "Epoch 275/1000\n",
            "79/79 [==============================] - 0s 495us/step - loss: 0.0022 - val_loss: 0.0050\n",
            "Epoch 276/1000\n",
            "79/79 [==============================] - 0s 420us/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 277/1000\n",
            "79/79 [==============================] - 0s 554us/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 278/1000\n",
            "79/79 [==============================] - 0s 477us/step - loss: 0.0022 - val_loss: 0.0050\n",
            "Epoch 279/1000\n",
            "79/79 [==============================] - 0s 545us/step - loss: 0.0022 - val_loss: 0.0050\n",
            "Epoch 280/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 281/1000\n",
            "79/79 [==============================] - 0s 441us/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 282/1000\n",
            "79/79 [==============================] - 0s 499us/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 283/1000\n",
            "79/79 [==============================] - 0s 419us/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 284/1000\n",
            "79/79 [==============================] - 0s 453us/step - loss: 0.0021 - val_loss: 0.0049\n",
            "Epoch 285/1000\n",
            "79/79 [==============================] - 0s 419us/step - loss: 0.0021 - val_loss: 0.0048\n",
            "Epoch 286/1000\n",
            "79/79 [==============================] - 0s 452us/step - loss: 0.0021 - val_loss: 0.0048\n",
            "Epoch 287/1000\n",
            "79/79 [==============================] - 0s 476us/step - loss: 0.0021 - val_loss: 0.0048\n",
            "Epoch 288/1000\n",
            "79/79 [==============================] - 0s 414us/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 289/1000\n",
            "79/79 [==============================] - 0s 412us/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 290/1000\n",
            "79/79 [==============================] - 0s 449us/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 291/1000\n",
            "79/79 [==============================] - 0s 470us/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 292/1000\n",
            "79/79 [==============================] - 0s 448us/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 293/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 294/1000\n",
            "79/79 [==============================] - 0s 401us/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 295/1000\n",
            "79/79 [==============================] - 0s 408us/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 296/1000\n",
            "79/79 [==============================] - 0s 536us/step - loss: 0.0021 - val_loss: 0.0046\n",
            "Epoch 297/1000\n",
            "79/79 [==============================] - 0s 463us/step - loss: 0.0021 - val_loss: 0.0046\n",
            "Epoch 298/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 299/1000\n",
            "79/79 [==============================] - 0s 530us/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 300/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 0.0021 - val_loss: 0.0045\n",
            "Epoch 301/1000\n",
            "79/79 [==============================] - 0s 471us/step - loss: 0.0022 - val_loss: 0.0045\n",
            "Epoch 302/1000\n",
            "79/79 [==============================] - 0s 432us/step - loss: 0.0021 - val_loss: 0.0046\n",
            "Epoch 303/1000\n",
            "79/79 [==============================] - 0s 611us/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 304/1000\n",
            "79/79 [==============================] - 0s 462us/step - loss: 0.0021 - val_loss: 0.0045\n",
            "Epoch 305/1000\n",
            "79/79 [==============================] - 0s 565us/step - loss: 0.0020 - val_loss: 0.0045\n",
            "Epoch 306/1000\n",
            "79/79 [==============================] - 0s 508us/step - loss: 0.0020 - val_loss: 0.0044\n",
            "Epoch 307/1000\n",
            "79/79 [==============================] - 0s 500us/step - loss: 0.0021 - val_loss: 0.0044\n",
            "Epoch 308/1000\n",
            "79/79 [==============================] - 0s 629us/step - loss: 0.0020 - val_loss: 0.0044\n",
            "Epoch 309/1000\n",
            "79/79 [==============================] - 0s 407us/step - loss: 0.0021 - val_loss: 0.0046\n",
            "Epoch 310/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 0.0020 - val_loss: 0.0044\n",
            "Epoch 311/1000\n",
            "79/79 [==============================] - 0s 494us/step - loss: 0.0020 - val_loss: 0.0043\n",
            "Epoch 312/1000\n",
            "79/79 [==============================] - 0s 634us/step - loss: 0.0020 - val_loss: 0.0044\n",
            "Epoch 313/1000\n",
            "79/79 [==============================] - 0s 473us/step - loss: 0.0020 - val_loss: 0.0044\n",
            "Epoch 314/1000\n",
            "79/79 [==============================] - 0s 461us/step - loss: 0.0020 - val_loss: 0.0043\n",
            "Epoch 315/1000\n",
            "79/79 [==============================] - 0s 446us/step - loss: 0.0020 - val_loss: 0.0044\n",
            "Epoch 316/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 0.0020 - val_loss: 0.0043\n",
            "Epoch 317/1000\n",
            "79/79 [==============================] - 0s 483us/step - loss: 0.0020 - val_loss: 0.0043\n",
            "Epoch 318/1000\n",
            "79/79 [==============================] - 0s 448us/step - loss: 0.0020 - val_loss: 0.0043\n",
            "Epoch 319/1000\n",
            "79/79 [==============================] - 0s 522us/step - loss: 0.0020 - val_loss: 0.0043\n",
            "Epoch 320/1000\n",
            "79/79 [==============================] - 0s 529us/step - loss: 0.0020 - val_loss: 0.0043\n",
            "Epoch 321/1000\n",
            "79/79 [==============================] - 0s 480us/step - loss: 0.0020 - val_loss: 0.0042\n",
            "Epoch 322/1000\n",
            "79/79 [==============================] - 0s 610us/step - loss: 0.0020 - val_loss: 0.0043\n",
            "Epoch 323/1000\n",
            "79/79 [==============================] - 0s 435us/step - loss: 0.0020 - val_loss: 0.0042\n",
            "Epoch 324/1000\n",
            "79/79 [==============================] - 0s 467us/step - loss: 0.0020 - val_loss: 0.0042\n",
            "Epoch 325/1000\n",
            "79/79 [==============================] - 0s 507us/step - loss: 0.0020 - val_loss: 0.0042\n",
            "Epoch 326/1000\n",
            "79/79 [==============================] - 0s 420us/step - loss: 0.0019 - val_loss: 0.0043\n",
            "Epoch 327/1000\n",
            "79/79 [==============================] - 0s 618us/step - loss: 0.0019 - val_loss: 0.0043\n",
            "Epoch 328/1000\n",
            "79/79 [==============================] - 0s 423us/step - loss: 0.0020 - val_loss: 0.0041\n",
            "Epoch 329/1000\n",
            "79/79 [==============================] - 0s 484us/step - loss: 0.0019 - val_loss: 0.0041\n",
            "Epoch 330/1000\n",
            "79/79 [==============================] - 0s 424us/step - loss: 0.0019 - val_loss: 0.0041\n",
            "Epoch 331/1000\n",
            "79/79 [==============================] - 0s 721us/step - loss: 0.0019 - val_loss: 0.0042\n",
            "Epoch 332/1000\n",
            "79/79 [==============================] - 0s 443us/step - loss: 0.0019 - val_loss: 0.0041\n",
            "Epoch 333/1000\n",
            "79/79 [==============================] - 0s 475us/step - loss: 0.0019 - val_loss: 0.0042\n",
            "Epoch 334/1000\n",
            "79/79 [==============================] - 0s 526us/step - loss: 0.0019 - val_loss: 0.0041\n",
            "Epoch 335/1000\n",
            "79/79 [==============================] - 0s 454us/step - loss: 0.0019 - val_loss: 0.0040\n",
            "Epoch 336/1000\n",
            "79/79 [==============================] - 0s 487us/step - loss: 0.0019 - val_loss: 0.0041\n",
            "Epoch 337/1000\n",
            "79/79 [==============================] - 0s 499us/step - loss: 0.0019 - val_loss: 0.0042\n",
            "Epoch 338/1000\n",
            "79/79 [==============================] - 0s 518us/step - loss: 0.0019 - val_loss: 0.0041\n",
            "Epoch 339/1000\n",
            "79/79 [==============================] - 0s 431us/step - loss: 0.0019 - val_loss: 0.0040\n",
            "Epoch 340/1000\n",
            "79/79 [==============================] - 0s 455us/step - loss: 0.0019 - val_loss: 0.0040\n",
            "Epoch 341/1000\n",
            "79/79 [==============================] - 0s 578us/step - loss: 0.0019 - val_loss: 0.0040\n",
            "Epoch 342/1000\n",
            "79/79 [==============================] - 0s 439us/step - loss: 0.0019 - val_loss: 0.0040\n",
            "Epoch 343/1000\n",
            "79/79 [==============================] - 0s 439us/step - loss: 0.0019 - val_loss: 0.0041\n",
            "Epoch 344/1000\n",
            "79/79 [==============================] - 0s 408us/step - loss: 0.0019 - val_loss: 0.0040\n",
            "Epoch 345/1000\n",
            "79/79 [==============================] - 0s 539us/step - loss: 0.0019 - val_loss: 0.0039\n",
            "Epoch 346/1000\n",
            "79/79 [==============================] - 0s 438us/step - loss: 0.0019 - val_loss: 0.0039\n",
            "Epoch 347/1000\n",
            "79/79 [==============================] - 0s 421us/step - loss: 0.0018 - val_loss: 0.0039\n",
            "Epoch 348/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 0.0018 - val_loss: 0.0040\n",
            "Epoch 349/1000\n",
            "79/79 [==============================] - 0s 501us/step - loss: 0.0019 - val_loss: 0.0041\n",
            "Epoch 350/1000\n",
            "79/79 [==============================] - 0s 436us/step - loss: 0.0019 - val_loss: 0.0039\n",
            "Epoch 351/1000\n",
            "79/79 [==============================] - 0s 550us/step - loss: 0.0018 - val_loss: 0.0039\n",
            "Epoch 352/1000\n",
            "79/79 [==============================] - 0s 491us/step - loss: 0.0018 - val_loss: 0.0039\n",
            "Epoch 353/1000\n",
            "79/79 [==============================] - 0s 441us/step - loss: 0.0018 - val_loss: 0.0039\n",
            "Epoch 354/1000\n",
            "79/79 [==============================] - 0s 433us/step - loss: 0.0018 - val_loss: 0.0039\n",
            "Epoch 355/1000\n",
            "79/79 [==============================] - 0s 435us/step - loss: 0.0018 - val_loss: 0.0040\n",
            "Epoch 356/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 0.0018 - val_loss: 0.0039\n",
            "Epoch 357/1000\n",
            "79/79 [==============================] - 0s 415us/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 358/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 359/1000\n",
            "79/79 [==============================] - 0s 417us/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 360/1000\n",
            "79/79 [==============================] - 0s 518us/step - loss: 0.0018 - val_loss: 0.0040\n",
            "Epoch 361/1000\n",
            "79/79 [==============================] - 0s 407us/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 362/1000\n",
            "79/79 [==============================] - 0s 422us/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 363/1000\n",
            "79/79 [==============================] - 0s 515us/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 364/1000\n",
            "79/79 [==============================] - 0s 513us/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 365/1000\n",
            "79/79 [==============================] - 0s 490us/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 366/1000\n",
            "79/79 [==============================] - 0s 529us/step - loss: 0.0018 - val_loss: 0.0037\n",
            "Epoch 367/1000\n",
            "79/79 [==============================] - 0s 419us/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 368/1000\n",
            "79/79 [==============================] - 0s 460us/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 369/1000\n",
            "79/79 [==============================] - 0s 417us/step - loss: 0.0018 - val_loss: 0.0037\n",
            "Epoch 370/1000\n",
            "79/79 [==============================] - 0s 423us/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 371/1000\n",
            "79/79 [==============================] - 0s 440us/step - loss: 0.0018 - val_loss: 0.0037\n",
            "Epoch 372/1000\n",
            "79/79 [==============================] - 0s 682us/step - loss: 0.0017 - val_loss: 0.0037\n",
            "Epoch 373/1000\n",
            "79/79 [==============================] - 0s 415us/step - loss: 0.0018 - val_loss: 0.0036\n",
            "Epoch 374/1000\n",
            "79/79 [==============================] - 0s 507us/step - loss: 0.0017 - val_loss: 0.0038\n",
            "Epoch 375/1000\n",
            "79/79 [==============================] - 0s 406us/step - loss: 0.0018 - val_loss: 0.0036\n",
            "Epoch 376/1000\n",
            "79/79 [==============================] - 0s 482us/step - loss: 0.0017 - val_loss: 0.0037\n",
            "Epoch 377/1000\n",
            "79/79 [==============================] - 0s 474us/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 378/1000\n",
            "79/79 [==============================] - 0s 488us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 379/1000\n",
            "79/79 [==============================] - 0s 466us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 380/1000\n",
            "79/79 [==============================] - 0s 739us/step - loss: 0.0017 - val_loss: 0.0037\n",
            "Epoch 381/1000\n",
            "79/79 [==============================] - 0s 472us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 382/1000\n",
            "79/79 [==============================] - 0s 568us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 383/1000\n",
            "79/79 [==============================] - 0s 445us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 384/1000\n",
            "79/79 [==============================] - 0s 420us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 385/1000\n",
            "79/79 [==============================] - 0s 458us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 386/1000\n",
            "79/79 [==============================] - 0s 439us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 387/1000\n",
            "79/79 [==============================] - 0s 412us/step - loss: 0.0017 - val_loss: 0.0035\n",
            "Epoch 388/1000\n",
            "79/79 [==============================] - 0s 542us/step - loss: 0.0017 - val_loss: 0.0035\n",
            "Epoch 389/1000\n",
            "79/79 [==============================] - 0s 719us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 390/1000\n",
            "79/79 [==============================] - 0s 466us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 391/1000\n",
            "79/79 [==============================] - 0s 426us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 392/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 0.0017 - val_loss: 0.0035\n",
            "Epoch 393/1000\n",
            "79/79 [==============================] - 0s 412us/step - loss: 0.0017 - val_loss: 0.0035\n",
            "Epoch 394/1000\n",
            "79/79 [==============================] - 0s 484us/step - loss: 0.0017 - val_loss: 0.0035\n",
            "Epoch 395/1000\n",
            "79/79 [==============================] - 0s 466us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 396/1000\n",
            "79/79 [==============================] - 0s 576us/step - loss: 0.0017 - val_loss: 0.0035\n",
            "Epoch 397/1000\n",
            "79/79 [==============================] - 0s 402us/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 398/1000\n",
            "79/79 [==============================] - 0s 599us/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 399/1000\n",
            "79/79 [==============================] - 0s 450us/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 400/1000\n",
            "79/79 [==============================] - 0s 475us/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 401/1000\n",
            "79/79 [==============================] - 0s 412us/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 402/1000\n",
            "79/79 [==============================] - 0s 435us/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 403/1000\n",
            "79/79 [==============================] - 0s 500us/step - loss: 0.0017 - val_loss: 0.0034\n",
            "Epoch 404/1000\n",
            "79/79 [==============================] - 0s 471us/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 405/1000\n",
            "79/79 [==============================] - 0s 488us/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 406/1000\n",
            "79/79 [==============================] - 0s 436us/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 407/1000\n",
            "79/79 [==============================] - 0s 484us/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 408/1000\n",
            "79/79 [==============================] - 0s 457us/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 409/1000\n",
            "79/79 [==============================] - 0s 502us/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 410/1000\n",
            "79/79 [==============================] - 0s 479us/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 411/1000\n",
            "79/79 [==============================] - 0s 475us/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 412/1000\n",
            "79/79 [==============================] - 0s 424us/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 413/1000\n",
            "79/79 [==============================] - 0s 501us/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 414/1000\n",
            "79/79 [==============================] - 0s 484us/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 415/1000\n",
            "79/79 [==============================] - 0s 459us/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 416/1000\n",
            "79/79 [==============================] - 0s 429us/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 417/1000\n",
            "79/79 [==============================] - 0s 544us/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 418/1000\n",
            "79/79 [==============================] - 0s 467us/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 419/1000\n",
            "79/79 [==============================] - 0s 547us/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 420/1000\n",
            "79/79 [==============================] - 0s 485us/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 421/1000\n",
            "79/79 [==============================] - 0s 429us/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 422/1000\n",
            "79/79 [==============================] - 0s 467us/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 423/1000\n",
            "79/79 [==============================] - 0s 439us/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 424/1000\n",
            "79/79 [==============================] - 0s 550us/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 425/1000\n",
            "79/79 [==============================] - 0s 432us/step - loss: 0.0015 - val_loss: 0.0033\n",
            "Epoch 426/1000\n",
            "79/79 [==============================] - 0s 424us/step - loss: 0.0015 - val_loss: 0.0033\n",
            "Epoch 427/1000\n",
            "79/79 [==============================] - 0s 573us/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 428/1000\n",
            "79/79 [==============================] - 0s 462us/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 429/1000\n",
            "79/79 [==============================] - 0s 453us/step - loss: 0.0015 - val_loss: 0.0033\n",
            "Epoch 430/1000\n",
            "79/79 [==============================] - 0s 419us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 431/1000\n",
            "79/79 [==============================] - 0s 404us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 432/1000\n",
            "79/79 [==============================] - 0s 709us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 433/1000\n",
            "79/79 [==============================] - 0s 509us/step - loss: 0.0015 - val_loss: 0.0033\n",
            "Epoch 434/1000\n",
            "79/79 [==============================] - 0s 452us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 435/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 436/1000\n",
            "79/79 [==============================] - 0s 455us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 437/1000\n",
            "79/79 [==============================] - 0s 450us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 438/1000\n",
            "79/79 [==============================] - 0s 417us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 439/1000\n",
            "79/79 [==============================] - 0s 676us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 440/1000\n",
            "79/79 [==============================] - 0s 424us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 441/1000\n",
            "79/79 [==============================] - 0s 439us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 442/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 443/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 444/1000\n",
            "79/79 [==============================] - 0s 432us/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 445/1000\n",
            "79/79 [==============================] - 0s 456us/step - loss: 0.0015 - val_loss: 0.0033\n",
            "Epoch 446/1000\n",
            "79/79 [==============================] - 0s 386us/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 447/1000\n",
            "79/79 [==============================] - 0s 435us/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 448/1000\n",
            "79/79 [==============================] - 0s 451us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 449/1000\n",
            "79/79 [==============================] - 0s 395us/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 450/1000\n",
            "79/79 [==============================] - 0s 397us/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 451/1000\n",
            "79/79 [==============================] - 0s 452us/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 452/1000\n",
            "79/79 [==============================] - 0s 445us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 453/1000\n",
            "79/79 [==============================] - 0s 715us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 454/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 0.0014 - val_loss: 0.0031\n",
            "Epoch 455/1000\n",
            "79/79 [==============================] - 0s 480us/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 456/1000\n",
            "79/79 [==============================] - 0s 440us/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 457/1000\n",
            "79/79 [==============================] - 0s 553us/step - loss: 0.0014 - val_loss: 0.0031\n",
            "Epoch 458/1000\n",
            "79/79 [==============================] - 0s 459us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 459/1000\n",
            "79/79 [==============================] - 0s 567us/step - loss: 0.0014 - val_loss: 0.0031\n",
            "Epoch 460/1000\n",
            "79/79 [==============================] - 0s 539us/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 461/1000\n",
            "79/79 [==============================] - 0s 517us/step - loss: 0.0014 - val_loss: 0.0031\n",
            "Epoch 462/1000\n",
            "79/79 [==============================] - 0s 689us/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 463/1000\n",
            "79/79 [==============================] - 0s 421us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 464/1000\n",
            "79/79 [==============================] - 0s 422us/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 465/1000\n",
            "79/79 [==============================] - 0s 408us/step - loss: 0.0014 - val_loss: 0.0031\n",
            "Epoch 466/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 467/1000\n",
            "79/79 [==============================] - 0s 440us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 468/1000\n",
            "79/79 [==============================] - 0s 481us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 469/1000\n",
            "79/79 [==============================] - 0s 409us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 470/1000\n",
            "79/79 [==============================] - 0s 502us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 471/1000\n",
            "79/79 [==============================] - 0s 510us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 472/1000\n",
            "79/79 [==============================] - 0s 505us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 473/1000\n",
            "79/79 [==============================] - 0s 446us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 474/1000\n",
            "79/79 [==============================] - 0s 423us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 475/1000\n",
            "79/79 [==============================] - 0s 481us/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 476/1000\n",
            "79/79 [==============================] - 0s 601us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 477/1000\n",
            "79/79 [==============================] - 0s 470us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 478/1000\n",
            "79/79 [==============================] - 0s 406us/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 479/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 480/1000\n",
            "79/79 [==============================] - 0s 408us/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 481/1000\n",
            "79/79 [==============================] - 0s 414us/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 482/1000\n",
            "79/79 [==============================] - 0s 783us/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 483/1000\n",
            "79/79 [==============================] - 0s 443us/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 484/1000\n",
            "79/79 [==============================] - 0s 431us/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 485/1000\n",
            "79/79 [==============================] - 0s 413us/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 486/1000\n",
            "79/79 [==============================] - 0s 604us/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 487/1000\n",
            "79/79 [==============================] - 0s 420us/step - loss: 0.0014 - val_loss: 0.0031\n",
            "Epoch 488/1000\n",
            "79/79 [==============================] - 0s 421us/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 489/1000\n",
            "79/79 [==============================] - 0s 418us/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 490/1000\n",
            "79/79 [==============================] - 0s 486us/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 491/1000\n",
            "79/79 [==============================] - 0s 482us/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 492/1000\n",
            "79/79 [==============================] - 0s 725us/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 493/1000\n",
            "79/79 [==============================] - 0s 496us/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 494/1000\n",
            "79/79 [==============================] - 0s 454us/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 495/1000\n",
            "79/79 [==============================] - 0s 461us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 496/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 497/1000\n",
            "79/79 [==============================] - 0s 453us/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 498/1000\n",
            "79/79 [==============================] - 0s 584us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 499/1000\n",
            "79/79 [==============================] - 0s 584us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 500/1000\n",
            "79/79 [==============================] - 0s 475us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 501/1000\n",
            "79/79 [==============================] - 0s 517us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 502/1000\n",
            "79/79 [==============================] - 0s 590us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 503/1000\n",
            "79/79 [==============================] - 0s 617us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 504/1000\n",
            "79/79 [==============================] - 0s 467us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 505/1000\n",
            "79/79 [==============================] - 0s 505us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 506/1000\n",
            "79/79 [==============================] - 0s 486us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 507/1000\n",
            "79/79 [==============================] - 0s 498us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 508/1000\n",
            "79/79 [==============================] - 0s 448us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 509/1000\n",
            "79/79 [==============================] - 0s 459us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 510/1000\n",
            "79/79 [==============================] - 0s 410us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 511/1000\n",
            "79/79 [==============================] - 0s 551us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 512/1000\n",
            "79/79 [==============================] - 0s 656us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 513/1000\n",
            "79/79 [==============================] - 0s 480us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 514/1000\n",
            "79/79 [==============================] - 0s 479us/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 515/1000\n",
            "79/79 [==============================] - 0s 503us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 516/1000\n",
            "79/79 [==============================] - 0s 455us/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 517/1000\n",
            "79/79 [==============================] - 0s 460us/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 518/1000\n",
            "79/79 [==============================] - 0s 422us/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 519/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 520/1000\n",
            "79/79 [==============================] - 0s 556us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 521/1000\n",
            "79/79 [==============================] - 0s 474us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 522/1000\n",
            "79/79 [==============================] - 0s 523us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 523/1000\n",
            "79/79 [==============================] - 0s 576us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 524/1000\n",
            "79/79 [==============================] - 0s 414us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 525/1000\n",
            "79/79 [==============================] - 0s 427us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 526/1000\n",
            "79/79 [==============================] - 0s 426us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 527/1000\n",
            "79/79 [==============================] - 0s 429us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 528/1000\n",
            "79/79 [==============================] - 0s 431us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 529/1000\n",
            "79/79 [==============================] - 0s 457us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 530/1000\n",
            "79/79 [==============================] - 0s 400us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 531/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 532/1000\n",
            "79/79 [==============================] - 0s 638us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 533/1000\n",
            "79/79 [==============================] - 0s 451us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 534/1000\n",
            "79/79 [==============================] - 0s 438us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 535/1000\n",
            "79/79 [==============================] - 0s 446us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 536/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 537/1000\n",
            "79/79 [==============================] - 0s 439us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 538/1000\n",
            "79/79 [==============================] - 0s 445us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 539/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 540/1000\n",
            "79/79 [==============================] - 0s 649us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 541/1000\n",
            "79/79 [==============================] - 0s 456us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 542/1000\n",
            "79/79 [==============================] - 0s 547us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 543/1000\n",
            "79/79 [==============================] - 0s 644us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 544/1000\n",
            "79/79 [==============================] - 0s 467us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 545/1000\n",
            "79/79 [==============================] - 0s 499us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 546/1000\n",
            "79/79 [==============================] - 0s 536us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 547/1000\n",
            "79/79 [==============================] - 0s 510us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 548/1000\n",
            "79/79 [==============================] - 0s 488us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 549/1000\n",
            "79/79 [==============================] - 0s 403us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 550/1000\n",
            "79/79 [==============================] - 0s 408us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 551/1000\n",
            "79/79 [==============================] - 0s 417us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 552/1000\n",
            "79/79 [==============================] - 0s 484us/step - loss: 0.0011 - val_loss: 0.0026\n",
            "Epoch 553/1000\n",
            "79/79 [==============================] - 0s 474us/step - loss: 0.0011 - val_loss: 0.0026\n",
            "Epoch 554/1000\n",
            "79/79 [==============================] - 0s 507us/step - loss: 0.0011 - val_loss: 0.0026\n",
            "Epoch 555/1000\n",
            "79/79 [==============================] - 0s 514us/step - loss: 0.0011 - val_loss: 0.0026\n",
            "Epoch 556/1000\n",
            "79/79 [==============================] - 0s 446us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 557/1000\n",
            "79/79 [==============================] - 0s 418us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 558/1000\n",
            "79/79 [==============================] - 0s 486us/step - loss: 0.0011 - val_loss: 0.0026\n",
            "Epoch 559/1000\n",
            "79/79 [==============================] - 0s 412us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 560/1000\n",
            "79/79 [==============================] - 0s 454us/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 561/1000\n",
            "79/79 [==============================] - 0s 486us/step - loss: 0.0011 - val_loss: 0.0026\n",
            "Epoch 562/1000\n",
            "79/79 [==============================] - 0s 455us/step - loss: 0.0011 - val_loss: 0.0026\n",
            "Epoch 563/1000\n",
            "79/79 [==============================] - 0s 488us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 564/1000\n",
            "79/79 [==============================] - 0s 527us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 565/1000\n",
            "79/79 [==============================] - 0s 454us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 566/1000\n",
            "79/79 [==============================] - 0s 415us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 567/1000\n",
            "79/79 [==============================] - 0s 507us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 568/1000\n",
            "79/79 [==============================] - 0s 412us/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 569/1000\n",
            "79/79 [==============================] - 0s 639us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 570/1000\n",
            "79/79 [==============================] - 0s 431us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 571/1000\n",
            "79/79 [==============================] - 0s 412us/step - loss: 0.0011 - val_loss: 0.0026\n",
            "Epoch 572/1000\n",
            "79/79 [==============================] - 0s 527us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 573/1000\n",
            "79/79 [==============================] - 0s 482us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 574/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 575/1000\n",
            "79/79 [==============================] - 0s 530us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 576/1000\n",
            "79/79 [==============================] - 0s 494us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 577/1000\n",
            "79/79 [==============================] - 0s 441us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 578/1000\n",
            "79/79 [==============================] - 0s 403us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 579/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 580/1000\n",
            "79/79 [==============================] - 0s 473us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 581/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 582/1000\n",
            "79/79 [==============================] - 0s 422us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 583/1000\n",
            "79/79 [==============================] - 0s 460us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 584/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 585/1000\n",
            "79/79 [==============================] - 0s 436us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 586/1000\n",
            "79/79 [==============================] - 0s 499us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 587/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 588/1000\n",
            "79/79 [==============================] - 0s 401us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 589/1000\n",
            "79/79 [==============================] - 0s 456us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 590/1000\n",
            "79/79 [==============================] - 0s 420us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 591/1000\n",
            "79/79 [==============================] - 0s 458us/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 592/1000\n",
            "79/79 [==============================] - 0s 492us/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 593/1000\n",
            "79/79 [==============================] - 0s 462us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 594/1000\n",
            "79/79 [==============================] - 0s 419us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 595/1000\n",
            "79/79 [==============================] - 0s 571us/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 596/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 597/1000\n",
            "79/79 [==============================] - 0s 440us/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 598/1000\n",
            "79/79 [==============================] - 0s 513us/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 599/1000\n",
            "79/79 [==============================] - 0s 526us/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 600/1000\n",
            "79/79 [==============================] - 0s 585us/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 601/1000\n",
            "79/79 [==============================] - 0s 421us/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 602/1000\n",
            "79/79 [==============================] - 0s 459us/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 603/1000\n",
            "79/79 [==============================] - 0s 399us/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 604/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 605/1000\n",
            "79/79 [==============================] - 0s 570us/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 606/1000\n",
            "79/79 [==============================] - 0s 419us/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 607/1000\n",
            "79/79 [==============================] - 0s 495us/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 608/1000\n",
            "79/79 [==============================] - 0s 558us/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 609/1000\n",
            "79/79 [==============================] - 0s 415us/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 610/1000\n",
            "79/79 [==============================] - 0s 436us/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 611/1000\n",
            "79/79 [==============================] - 0s 547us/step - loss: 9.9940e-04 - val_loss: 0.0023\n",
            "Epoch 612/1000\n",
            "79/79 [==============================] - 0s 450us/step - loss: 9.9358e-04 - val_loss: 0.0023\n",
            "Epoch 613/1000\n",
            "79/79 [==============================] - 0s 466us/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 614/1000\n",
            "79/79 [==============================] - 0s 592us/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 615/1000\n",
            "79/79 [==============================] - 0s 426us/step - loss: 9.9199e-04 - val_loss: 0.0023\n",
            "Epoch 616/1000\n",
            "79/79 [==============================] - 0s 502us/step - loss: 9.9373e-04 - val_loss: 0.0023\n",
            "Epoch 617/1000\n",
            "79/79 [==============================] - 0s 507us/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 618/1000\n",
            "79/79 [==============================] - 0s 400us/step - loss: 9.9291e-04 - val_loss: 0.0023\n",
            "Epoch 619/1000\n",
            "79/79 [==============================] - 0s 448us/step - loss: 9.9923e-04 - val_loss: 0.0023\n",
            "Epoch 620/1000\n",
            "79/79 [==============================] - 0s 451us/step - loss: 9.7378e-04 - val_loss: 0.0023\n",
            "Epoch 621/1000\n",
            "79/79 [==============================] - 0s 495us/step - loss: 9.7962e-04 - val_loss: 0.0023\n",
            "Epoch 622/1000\n",
            "79/79 [==============================] - 0s 496us/step - loss: 9.7326e-04 - val_loss: 0.0023\n",
            "Epoch 623/1000\n",
            "79/79 [==============================] - 0s 437us/step - loss: 9.8906e-04 - val_loss: 0.0023\n",
            "Epoch 624/1000\n",
            "79/79 [==============================] - 0s 449us/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 625/1000\n",
            "79/79 [==============================] - 0s 410us/step - loss: 9.7303e-04 - val_loss: 0.0022\n",
            "Epoch 626/1000\n",
            "79/79 [==============================] - 0s 526us/step - loss: 9.6137e-04 - val_loss: 0.0022\n",
            "Epoch 627/1000\n",
            "79/79 [==============================] - 0s 489us/step - loss: 9.6398e-04 - val_loss: 0.0022\n",
            "Epoch 628/1000\n",
            "79/79 [==============================] - 0s 548us/step - loss: 9.8123e-04 - val_loss: 0.0023\n",
            "Epoch 629/1000\n",
            "79/79 [==============================] - 0s 511us/step - loss: 9.7249e-04 - val_loss: 0.0022\n",
            "Epoch 630/1000\n",
            "79/79 [==============================] - 0s 636us/step - loss: 9.5432e-04 - val_loss: 0.0023\n",
            "Epoch 631/1000\n",
            "79/79 [==============================] - 0s 624us/step - loss: 9.6382e-04 - val_loss: 0.0022\n",
            "Epoch 632/1000\n",
            "79/79 [==============================] - 0s 423us/step - loss: 9.5945e-04 - val_loss: 0.0022\n",
            "Epoch 633/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 9.5068e-04 - val_loss: 0.0022\n",
            "Epoch 634/1000\n",
            "79/79 [==============================] - 0s 591us/step - loss: 9.5716e-04 - val_loss: 0.0022\n",
            "Epoch 635/1000\n",
            "79/79 [==============================] - 0s 522us/step - loss: 9.5253e-04 - val_loss: 0.0022\n",
            "Epoch 636/1000\n",
            "79/79 [==============================] - 0s 450us/step - loss: 9.4938e-04 - val_loss: 0.0022\n",
            "Epoch 637/1000\n",
            "79/79 [==============================] - 0s 436us/step - loss: 9.4253e-04 - val_loss: 0.0022\n",
            "Epoch 638/1000\n",
            "79/79 [==============================] - 0s 469us/step - loss: 9.4435e-04 - val_loss: 0.0022\n",
            "Epoch 639/1000\n",
            "79/79 [==============================] - 0s 460us/step - loss: 9.8685e-04 - val_loss: 0.0023\n",
            "Epoch 640/1000\n",
            "79/79 [==============================] - 0s 407us/step - loss: 9.8199e-04 - val_loss: 0.0023\n",
            "Epoch 641/1000\n",
            "79/79 [==============================] - 0s 472us/step - loss: 9.5048e-04 - val_loss: 0.0022\n",
            "Epoch 642/1000\n",
            "79/79 [==============================] - 0s 480us/step - loss: 9.3144e-04 - val_loss: 0.0022\n",
            "Epoch 643/1000\n",
            "79/79 [==============================] - 0s 642us/step - loss: 9.2735e-04 - val_loss: 0.0022\n",
            "Epoch 644/1000\n",
            "79/79 [==============================] - 0s 535us/step - loss: 9.3453e-04 - val_loss: 0.0022\n",
            "Epoch 645/1000\n",
            "79/79 [==============================] - 0s 533us/step - loss: 9.2102e-04 - val_loss: 0.0022\n",
            "Epoch 646/1000\n",
            "79/79 [==============================] - 0s 469us/step - loss: 9.1721e-04 - val_loss: 0.0022\n",
            "Epoch 647/1000\n",
            "79/79 [==============================] - 0s 480us/step - loss: 9.2456e-04 - val_loss: 0.0022\n",
            "Epoch 648/1000\n",
            "79/79 [==============================] - 0s 489us/step - loss: 9.1418e-04 - val_loss: 0.0022\n",
            "Epoch 649/1000\n",
            "79/79 [==============================] - 0s 534us/step - loss: 9.1283e-04 - val_loss: 0.0022\n",
            "Epoch 650/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 9.1289e-04 - val_loss: 0.0021\n",
            "Epoch 651/1000\n",
            "79/79 [==============================] - 0s 463us/step - loss: 9.1793e-04 - val_loss: 0.0021\n",
            "Epoch 652/1000\n",
            "79/79 [==============================] - 0s 471us/step - loss: 8.9955e-04 - val_loss: 0.0022\n",
            "Epoch 653/1000\n",
            "79/79 [==============================] - 0s 477us/step - loss: 9.1645e-04 - val_loss: 0.0022\n",
            "Epoch 654/1000\n",
            "79/79 [==============================] - 0s 429us/step - loss: 8.9763e-04 - val_loss: 0.0021\n",
            "Epoch 655/1000\n",
            "79/79 [==============================] - 0s 401us/step - loss: 9.0538e-04 - val_loss: 0.0022\n",
            "Epoch 656/1000\n",
            "79/79 [==============================] - 0s 433us/step - loss: 8.9038e-04 - val_loss: 0.0021\n",
            "Epoch 657/1000\n",
            "79/79 [==============================] - 0s 478us/step - loss: 8.9848e-04 - val_loss: 0.0022\n",
            "Epoch 658/1000\n",
            "79/79 [==============================] - 0s 426us/step - loss: 8.9830e-04 - val_loss: 0.0021\n",
            "Epoch 659/1000\n",
            "79/79 [==============================] - 0s 431us/step - loss: 8.8980e-04 - val_loss: 0.0021\n",
            "Epoch 660/1000\n",
            "79/79 [==============================] - 0s 576us/step - loss: 8.9703e-04 - val_loss: 0.0021\n",
            "Epoch 661/1000\n",
            "79/79 [==============================] - 0s 502us/step - loss: 8.9176e-04 - val_loss: 0.0021\n",
            "Epoch 662/1000\n",
            "79/79 [==============================] - 0s 461us/step - loss: 8.8231e-04 - val_loss: 0.0021\n",
            "Epoch 663/1000\n",
            "79/79 [==============================] - 0s 497us/step - loss: 8.8515e-04 - val_loss: 0.0021\n",
            "Epoch 664/1000\n",
            "79/79 [==============================] - 0s 471us/step - loss: 8.8842e-04 - val_loss: 0.0021\n",
            "Epoch 665/1000\n",
            "79/79 [==============================] - 0s 547us/step - loss: 8.8683e-04 - val_loss: 0.0021\n",
            "Epoch 666/1000\n",
            "79/79 [==============================] - 0s 431us/step - loss: 8.7325e-04 - val_loss: 0.0021\n",
            "Epoch 667/1000\n",
            "79/79 [==============================] - 0s 431us/step - loss: 8.7069e-04 - val_loss: 0.0021\n",
            "Epoch 668/1000\n",
            "79/79 [==============================] - 0s 525us/step - loss: 8.7180e-04 - val_loss: 0.0021\n",
            "Epoch 669/1000\n",
            "79/79 [==============================] - 0s 654us/step - loss: 8.9223e-04 - val_loss: 0.0021\n",
            "Epoch 670/1000\n",
            "79/79 [==============================] - 0s 463us/step - loss: 8.6230e-04 - val_loss: 0.0021\n",
            "Epoch 671/1000\n",
            "79/79 [==============================] - 0s 527us/step - loss: 8.7300e-04 - val_loss: 0.0021\n",
            "Epoch 672/1000\n",
            "79/79 [==============================] - 0s 450us/step - loss: 8.7626e-04 - val_loss: 0.0021\n",
            "Epoch 673/1000\n",
            "79/79 [==============================] - 0s 418us/step - loss: 8.6832e-04 - val_loss: 0.0021\n",
            "Epoch 674/1000\n",
            "79/79 [==============================] - 0s 437us/step - loss: 8.6220e-04 - val_loss: 0.0021\n",
            "Epoch 675/1000\n",
            "79/79 [==============================] - 0s 516us/step - loss: 8.7703e-04 - val_loss: 0.0021\n",
            "Epoch 676/1000\n",
            "79/79 [==============================] - 0s 466us/step - loss: 8.5081e-04 - val_loss: 0.0021\n",
            "Epoch 677/1000\n",
            "79/79 [==============================] - 0s 518us/step - loss: 8.7183e-04 - val_loss: 0.0021\n",
            "Epoch 678/1000\n",
            "79/79 [==============================] - 0s 532us/step - loss: 8.5202e-04 - val_loss: 0.0021\n",
            "Epoch 679/1000\n",
            "79/79 [==============================] - 0s 458us/step - loss: 8.5212e-04 - val_loss: 0.0021\n",
            "Epoch 680/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 8.7587e-04 - val_loss: 0.0021\n",
            "Epoch 681/1000\n",
            "79/79 [==============================] - 0s 426us/step - loss: 8.3521e-04 - val_loss: 0.0021\n",
            "Epoch 682/1000\n",
            "79/79 [==============================] - 0s 438us/step - loss: 8.6635e-04 - val_loss: 0.0021\n",
            "Epoch 683/1000\n",
            "79/79 [==============================] - 0s 409us/step - loss: 8.5036e-04 - val_loss: 0.0021\n",
            "Epoch 684/1000\n",
            "79/79 [==============================] - 0s 469us/step - loss: 8.5424e-04 - val_loss: 0.0020\n",
            "Epoch 685/1000\n",
            "79/79 [==============================] - 0s 556us/step - loss: 8.3612e-04 - val_loss: 0.0021\n",
            "Epoch 686/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 8.4428e-04 - val_loss: 0.0020\n",
            "Epoch 687/1000\n",
            "79/79 [==============================] - 0s 622us/step - loss: 8.4669e-04 - val_loss: 0.0021\n",
            "Epoch 688/1000\n",
            "79/79 [==============================] - 0s 409us/step - loss: 8.3548e-04 - val_loss: 0.0020\n",
            "Epoch 689/1000\n",
            "79/79 [==============================] - 0s 433us/step - loss: 8.3894e-04 - val_loss: 0.0020\n",
            "Epoch 690/1000\n",
            "79/79 [==============================] - 0s 436us/step - loss: 8.8958e-04 - val_loss: 0.0020\n",
            "Epoch 691/1000\n",
            "79/79 [==============================] - 0s 479us/step - loss: 8.3683e-04 - val_loss: 0.0021\n",
            "Epoch 692/1000\n",
            "79/79 [==============================] - 0s 432us/step - loss: 8.2762e-04 - val_loss: 0.0020\n",
            "Epoch 693/1000\n",
            "79/79 [==============================] - 0s 436us/step - loss: 8.1599e-04 - val_loss: 0.0020\n",
            "Epoch 694/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 8.4234e-04 - val_loss: 0.0020\n",
            "Epoch 695/1000\n",
            "79/79 [==============================] - 0s 445us/step - loss: 8.3080e-04 - val_loss: 0.0020\n",
            "Epoch 696/1000\n",
            "79/79 [==============================] - 0s 576us/step - loss: 8.2569e-04 - val_loss: 0.0020\n",
            "Epoch 697/1000\n",
            "79/79 [==============================] - 0s 459us/step - loss: 8.2159e-04 - val_loss: 0.0020\n",
            "Epoch 698/1000\n",
            "79/79 [==============================] - 0s 404us/step - loss: 8.1052e-04 - val_loss: 0.0020\n",
            "Epoch 699/1000\n",
            "79/79 [==============================] - 0s 456us/step - loss: 8.1090e-04 - val_loss: 0.0020\n",
            "Epoch 700/1000\n",
            "79/79 [==============================] - 0s 416us/step - loss: 8.2763e-04 - val_loss: 0.0020\n",
            "Epoch 701/1000\n",
            "79/79 [==============================] - 0s 439us/step - loss: 8.1313e-04 - val_loss: 0.0020\n",
            "Epoch 702/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 8.0544e-04 - val_loss: 0.0020\n",
            "Epoch 703/1000\n",
            "79/79 [==============================] - 0s 469us/step - loss: 8.2077e-04 - val_loss: 0.0020\n",
            "Epoch 704/1000\n",
            "79/79 [==============================] - 0s 418us/step - loss: 8.0489e-04 - val_loss: 0.0020\n",
            "Epoch 705/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 8.2049e-04 - val_loss: 0.0020\n",
            "Epoch 706/1000\n",
            "79/79 [==============================] - 0s 497us/step - loss: 8.0361e-04 - val_loss: 0.0020\n",
            "Epoch 707/1000\n",
            "79/79 [==============================] - 0s 410us/step - loss: 7.9967e-04 - val_loss: 0.0020\n",
            "Epoch 708/1000\n",
            "79/79 [==============================] - 0s 487us/step - loss: 7.9997e-04 - val_loss: 0.0020\n",
            "Epoch 709/1000\n",
            "79/79 [==============================] - 0s 453us/step - loss: 7.9760e-04 - val_loss: 0.0019\n",
            "Epoch 710/1000\n",
            "79/79 [==============================] - 0s 560us/step - loss: 7.9696e-04 - val_loss: 0.0019\n",
            "Epoch 711/1000\n",
            "79/79 [==============================] - 0s 513us/step - loss: 7.9442e-04 - val_loss: 0.0019\n",
            "Epoch 712/1000\n",
            "79/79 [==============================] - 0s 421us/step - loss: 7.8147e-04 - val_loss: 0.0019\n",
            "Epoch 713/1000\n",
            "79/79 [==============================] - 0s 418us/step - loss: 7.9595e-04 - val_loss: 0.0019\n",
            "Epoch 714/1000\n",
            "79/79 [==============================] - 0s 469us/step - loss: 7.9599e-04 - val_loss: 0.0019\n",
            "Epoch 715/1000\n",
            "79/79 [==============================] - 0s 429us/step - loss: 8.1626e-04 - val_loss: 0.0020\n",
            "Epoch 716/1000\n",
            "79/79 [==============================] - 0s 464us/step - loss: 7.8374e-04 - val_loss: 0.0019\n",
            "Epoch 717/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 7.9385e-04 - val_loss: 0.0019\n",
            "Epoch 718/1000\n",
            "79/79 [==============================] - 0s 437us/step - loss: 7.8510e-04 - val_loss: 0.0019\n",
            "Epoch 719/1000\n",
            "79/79 [==============================] - 0s 455us/step - loss: 7.7661e-04 - val_loss: 0.0019\n",
            "Epoch 720/1000\n",
            "79/79 [==============================] - 0s 517us/step - loss: 7.7490e-04 - val_loss: 0.0019\n",
            "Epoch 721/1000\n",
            "79/79 [==============================] - 0s 690us/step - loss: 7.7546e-04 - val_loss: 0.0019\n",
            "Epoch 722/1000\n",
            "79/79 [==============================] - 0s 795us/step - loss: 7.7645e-04 - val_loss: 0.0019\n",
            "Epoch 723/1000\n",
            "79/79 [==============================] - 0s 454us/step - loss: 7.7102e-04 - val_loss: 0.0019\n",
            "Epoch 724/1000\n",
            "79/79 [==============================] - 0s 646us/step - loss: 7.6923e-04 - val_loss: 0.0019\n",
            "Epoch 725/1000\n",
            "79/79 [==============================] - 0s 420us/step - loss: 7.6922e-04 - val_loss: 0.0019\n",
            "Epoch 726/1000\n",
            "79/79 [==============================] - 0s 480us/step - loss: 7.6085e-04 - val_loss: 0.0019\n",
            "Epoch 727/1000\n",
            "79/79 [==============================] - 0s 413us/step - loss: 7.6120e-04 - val_loss: 0.0019\n",
            "Epoch 728/1000\n",
            "79/79 [==============================] - 0s 507us/step - loss: 7.7242e-04 - val_loss: 0.0019\n",
            "Epoch 729/1000\n",
            "79/79 [==============================] - 0s 437us/step - loss: 7.6703e-04 - val_loss: 0.0019\n",
            "Epoch 730/1000\n",
            "79/79 [==============================] - 0s 476us/step - loss: 7.6715e-04 - val_loss: 0.0019\n",
            "Epoch 731/1000\n",
            "79/79 [==============================] - 0s 477us/step - loss: 7.9900e-04 - val_loss: 0.0020\n",
            "Epoch 732/1000\n",
            "79/79 [==============================] - 0s 423us/step - loss: 7.5521e-04 - val_loss: 0.0019\n",
            "Epoch 733/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 7.9121e-04 - val_loss: 0.0020\n",
            "Epoch 734/1000\n",
            "79/79 [==============================] - 0s 403us/step - loss: 7.8419e-04 - val_loss: 0.0020\n",
            "Epoch 735/1000\n",
            "79/79 [==============================] - 0s 474us/step - loss: 7.5823e-04 - val_loss: 0.0019\n",
            "Epoch 736/1000\n",
            "79/79 [==============================] - 0s 512us/step - loss: 7.7238e-04 - val_loss: 0.0019\n",
            "Epoch 737/1000\n",
            "79/79 [==============================] - 0s 415us/step - loss: 7.4665e-04 - val_loss: 0.0019\n",
            "Epoch 738/1000\n",
            "79/79 [==============================] - 0s 410us/step - loss: 7.5485e-04 - val_loss: 0.0019\n",
            "Epoch 739/1000\n",
            "79/79 [==============================] - 0s 398us/step - loss: 7.5093e-04 - val_loss: 0.0019\n",
            "Epoch 740/1000\n",
            "79/79 [==============================] - 0s 432us/step - loss: 7.5930e-04 - val_loss: 0.0019\n",
            "Epoch 741/1000\n",
            "79/79 [==============================] - 0s 548us/step - loss: 7.3675e-04 - val_loss: 0.0018\n",
            "Epoch 742/1000\n",
            "79/79 [==============================] - 0s 453us/step - loss: 7.3510e-04 - val_loss: 0.0018\n",
            "Epoch 743/1000\n",
            "79/79 [==============================] - 0s 411us/step - loss: 7.4337e-04 - val_loss: 0.0018\n",
            "Epoch 744/1000\n",
            "79/79 [==============================] - 0s 394us/step - loss: 7.3870e-04 - val_loss: 0.0018\n",
            "Epoch 745/1000\n",
            "79/79 [==============================] - 0s 411us/step - loss: 7.5311e-04 - val_loss: 0.0019\n",
            "Epoch 746/1000\n",
            "79/79 [==============================] - 0s 496us/step - loss: 7.2845e-04 - val_loss: 0.0018\n",
            "Epoch 747/1000\n",
            "79/79 [==============================] - 0s 635us/step - loss: 7.4493e-04 - val_loss: 0.0018\n",
            "Epoch 748/1000\n",
            "79/79 [==============================] - 0s 583us/step - loss: 7.3500e-04 - val_loss: 0.0019\n",
            "Epoch 749/1000\n",
            "79/79 [==============================] - 0s 407us/step - loss: 7.2916e-04 - val_loss: 0.0018\n",
            "Epoch 750/1000\n",
            "79/79 [==============================] - 0s 431us/step - loss: 7.2120e-04 - val_loss: 0.0018\n",
            "Epoch 751/1000\n",
            "79/79 [==============================] - 0s 488us/step - loss: 7.2605e-04 - val_loss: 0.0018\n",
            "Epoch 752/1000\n",
            "79/79 [==============================] - 0s 423us/step - loss: 7.1921e-04 - val_loss: 0.0018\n",
            "Epoch 753/1000\n",
            "79/79 [==============================] - 0s 474us/step - loss: 7.2110e-04 - val_loss: 0.0018\n",
            "Epoch 754/1000\n",
            "79/79 [==============================] - 0s 477us/step - loss: 7.2003e-04 - val_loss: 0.0018\n",
            "Epoch 755/1000\n",
            "79/79 [==============================] - 0s 443us/step - loss: 7.1920e-04 - val_loss: 0.0018\n",
            "Epoch 756/1000\n",
            "79/79 [==============================] - 0s 426us/step - loss: 7.2500e-04 - val_loss: 0.0018\n",
            "Epoch 757/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 7.1261e-04 - val_loss: 0.0018\n",
            "Epoch 758/1000\n",
            "79/79 [==============================] - 0s 427us/step - loss: 7.1330e-04 - val_loss: 0.0018\n",
            "Epoch 759/1000\n",
            "79/79 [==============================] - 0s 504us/step - loss: 7.2987e-04 - val_loss: 0.0018\n",
            "Epoch 760/1000\n",
            "79/79 [==============================] - 0s 427us/step - loss: 7.1804e-04 - val_loss: 0.0018\n",
            "Epoch 761/1000\n",
            "79/79 [==============================] - 0s 466us/step - loss: 7.1622e-04 - val_loss: 0.0018\n",
            "Epoch 762/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 7.5146e-04 - val_loss: 0.0019\n",
            "Epoch 763/1000\n",
            "79/79 [==============================] - 0s 427us/step - loss: 7.1393e-04 - val_loss: 0.0019\n",
            "Epoch 764/1000\n",
            "79/79 [==============================] - 0s 457us/step - loss: 7.2149e-04 - val_loss: 0.0018\n",
            "Epoch 765/1000\n",
            "79/79 [==============================] - 0s 404us/step - loss: 6.9767e-04 - val_loss: 0.0018\n",
            "Epoch 766/1000\n",
            "79/79 [==============================] - 0s 630us/step - loss: 7.2818e-04 - val_loss: 0.0018\n",
            "Epoch 767/1000\n",
            "79/79 [==============================] - 0s 453us/step - loss: 6.8965e-04 - val_loss: 0.0019\n",
            "Epoch 768/1000\n",
            "79/79 [==============================] - 0s 515us/step - loss: 7.2838e-04 - val_loss: 0.0018\n",
            "Epoch 769/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 7.3999e-04 - val_loss: 0.0019\n",
            "Epoch 770/1000\n",
            "79/79 [==============================] - 0s 415us/step - loss: 7.1316e-04 - val_loss: 0.0018\n",
            "Epoch 771/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 6.9767e-04 - val_loss: 0.0018\n",
            "Epoch 772/1000\n",
            "79/79 [==============================] - 0s 449us/step - loss: 6.9458e-04 - val_loss: 0.0018\n",
            "Epoch 773/1000\n",
            "79/79 [==============================] - 0s 450us/step - loss: 6.8719e-04 - val_loss: 0.0018\n",
            "Epoch 774/1000\n",
            "79/79 [==============================] - 0s 504us/step - loss: 6.8842e-04 - val_loss: 0.0018\n",
            "Epoch 775/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 7.2800e-04 - val_loss: 0.0018\n",
            "Epoch 776/1000\n",
            "79/79 [==============================] - 0s 460us/step - loss: 6.9173e-04 - val_loss: 0.0018\n",
            "Epoch 777/1000\n",
            "79/79 [==============================] - 0s 506us/step - loss: 7.1174e-04 - val_loss: 0.0018\n",
            "Epoch 778/1000\n",
            "79/79 [==============================] - 0s 418us/step - loss: 6.9088e-04 - val_loss: 0.0019\n",
            "Epoch 779/1000\n",
            "79/79 [==============================] - 0s 452us/step - loss: 7.0589e-04 - val_loss: 0.0017\n",
            "Epoch 780/1000\n",
            "79/79 [==============================] - 0s 471us/step - loss: 6.8053e-04 - val_loss: 0.0017\n",
            "Epoch 781/1000\n",
            "79/79 [==============================] - 0s 497us/step - loss: 7.1378e-04 - val_loss: 0.0018\n",
            "Epoch 782/1000\n",
            "79/79 [==============================] - 0s 648us/step - loss: 6.7599e-04 - val_loss: 0.0018\n",
            "Epoch 783/1000\n",
            "79/79 [==============================] - 0s 473us/step - loss: 7.0875e-04 - val_loss: 0.0018\n",
            "Epoch 784/1000\n",
            "79/79 [==============================] - 0s 435us/step - loss: 6.7542e-04 - val_loss: 0.0018\n",
            "Epoch 785/1000\n",
            "79/79 [==============================] - 0s 485us/step - loss: 6.7711e-04 - val_loss: 0.0017\n",
            "Epoch 786/1000\n",
            "79/79 [==============================] - 0s 580us/step - loss: 6.9108e-04 - val_loss: 0.0018\n",
            "Epoch 787/1000\n",
            "79/79 [==============================] - 0s 549us/step - loss: 6.7046e-04 - val_loss: 0.0017\n",
            "Epoch 788/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 6.7643e-04 - val_loss: 0.0017\n",
            "Epoch 789/1000\n",
            "79/79 [==============================] - 0s 450us/step - loss: 6.8316e-04 - val_loss: 0.0017\n",
            "Epoch 790/1000\n",
            "79/79 [==============================] - 0s 464us/step - loss: 6.8236e-04 - val_loss: 0.0018\n",
            "Epoch 791/1000\n",
            "79/79 [==============================] - 0s 502us/step - loss: 6.7399e-04 - val_loss: 0.0017\n",
            "Epoch 792/1000\n",
            "79/79 [==============================] - 0s 505us/step - loss: 7.0202e-04 - val_loss: 0.0017\n",
            "Epoch 793/1000\n",
            "79/79 [==============================] - 0s 664us/step - loss: 6.6495e-04 - val_loss: 0.0017\n",
            "Epoch 794/1000\n",
            "79/79 [==============================] - 0s 437us/step - loss: 6.7458e-04 - val_loss: 0.0017\n",
            "Epoch 795/1000\n",
            "79/79 [==============================] - 0s 450us/step - loss: 6.8401e-04 - val_loss: 0.0018\n",
            "Epoch 796/1000\n",
            "79/79 [==============================] - 0s 459us/step - loss: 6.8008e-04 - val_loss: 0.0018\n",
            "Epoch 797/1000\n",
            "79/79 [==============================] - 0s 461us/step - loss: 6.5994e-04 - val_loss: 0.0017\n",
            "Epoch 798/1000\n",
            "79/79 [==============================] - 0s 493us/step - loss: 6.5420e-04 - val_loss: 0.0017\n",
            "Epoch 799/1000\n",
            "79/79 [==============================] - 0s 554us/step - loss: 6.5242e-04 - val_loss: 0.0017\n",
            "Epoch 800/1000\n",
            "79/79 [==============================] - 0s 517us/step - loss: 6.7682e-04 - val_loss: 0.0017\n",
            "Epoch 801/1000\n",
            "79/79 [==============================] - 0s 544us/step - loss: 6.5295e-04 - val_loss: 0.0017\n",
            "Epoch 802/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 6.6387e-04 - val_loss: 0.0017\n",
            "Epoch 803/1000\n",
            "79/79 [==============================] - 0s 402us/step - loss: 6.5123e-04 - val_loss: 0.0017\n",
            "Epoch 804/1000\n",
            "79/79 [==============================] - 0s 396us/step - loss: 6.5024e-04 - val_loss: 0.0017\n",
            "Epoch 805/1000\n",
            "79/79 [==============================] - 0s 413us/step - loss: 6.7900e-04 - val_loss: 0.0018\n",
            "Epoch 806/1000\n",
            "79/79 [==============================] - 0s 439us/step - loss: 6.5055e-04 - val_loss: 0.0017\n",
            "Epoch 807/1000\n",
            "79/79 [==============================] - 0s 416us/step - loss: 6.5060e-04 - val_loss: 0.0017\n",
            "Epoch 808/1000\n",
            "79/79 [==============================] - 0s 482us/step - loss: 6.4641e-04 - val_loss: 0.0017\n",
            "Epoch 809/1000\n",
            "79/79 [==============================] - 0s 518us/step - loss: 6.5019e-04 - val_loss: 0.0017\n",
            "Epoch 810/1000\n",
            "79/79 [==============================] - 0s 475us/step - loss: 6.6770e-04 - val_loss: 0.0018\n",
            "Epoch 811/1000\n",
            "79/79 [==============================] - 0s 384us/step - loss: 6.4848e-04 - val_loss: 0.0017\n",
            "Epoch 812/1000\n",
            "79/79 [==============================] - 0s 417us/step - loss: 6.4942e-04 - val_loss: 0.0017\n",
            "Epoch 813/1000\n",
            "79/79 [==============================] - 0s 489us/step - loss: 6.4275e-04 - val_loss: 0.0017\n",
            "Epoch 814/1000\n",
            "79/79 [==============================] - 0s 468us/step - loss: 6.3601e-04 - val_loss: 0.0016\n",
            "Epoch 815/1000\n",
            "79/79 [==============================] - 0s 406us/step - loss: 6.3547e-04 - val_loss: 0.0016\n",
            "Epoch 816/1000\n",
            "79/79 [==============================] - 0s 414us/step - loss: 6.3538e-04 - val_loss: 0.0017\n",
            "Epoch 817/1000\n",
            "79/79 [==============================] - 0s 449us/step - loss: 6.3511e-04 - val_loss: 0.0016\n",
            "Epoch 818/1000\n",
            "79/79 [==============================] - 0s 479us/step - loss: 6.5164e-04 - val_loss: 0.0016\n",
            "Epoch 819/1000\n",
            "79/79 [==============================] - 0s 470us/step - loss: 6.3640e-04 - val_loss: 0.0017\n",
            "Epoch 820/1000\n",
            "79/79 [==============================] - 0s 432us/step - loss: 6.2534e-04 - val_loss: 0.0016\n",
            "Epoch 821/1000\n",
            "79/79 [==============================] - 0s 427us/step - loss: 6.4949e-04 - val_loss: 0.0017\n",
            "Epoch 822/1000\n",
            "79/79 [==============================] - 0s 458us/step - loss: 6.2137e-04 - val_loss: 0.0017\n",
            "Epoch 823/1000\n",
            "79/79 [==============================] - 0s 542us/step - loss: 6.3161e-04 - val_loss: 0.0016\n",
            "Epoch 824/1000\n",
            "79/79 [==============================] - 0s 459us/step - loss: 6.1895e-04 - val_loss: 0.0017\n",
            "Epoch 825/1000\n",
            "79/79 [==============================] - 0s 486us/step - loss: 6.4164e-04 - val_loss: 0.0016\n",
            "Epoch 826/1000\n",
            "79/79 [==============================] - 0s 411us/step - loss: 6.1377e-04 - val_loss: 0.0016\n",
            "Epoch 827/1000\n",
            "79/79 [==============================] - 0s 421us/step - loss: 6.4213e-04 - val_loss: 0.0017\n",
            "Epoch 828/1000\n",
            "79/79 [==============================] - 0s 403us/step - loss: 6.1755e-04 - val_loss: 0.0017\n",
            "Epoch 829/1000\n",
            "79/79 [==============================] - 0s 439us/step - loss: 6.2563e-04 - val_loss: 0.0016\n",
            "Epoch 830/1000\n",
            "79/79 [==============================] - 0s 513us/step - loss: 6.1930e-04 - val_loss: 0.0017\n",
            "Epoch 831/1000\n",
            "79/79 [==============================] - 0s 416us/step - loss: 6.4196e-04 - val_loss: 0.0016\n",
            "Epoch 832/1000\n",
            "79/79 [==============================] - 0s 403us/step - loss: 6.0509e-04 - val_loss: 0.0016\n",
            "Epoch 833/1000\n",
            "79/79 [==============================] - 0s 462us/step - loss: 6.1022e-04 - val_loss: 0.0016\n",
            "Epoch 834/1000\n",
            "79/79 [==============================] - 0s 424us/step - loss: 6.1024e-04 - val_loss: 0.0016\n",
            "Epoch 835/1000\n",
            "79/79 [==============================] - 0s 454us/step - loss: 6.0577e-04 - val_loss: 0.0016\n",
            "Epoch 836/1000\n",
            "79/79 [==============================] - 0s 529us/step - loss: 6.0443e-04 - val_loss: 0.0016\n",
            "Epoch 837/1000\n",
            "79/79 [==============================] - 0s 496us/step - loss: 6.0716e-04 - val_loss: 0.0016\n",
            "Epoch 838/1000\n",
            "79/79 [==============================] - 0s 440us/step - loss: 6.0137e-04 - val_loss: 0.0016\n",
            "Epoch 839/1000\n",
            "79/79 [==============================] - 0s 467us/step - loss: 6.1096e-04 - val_loss: 0.0016\n",
            "Epoch 840/1000\n",
            "79/79 [==============================] - 0s 405us/step - loss: 6.0935e-04 - val_loss: 0.0016\n",
            "Epoch 841/1000\n",
            "79/79 [==============================] - 0s 517us/step - loss: 6.1142e-04 - val_loss: 0.0016\n",
            "Epoch 842/1000\n",
            "79/79 [==============================] - 0s 407us/step - loss: 6.0300e-04 - val_loss: 0.0016\n",
            "Epoch 843/1000\n",
            "79/79 [==============================] - 0s 464us/step - loss: 5.9945e-04 - val_loss: 0.0016\n",
            "Epoch 844/1000\n",
            "79/79 [==============================] - 0s 543us/step - loss: 5.9906e-04 - val_loss: 0.0016\n",
            "Epoch 845/1000\n",
            "79/79 [==============================] - 0s 500us/step - loss: 5.9327e-04 - val_loss: 0.0016\n",
            "Epoch 846/1000\n",
            "79/79 [==============================] - 0s 406us/step - loss: 6.0306e-04 - val_loss: 0.0016\n",
            "Epoch 847/1000\n",
            "79/79 [==============================] - 0s 456us/step - loss: 5.9999e-04 - val_loss: 0.0016\n",
            "Epoch 848/1000\n",
            "79/79 [==============================] - 0s 421us/step - loss: 5.8796e-04 - val_loss: 0.0016\n",
            "Epoch 849/1000\n",
            "79/79 [==============================] - 0s 463us/step - loss: 5.9709e-04 - val_loss: 0.0016\n",
            "Epoch 850/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 5.9857e-04 - val_loss: 0.0016\n",
            "Epoch 851/1000\n",
            "79/79 [==============================] - 0s 456us/step - loss: 5.9802e-04 - val_loss: 0.0016\n",
            "Epoch 852/1000\n",
            "79/79 [==============================] - 0s 438us/step - loss: 5.8680e-04 - val_loss: 0.0016\n",
            "Epoch 853/1000\n",
            "79/79 [==============================] - 0s 645us/step - loss: 5.8963e-04 - val_loss: 0.0016\n",
            "Epoch 854/1000\n",
            "79/79 [==============================] - 0s 417us/step - loss: 5.8739e-04 - val_loss: 0.0016\n",
            "Epoch 855/1000\n",
            "79/79 [==============================] - 0s 433us/step - loss: 5.9025e-04 - val_loss: 0.0016\n",
            "Epoch 856/1000\n",
            "79/79 [==============================] - 0s 410us/step - loss: 5.8538e-04 - val_loss: 0.0016\n",
            "Epoch 857/1000\n",
            "79/79 [==============================] - 0s 463us/step - loss: 5.8643e-04 - val_loss: 0.0016\n",
            "Epoch 858/1000\n",
            "79/79 [==============================] - 0s 522us/step - loss: 5.8482e-04 - val_loss: 0.0016\n",
            "Epoch 859/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 5.8046e-04 - val_loss: 0.0016\n",
            "Epoch 860/1000\n",
            "79/79 [==============================] - 0s 427us/step - loss: 5.8755e-04 - val_loss: 0.0015\n",
            "Epoch 861/1000\n",
            "79/79 [==============================] - 0s 395us/step - loss: 5.8333e-04 - val_loss: 0.0016\n",
            "Epoch 862/1000\n",
            "79/79 [==============================] - 0s 463us/step - loss: 5.9503e-04 - val_loss: 0.0015\n",
            "Epoch 863/1000\n",
            "79/79 [==============================] - 0s 422us/step - loss: 5.7883e-04 - val_loss: 0.0016\n",
            "Epoch 864/1000\n",
            "79/79 [==============================] - 0s 424us/step - loss: 5.8923e-04 - val_loss: 0.0016\n",
            "Epoch 865/1000\n",
            "79/79 [==============================] - 0s 687us/step - loss: 5.7772e-04 - val_loss: 0.0016\n",
            "Epoch 866/1000\n",
            "79/79 [==============================] - 0s 487us/step - loss: 5.8664e-04 - val_loss: 0.0016\n",
            "Epoch 867/1000\n",
            "79/79 [==============================] - 0s 479us/step - loss: 5.9154e-04 - val_loss: 0.0015\n",
            "Epoch 868/1000\n",
            "79/79 [==============================] - 0s 419us/step - loss: 5.7790e-04 - val_loss: 0.0016\n",
            "Epoch 869/1000\n",
            "79/79 [==============================] - 0s 621us/step - loss: 5.7041e-04 - val_loss: 0.0015\n",
            "Epoch 870/1000\n",
            "79/79 [==============================] - 0s 418us/step - loss: 5.7057e-04 - val_loss: 0.0015\n",
            "Epoch 871/1000\n",
            "79/79 [==============================] - 0s 409us/step - loss: 5.8498e-04 - val_loss: 0.0015\n",
            "Epoch 872/1000\n",
            "79/79 [==============================] - 0s 402us/step - loss: 5.8846e-04 - val_loss: 0.0017\n",
            "Epoch 873/1000\n",
            "79/79 [==============================] - 0s 489us/step - loss: 5.8884e-04 - val_loss: 0.0015\n",
            "Epoch 874/1000\n",
            "79/79 [==============================] - 0s 469us/step - loss: 5.6520e-04 - val_loss: 0.0015\n",
            "Epoch 875/1000\n",
            "79/79 [==============================] - 0s 461us/step - loss: 5.6505e-04 - val_loss: 0.0015\n",
            "Epoch 876/1000\n",
            "79/79 [==============================] - 0s 402us/step - loss: 5.6238e-04 - val_loss: 0.0015\n",
            "Epoch 877/1000\n",
            "79/79 [==============================] - 0s 403us/step - loss: 5.6267e-04 - val_loss: 0.0015\n",
            "Epoch 878/1000\n",
            "79/79 [==============================] - 0s 464us/step - loss: 5.7167e-04 - val_loss: 0.0016\n",
            "Epoch 879/1000\n",
            "79/79 [==============================] - 0s 461us/step - loss: 5.6924e-04 - val_loss: 0.0015\n",
            "Epoch 880/1000\n",
            "79/79 [==============================] - 0s 386us/step - loss: 5.6490e-04 - val_loss: 0.0015\n",
            "Epoch 881/1000\n",
            "79/79 [==============================] - 0s 402us/step - loss: 5.6249e-04 - val_loss: 0.0015\n",
            "Epoch 882/1000\n",
            "79/79 [==============================] - 0s 400us/step - loss: 5.6007e-04 - val_loss: 0.0015\n",
            "Epoch 883/1000\n",
            "79/79 [==============================] - 0s 435us/step - loss: 5.5928e-04 - val_loss: 0.0015\n",
            "Epoch 884/1000\n",
            "79/79 [==============================] - 0s 416us/step - loss: 5.5619e-04 - val_loss: 0.0015\n",
            "Epoch 885/1000\n",
            "79/79 [==============================] - 0s 463us/step - loss: 5.5521e-04 - val_loss: 0.0015\n",
            "Epoch 886/1000\n",
            "79/79 [==============================] - 0s 543us/step - loss: 5.5608e-04 - val_loss: 0.0015\n",
            "Epoch 887/1000\n",
            "79/79 [==============================] - 0s 487us/step - loss: 5.5009e-04 - val_loss: 0.0015\n",
            "Epoch 888/1000\n",
            "79/79 [==============================] - 0s 449us/step - loss: 5.5699e-04 - val_loss: 0.0015\n",
            "Epoch 889/1000\n",
            "79/79 [==============================] - 0s 441us/step - loss: 5.5069e-04 - val_loss: 0.0015\n",
            "Epoch 890/1000\n",
            "79/79 [==============================] - 0s 479us/step - loss: 5.6709e-04 - val_loss: 0.0015\n",
            "Epoch 891/1000\n",
            "79/79 [==============================] - 0s 395us/step - loss: 5.5469e-04 - val_loss: 0.0015\n",
            "Epoch 892/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 5.5099e-04 - val_loss: 0.0015\n",
            "Epoch 893/1000\n",
            "79/79 [==============================] - 0s 382us/step - loss: 5.5251e-04 - val_loss: 0.0015\n",
            "Epoch 894/1000\n",
            "79/79 [==============================] - 0s 524us/step - loss: 5.4442e-04 - val_loss: 0.0015\n",
            "Epoch 895/1000\n",
            "79/79 [==============================] - 0s 445us/step - loss: 5.6896e-04 - val_loss: 0.0015\n",
            "Epoch 896/1000\n",
            "79/79 [==============================] - 0s 455us/step - loss: 5.5470e-04 - val_loss: 0.0015\n",
            "Epoch 897/1000\n",
            "79/79 [==============================] - 0s 507us/step - loss: 5.4419e-04 - val_loss: 0.0015\n",
            "Epoch 898/1000\n",
            "79/79 [==============================] - 0s 487us/step - loss: 5.4792e-04 - val_loss: 0.0017\n",
            "Epoch 899/1000\n",
            "79/79 [==============================] - 0s 454us/step - loss: 5.4480e-04 - val_loss: 0.0015\n",
            "Epoch 900/1000\n",
            "79/79 [==============================] - 0s 482us/step - loss: 5.4105e-04 - val_loss: 0.0015\n",
            "Epoch 901/1000\n",
            "79/79 [==============================] - 0s 478us/step - loss: 5.3886e-04 - val_loss: 0.0015\n",
            "Epoch 902/1000\n",
            "79/79 [==============================] - 0s 484us/step - loss: 5.3763e-04 - val_loss: 0.0015\n",
            "Epoch 903/1000\n",
            "79/79 [==============================] - 0s 426us/step - loss: 5.3779e-04 - val_loss: 0.0015\n",
            "Epoch 904/1000\n",
            "79/79 [==============================] - 0s 452us/step - loss: 5.3971e-04 - val_loss: 0.0015\n",
            "Epoch 905/1000\n",
            "79/79 [==============================] - 0s 520us/step - loss: 5.3234e-04 - val_loss: 0.0015\n",
            "Epoch 906/1000\n",
            "79/79 [==============================] - 0s 547us/step - loss: 5.3240e-04 - val_loss: 0.0015\n",
            "Epoch 907/1000\n",
            "79/79 [==============================] - 0s 445us/step - loss: 5.3177e-04 - val_loss: 0.0015\n",
            "Epoch 908/1000\n",
            "79/79 [==============================] - 0s 467us/step - loss: 5.2794e-04 - val_loss: 0.0014\n",
            "Epoch 909/1000\n",
            "79/79 [==============================] - 0s 397us/step - loss: 5.3109e-04 - val_loss: 0.0014\n",
            "Epoch 910/1000\n",
            "79/79 [==============================] - 0s 508us/step - loss: 5.2841e-04 - val_loss: 0.0015\n",
            "Epoch 911/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 5.3706e-04 - val_loss: 0.0014\n",
            "Epoch 912/1000\n",
            "79/79 [==============================] - 0s 414us/step - loss: 5.3216e-04 - val_loss: 0.0014\n",
            "Epoch 913/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 5.2658e-04 - val_loss: 0.0014\n",
            "Epoch 914/1000\n",
            "79/79 [==============================] - 0s 423us/step - loss: 5.3223e-04 - val_loss: 0.0015\n",
            "Epoch 915/1000\n",
            "79/79 [==============================] - 0s 412us/step - loss: 5.4001e-04 - val_loss: 0.0015\n",
            "Epoch 916/1000\n",
            "79/79 [==============================] - 0s 431us/step - loss: 5.2372e-04 - val_loss: 0.0015\n",
            "Epoch 917/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 5.3101e-04 - val_loss: 0.0015\n",
            "Epoch 918/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 5.1786e-04 - val_loss: 0.0014\n",
            "Epoch 919/1000\n",
            "79/79 [==============================] - 0s 429us/step - loss: 5.2836e-04 - val_loss: 0.0014\n",
            "Epoch 920/1000\n",
            "79/79 [==============================] - 0s 477us/step - loss: 5.1755e-04 - val_loss: 0.0015\n",
            "Epoch 921/1000\n",
            "79/79 [==============================] - 0s 475us/step - loss: 5.2435e-04 - val_loss: 0.0015\n",
            "Epoch 922/1000\n",
            "79/79 [==============================] - 0s 457us/step - loss: 5.2178e-04 - val_loss: 0.0014\n",
            "Epoch 923/1000\n",
            "79/79 [==============================] - 0s 494us/step - loss: 5.1857e-04 - val_loss: 0.0014\n",
            "Epoch 924/1000\n",
            "79/79 [==============================] - 0s 500us/step - loss: 5.2686e-04 - val_loss: 0.0015\n",
            "Epoch 925/1000\n",
            "79/79 [==============================] - 0s 450us/step - loss: 5.3459e-04 - val_loss: 0.0014\n",
            "Epoch 926/1000\n",
            "79/79 [==============================] - 0s 515us/step - loss: 5.1205e-04 - val_loss: 0.0014\n",
            "Epoch 927/1000\n",
            "79/79 [==============================] - 0s 533us/step - loss: 5.1065e-04 - val_loss: 0.0015\n",
            "Epoch 928/1000\n",
            "79/79 [==============================] - 0s 484us/step - loss: 5.2540e-04 - val_loss: 0.0015\n",
            "Epoch 929/1000\n",
            "79/79 [==============================] - 0s 426us/step - loss: 5.2601e-04 - val_loss: 0.0014\n",
            "Epoch 930/1000\n",
            "79/79 [==============================] - 0s 491us/step - loss: 5.2828e-04 - val_loss: 0.0015\n",
            "Epoch 931/1000\n",
            "79/79 [==============================] - 0s 462us/step - loss: 5.1194e-04 - val_loss: 0.0014\n",
            "Epoch 932/1000\n",
            "79/79 [==============================] - 0s 416us/step - loss: 5.0948e-04 - val_loss: 0.0014\n",
            "Epoch 933/1000\n",
            "79/79 [==============================] - 0s 437us/step - loss: 5.1087e-04 - val_loss: 0.0014\n",
            "Epoch 934/1000\n",
            "79/79 [==============================] - 0s 399us/step - loss: 5.1470e-04 - val_loss: 0.0014\n",
            "Epoch 935/1000\n",
            "79/79 [==============================] - 0s 487us/step - loss: 5.0708e-04 - val_loss: 0.0014\n",
            "Epoch 936/1000\n",
            "79/79 [==============================] - 0s 446us/step - loss: 5.1706e-04 - val_loss: 0.0014\n",
            "Epoch 937/1000\n",
            "79/79 [==============================] - 0s 406us/step - loss: 5.0650e-04 - val_loss: 0.0015\n",
            "Epoch 938/1000\n",
            "79/79 [==============================] - 0s 601us/step - loss: 5.0770e-04 - val_loss: 0.0014\n",
            "Epoch 939/1000\n",
            "79/79 [==============================] - 0s 485us/step - loss: 4.9906e-04 - val_loss: 0.0014\n",
            "Epoch 940/1000\n",
            "79/79 [==============================] - 0s 501us/step - loss: 5.1275e-04 - val_loss: 0.0014\n",
            "Epoch 941/1000\n",
            "79/79 [==============================] - 0s 478us/step - loss: 5.0274e-04 - val_loss: 0.0014\n",
            "Epoch 942/1000\n",
            "79/79 [==============================] - 0s 454us/step - loss: 5.0361e-04 - val_loss: 0.0014\n",
            "Epoch 943/1000\n",
            "79/79 [==============================] - 0s 407us/step - loss: 5.0193e-04 - val_loss: 0.0014\n",
            "Epoch 944/1000\n",
            "79/79 [==============================] - 0s 485us/step - loss: 5.2312e-04 - val_loss: 0.0014\n",
            "Epoch 945/1000\n",
            "79/79 [==============================] - 0s 491us/step - loss: 5.0526e-04 - val_loss: 0.0015\n",
            "Epoch 946/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 5.0044e-04 - val_loss: 0.0014\n",
            "Epoch 947/1000\n",
            "79/79 [==============================] - 0s 442us/step - loss: 4.9466e-04 - val_loss: 0.0014\n",
            "Epoch 948/1000\n",
            "79/79 [==============================] - 0s 508us/step - loss: 5.0361e-04 - val_loss: 0.0014\n",
            "Epoch 949/1000\n",
            "79/79 [==============================] - 0s 514us/step - loss: 5.0135e-04 - val_loss: 0.0014\n",
            "Epoch 950/1000\n",
            "79/79 [==============================] - 0s 549us/step - loss: 4.9496e-04 - val_loss: 0.0014\n",
            "Epoch 951/1000\n",
            "79/79 [==============================] - 0s 427us/step - loss: 5.0528e-04 - val_loss: 0.0014\n",
            "Epoch 952/1000\n",
            "79/79 [==============================] - 0s 462us/step - loss: 5.1075e-04 - val_loss: 0.0014\n",
            "Epoch 953/1000\n",
            "79/79 [==============================] - 0s 444us/step - loss: 4.9226e-04 - val_loss: 0.0014\n",
            "Epoch 954/1000\n",
            "79/79 [==============================] - 0s 467us/step - loss: 5.0490e-04 - val_loss: 0.0014\n",
            "Epoch 955/1000\n",
            "79/79 [==============================] - 0s 395us/step - loss: 4.9458e-04 - val_loss: 0.0014\n",
            "Epoch 956/1000\n",
            "79/79 [==============================] - 0s 403us/step - loss: 4.9946e-04 - val_loss: 0.0014\n",
            "Epoch 957/1000\n",
            "79/79 [==============================] - 0s 483us/step - loss: 4.9295e-04 - val_loss: 0.0014\n",
            "Epoch 958/1000\n",
            "79/79 [==============================] - 0s 396us/step - loss: 4.8755e-04 - val_loss: 0.0014\n",
            "Epoch 959/1000\n",
            "79/79 [==============================] - 0s 407us/step - loss: 4.8936e-04 - val_loss: 0.0014\n",
            "Epoch 960/1000\n",
            "79/79 [==============================] - 0s 410us/step - loss: 4.8474e-04 - val_loss: 0.0014\n",
            "Epoch 961/1000\n",
            "79/79 [==============================] - 0s 419us/step - loss: 4.8796e-04 - val_loss: 0.0014\n",
            "Epoch 962/1000\n",
            "79/79 [==============================] - 0s 495us/step - loss: 4.9541e-04 - val_loss: 0.0014\n",
            "Epoch 963/1000\n",
            "79/79 [==============================] - 0s 511us/step - loss: 4.8855e-04 - val_loss: 0.0014\n",
            "Epoch 964/1000\n",
            "79/79 [==============================] - 0s 503us/step - loss: 4.8305e-04 - val_loss: 0.0014\n",
            "Epoch 965/1000\n",
            "79/79 [==============================] - 0s 459us/step - loss: 4.8848e-04 - val_loss: 0.0014\n",
            "Epoch 966/1000\n",
            "79/79 [==============================] - 0s 402us/step - loss: 4.8658e-04 - val_loss: 0.0014\n",
            "Epoch 967/1000\n",
            "79/79 [==============================] - 0s 407us/step - loss: 4.8412e-04 - val_loss: 0.0013\n",
            "Epoch 968/1000\n",
            "79/79 [==============================] - 0s 486us/step - loss: 4.9404e-04 - val_loss: 0.0014\n",
            "Epoch 969/1000\n",
            "79/79 [==============================] - 0s 478us/step - loss: 4.8542e-04 - val_loss: 0.0013\n",
            "Epoch 970/1000\n",
            "79/79 [==============================] - 0s 420us/step - loss: 4.8140e-04 - val_loss: 0.0013\n",
            "Epoch 971/1000\n",
            "79/79 [==============================] - 0s 436us/step - loss: 4.9243e-04 - val_loss: 0.0014\n",
            "Epoch 972/1000\n",
            "79/79 [==============================] - 0s 416us/step - loss: 4.8185e-04 - val_loss: 0.0013\n",
            "Epoch 973/1000\n",
            "79/79 [==============================] - 0s 398us/step - loss: 4.8568e-04 - val_loss: 0.0013\n",
            "Epoch 974/1000\n",
            "79/79 [==============================] - 0s 437us/step - loss: 4.8846e-04 - val_loss: 0.0013\n",
            "Epoch 975/1000\n",
            "79/79 [==============================] - 0s 455us/step - loss: 4.7621e-04 - val_loss: 0.0014\n",
            "Epoch 976/1000\n",
            "79/79 [==============================] - 0s 433us/step - loss: 4.7955e-04 - val_loss: 0.0013\n",
            "Epoch 977/1000\n",
            "79/79 [==============================] - 0s 431us/step - loss: 4.9013e-04 - val_loss: 0.0013\n",
            "Epoch 978/1000\n",
            "79/79 [==============================] - 0s 476us/step - loss: 4.7875e-04 - val_loss: 0.0014\n",
            "Epoch 979/1000\n",
            "79/79 [==============================] - 0s 522us/step - loss: 4.7333e-04 - val_loss: 0.0013\n",
            "Epoch 980/1000\n",
            "79/79 [==============================] - 0s 480us/step - loss: 4.8376e-04 - val_loss: 0.0013\n",
            "Epoch 981/1000\n",
            "79/79 [==============================] - 0s 517us/step - loss: 4.7426e-04 - val_loss: 0.0014\n",
            "Epoch 982/1000\n",
            "79/79 [==============================] - 0s 521us/step - loss: 4.7802e-04 - val_loss: 0.0013\n",
            "Epoch 983/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 4.7084e-04 - val_loss: 0.0013\n",
            "Epoch 984/1000\n",
            "79/79 [==============================] - 0s 486us/step - loss: 4.6944e-04 - val_loss: 0.0013\n",
            "Epoch 985/1000\n",
            "79/79 [==============================] - 0s 428us/step - loss: 4.8287e-04 - val_loss: 0.0013\n",
            "Epoch 986/1000\n",
            "79/79 [==============================] - 0s 426us/step - loss: 4.5957e-04 - val_loss: 0.0014\n",
            "Epoch 987/1000\n",
            "79/79 [==============================] - 0s 485us/step - loss: 4.7447e-04 - val_loss: 0.0013\n",
            "Epoch 988/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 4.6425e-04 - val_loss: 0.0013\n",
            "Epoch 989/1000\n",
            "79/79 [==============================] - 0s 434us/step - loss: 4.7718e-04 - val_loss: 0.0013\n",
            "Epoch 990/1000\n",
            "79/79 [==============================] - 0s 451us/step - loss: 4.7171e-04 - val_loss: 0.0014\n",
            "Epoch 991/1000\n",
            "79/79 [==============================] - 0s 422us/step - loss: 4.7202e-04 - val_loss: 0.0013\n",
            "Epoch 992/1000\n",
            "79/79 [==============================] - 0s 422us/step - loss: 4.6463e-04 - val_loss: 0.0013\n",
            "Epoch 993/1000\n",
            "79/79 [==============================] - 0s 448us/step - loss: 4.6380e-04 - val_loss: 0.0013\n",
            "Epoch 994/1000\n",
            "79/79 [==============================] - 0s 430us/step - loss: 4.8349e-04 - val_loss: 0.0014\n",
            "Epoch 995/1000\n",
            "79/79 [==============================] - 0s 561us/step - loss: 4.6360e-04 - val_loss: 0.0013\n",
            "Epoch 996/1000\n",
            "79/79 [==============================] - 0s 421us/step - loss: 4.7115e-04 - val_loss: 0.0013\n",
            "Epoch 997/1000\n",
            "79/79 [==============================] - 0s 392us/step - loss: 4.6130e-04 - val_loss: 0.0013\n",
            "Epoch 998/1000\n",
            "79/79 [==============================] - 0s 445us/step - loss: 4.6075e-04 - val_loss: 0.0013\n",
            "Epoch 999/1000\n",
            "79/79 [==============================] - 0s 422us/step - loss: 4.6678e-04 - val_loss: 0.0013\n",
            "Epoch 1000/1000\n",
            "79/79 [==============================] - 0s 425us/step - loss: 4.6023e-04 - val_loss: 0.0013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc3d2f77fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVmZ0vopbY0A",
        "colab_type": "text"
      },
      "source": [
        "**RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksk1J9mlbsRF",
        "colab_type": "code",
        "outputId": "01a3a859-e20e-401d-d961-2e5f1dfbc0c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import LSTM, SimpleRNN, Dropout\n",
        "from keras.callbacks import LambdaCallback\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "import plotutil\n",
        "from plotutil import PlotCallback\n",
        "\n",
        "wandb.init(\"ml_class_rnn\")\n",
        "config = wandb.config\n",
        "\n",
        "config.repeated_predictions = False\n",
        "config.look_back = 20\n",
        "\n",
        "df = pd.read_csv('international-airline-passengers.csv')\n",
        "data = df.passengers.astype('float32').values\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-config.look_back-1):\n",
        "        a = dataset[i:(i+config.look_back)]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + config.look_back])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "data = load_data()\n",
        "    \n",
        "# normalize data to between 0 and 1\n",
        "max_val = max(data)\n",
        "min_val = min(data)\n",
        "data=(data-min_val)/(max_val-min_val)\n",
        "\n",
        "# split into train and test sets\n",
        "split = int(len(data) * 0.70)\n",
        "train = data[:split]\n",
        "test = data[split:]\n",
        "\n",
        "trainX, trainY = create_dataset(train)\n",
        "testX, testY = create_dataset(test)\n",
        "\n",
        "trainX = trainX[:, :, np.newaxis]\n",
        "testX = testX[:, :, np.newaxis]\n",
        "\n",
        "# create and fit the RNN\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(5, input_shape=(config.look_back,1 )))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss='mae', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=1000, batch_size=1, validation_data=(testX, testY),  callbacks=[WandbCallback(), PlotCallback(trainX, trainY, testX, testY, config.look_back)])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/10dimensions/ml-class-videos_time-series\" target=\"_blank\">https://app.wandb.ai/10dimensions/ml-class-videos_time-series</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/10dimensions/ml-class-videos_time-series/runs/ayxpgipp\" target=\"_blank\">https://app.wandb.ai/10dimensions/ml-class-videos_time-series/runs/ayxpgipp</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 79 samples, validate on 23 samples\n",
            "Epoch 1/1000\n",
            "79/79 [==============================] - 2s 31ms/step - loss: 0.3091 - val_loss: 0.1104\n",
            "Epoch 2/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.1071 - val_loss: 0.2403\n",
            "Epoch 3/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0814 - val_loss: 0.2045\n",
            "Epoch 4/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0724 - val_loss: 0.1075\n",
            "Epoch 5/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0655 - val_loss: 0.1037\n",
            "Epoch 6/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0605 - val_loss: 0.1039\n",
            "Epoch 7/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0597 - val_loss: 0.1046\n",
            "Epoch 8/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0575 - val_loss: 0.1022\n",
            "Epoch 9/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0552 - val_loss: 0.1077\n",
            "Epoch 10/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0558 - val_loss: 0.1028\n",
            "Epoch 11/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0578 - val_loss: 0.1017\n",
            "Epoch 12/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0535 - val_loss: 0.1075\n",
            "Epoch 13/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0545 - val_loss: 0.1035\n",
            "Epoch 14/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0535 - val_loss: 0.1059\n",
            "Epoch 15/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0574 - val_loss: 0.1000\n",
            "Epoch 16/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0546 - val_loss: 0.1009\n",
            "Epoch 17/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0521 - val_loss: 0.1007\n",
            "Epoch 18/1000\n",
            "79/79 [==============================] - 2s 28ms/step - loss: 0.0522 - val_loss: 0.1026\n",
            "Epoch 19/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0516 - val_loss: 0.1028\n",
            "Epoch 20/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0537 - val_loss: 0.1010\n",
            "Epoch 21/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0515 - val_loss: 0.0991\n",
            "Epoch 22/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0514 - val_loss: 0.1009\n",
            "Epoch 23/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0508 - val_loss: 0.1005\n",
            "Epoch 24/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0528 - val_loss: 0.1008\n",
            "Epoch 25/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0504 - val_loss: 0.1013\n",
            "Epoch 26/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0506 - val_loss: 0.0995\n",
            "Epoch 27/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0500 - val_loss: 0.1012\n",
            "Epoch 28/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0517 - val_loss: 0.1000\n",
            "Epoch 29/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0490 - val_loss: 0.0988\n",
            "Epoch 30/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0495 - val_loss: 0.0990\n",
            "Epoch 31/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0486 - val_loss: 0.1002\n",
            "Epoch 32/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0485 - val_loss: 0.0993\n",
            "Epoch 33/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0503 - val_loss: 0.0948\n",
            "Epoch 34/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0501 - val_loss: 0.0975\n",
            "Epoch 35/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0491 - val_loss: 0.0973\n",
            "Epoch 36/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0463 - val_loss: 0.1073\n",
            "Epoch 37/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0494 - val_loss: 0.0988\n",
            "Epoch 38/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0525 - val_loss: 0.0968\n",
            "Epoch 39/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0474 - val_loss: 0.0965\n",
            "Epoch 40/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0487 - val_loss: 0.0962\n",
            "Epoch 41/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0468 - val_loss: 0.1000\n",
            "Epoch 42/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0469 - val_loss: 0.0939\n",
            "Epoch 43/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0477 - val_loss: 0.0983\n",
            "Epoch 44/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0490 - val_loss: 0.0952\n",
            "Epoch 45/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0481 - val_loss: 0.0965\n",
            "Epoch 46/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0461 - val_loss: 0.0985\n",
            "Epoch 47/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0472 - val_loss: 0.0951\n",
            "Epoch 48/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0506 - val_loss: 0.0957\n",
            "Epoch 49/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0460 - val_loss: 0.0968\n",
            "Epoch 50/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0471 - val_loss: 0.0956\n",
            "Epoch 51/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0474 - val_loss: 0.0948\n",
            "Epoch 52/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0460 - val_loss: 0.0961\n",
            "Epoch 53/1000\n",
            "79/79 [==============================] - 2s 28ms/step - loss: 0.0458 - val_loss: 0.0950\n",
            "Epoch 54/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0446 - val_loss: 0.0972\n",
            "Epoch 55/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0467 - val_loss: 0.0944\n",
            "Epoch 56/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0466 - val_loss: 0.0941\n",
            "Epoch 57/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0444 - val_loss: 0.0930\n",
            "Epoch 58/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0451 - val_loss: 0.0982\n",
            "Epoch 59/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0470 - val_loss: 0.0928\n",
            "Epoch 60/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0457 - val_loss: 0.0912\n",
            "Epoch 61/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0454 - val_loss: 0.0919\n",
            "Epoch 62/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0459 - val_loss: 0.0923\n",
            "Epoch 63/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0452 - val_loss: 0.0915\n",
            "Epoch 64/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0462 - val_loss: 0.0929\n",
            "Epoch 65/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0438 - val_loss: 0.0886\n",
            "Epoch 66/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0449 - val_loss: 0.0937\n",
            "Epoch 67/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0469 - val_loss: 0.0923\n",
            "Epoch 68/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0446 - val_loss: 0.0928\n",
            "Epoch 69/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0472 - val_loss: 0.0938\n",
            "Epoch 70/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0436 - val_loss: 0.0908\n",
            "Epoch 71/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0415 - val_loss: 0.0890\n",
            "Epoch 72/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0438 - val_loss: 0.0934\n",
            "Epoch 73/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0432 - val_loss: 0.0914\n",
            "Epoch 74/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0435 - val_loss: 0.0916\n",
            "Epoch 75/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0465 - val_loss: 0.0889\n",
            "Epoch 76/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0460 - val_loss: 0.0952\n",
            "Epoch 77/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0458 - val_loss: 0.0905\n",
            "Epoch 78/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0435 - val_loss: 0.0889\n",
            "Epoch 79/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0407 - val_loss: 0.0869\n",
            "Epoch 80/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0440 - val_loss: 0.0878\n",
            "Epoch 81/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0431 - val_loss: 0.0894\n",
            "Epoch 82/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0426 - val_loss: 0.0894\n",
            "Epoch 83/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0427 - val_loss: 0.0940\n",
            "Epoch 84/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0444 - val_loss: 0.0939\n",
            "Epoch 85/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0409 - val_loss: 0.0888\n",
            "Epoch 86/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0459 - val_loss: 0.0902\n",
            "Epoch 87/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0428 - val_loss: 0.0863\n",
            "Epoch 88/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0415 - val_loss: 0.0876\n",
            "Epoch 89/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0452 - val_loss: 0.0890\n",
            "Epoch 90/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0452 - val_loss: 0.0911\n",
            "Epoch 91/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0419 - val_loss: 0.0867\n",
            "Epoch 92/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0453 - val_loss: 0.0864\n",
            "Epoch 93/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0414 - val_loss: 0.0867\n",
            "Epoch 94/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0416 - val_loss: 0.0879\n",
            "Epoch 95/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0447 - val_loss: 0.0878\n",
            "Epoch 96/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0404 - val_loss: 0.0883\n",
            "Epoch 97/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0435 - val_loss: 0.0878\n",
            "Epoch 98/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0458 - val_loss: 0.0890\n",
            "Epoch 99/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0409 - val_loss: 0.0876\n",
            "Epoch 100/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0399 - val_loss: 0.0861\n",
            "Epoch 101/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0414 - val_loss: 0.0877\n",
            "Epoch 102/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0407 - val_loss: 0.0879\n",
            "Epoch 103/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0398 - val_loss: 0.0856\n",
            "Epoch 104/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0405 - val_loss: 0.0855\n",
            "Epoch 105/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0411 - val_loss: 0.0875\n",
            "Epoch 106/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0434 - val_loss: 0.0884\n",
            "Epoch 107/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0391 - val_loss: 0.0893\n",
            "Epoch 108/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0404 - val_loss: 0.0834\n",
            "Epoch 109/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0406 - val_loss: 0.0862\n",
            "Epoch 110/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0423 - val_loss: 0.0872\n",
            "Epoch 111/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0426 - val_loss: 0.0888\n",
            "Epoch 112/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0382 - val_loss: 0.0862\n",
            "Epoch 113/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0418 - val_loss: 0.0890\n",
            "Epoch 114/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0382 - val_loss: 0.0887\n",
            "Epoch 115/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0411 - val_loss: 0.0854\n",
            "Epoch 116/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0384 - val_loss: 0.0860\n",
            "Epoch 117/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0386 - val_loss: 0.0834\n",
            "Epoch 118/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0397 - val_loss: 0.0836\n",
            "Epoch 119/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0417 - val_loss: 0.0879\n",
            "Epoch 120/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0373 - val_loss: 0.0911\n",
            "Epoch 121/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0416 - val_loss: 0.0830\n",
            "Epoch 122/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0410 - val_loss: 0.0819\n",
            "Epoch 123/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0367 - val_loss: 0.0868\n",
            "Epoch 124/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0364 - val_loss: 0.0841\n",
            "Epoch 125/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0385 - val_loss: 0.0873\n",
            "Epoch 126/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0365 - val_loss: 0.0833\n",
            "Epoch 127/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0414 - val_loss: 0.0849\n",
            "Epoch 128/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0387 - val_loss: 0.0845\n",
            "Epoch 129/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0378 - val_loss: 0.0814\n",
            "Epoch 130/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0390 - val_loss: 0.0840\n",
            "Epoch 131/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0381 - val_loss: 0.0853\n",
            "Epoch 132/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0377 - val_loss: 0.0864\n",
            "Epoch 133/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0388 - val_loss: 0.0847\n",
            "Epoch 134/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0382 - val_loss: 0.0885\n",
            "Epoch 135/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0389 - val_loss: 0.0827\n",
            "Epoch 136/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0382 - val_loss: 0.0942\n",
            "Epoch 137/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0410 - val_loss: 0.0844\n",
            "Epoch 138/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0374 - val_loss: 0.0806\n",
            "Epoch 139/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0412 - val_loss: 0.0845\n",
            "Epoch 140/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0365 - val_loss: 0.0851\n",
            "Epoch 141/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0405 - val_loss: 0.0856\n",
            "Epoch 142/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0407 - val_loss: 0.0856\n",
            "Epoch 143/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0379 - val_loss: 0.0831\n",
            "Epoch 144/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0387 - val_loss: 0.0842\n",
            "Epoch 145/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0377 - val_loss: 0.0874\n",
            "Epoch 146/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0384 - val_loss: 0.0870\n",
            "Epoch 147/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0372 - val_loss: 0.0825\n",
            "Epoch 148/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0401 - val_loss: 0.0867\n",
            "Epoch 149/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0362 - val_loss: 0.0839\n",
            "Epoch 150/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0356 - val_loss: 0.0822\n",
            "Epoch 151/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0379 - val_loss: 0.0856\n",
            "Epoch 152/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0368 - val_loss: 0.0908\n",
            "Epoch 153/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0379 - val_loss: 0.0809\n",
            "Epoch 154/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0360 - val_loss: 0.0911\n",
            "Epoch 155/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0346 - val_loss: 0.0847\n",
            "Epoch 156/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0406 - val_loss: 0.0855\n",
            "Epoch 157/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0374 - val_loss: 0.0829\n",
            "Epoch 158/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0358 - val_loss: 0.0846\n",
            "Epoch 159/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0351 - val_loss: 0.0857\n",
            "Epoch 160/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0385 - val_loss: 0.0812\n",
            "Epoch 161/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0355 - val_loss: 0.0819\n",
            "Epoch 162/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0400 - val_loss: 0.0851\n",
            "Epoch 163/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0376 - val_loss: 0.0894\n",
            "Epoch 164/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0350 - val_loss: 0.0819\n",
            "Epoch 165/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0360 - val_loss: 0.0956\n",
            "Epoch 166/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0380 - val_loss: 0.0849\n",
            "Epoch 167/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0361 - val_loss: 0.0822\n",
            "Epoch 168/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0376 - val_loss: 0.0829\n",
            "Epoch 169/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0351 - val_loss: 0.0942\n",
            "Epoch 170/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0373 - val_loss: 0.0855\n",
            "Epoch 171/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0357 - val_loss: 0.0862\n",
            "Epoch 172/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0374 - val_loss: 0.0856\n",
            "Epoch 173/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0355 - val_loss: 0.0850\n",
            "Epoch 174/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0381 - val_loss: 0.0939\n",
            "Epoch 175/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0373 - val_loss: 0.0837\n",
            "Epoch 176/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0372 - val_loss: 0.0797\n",
            "Epoch 177/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0391 - val_loss: 0.0814\n",
            "Epoch 178/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0377 - val_loss: 0.0826\n",
            "Epoch 179/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0373 - val_loss: 0.0838\n",
            "Epoch 180/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0350 - val_loss: 0.0786\n",
            "Epoch 181/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0365 - val_loss: 0.0828\n",
            "Epoch 182/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0355 - val_loss: 0.0831\n",
            "Epoch 183/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0352 - val_loss: 0.0828\n",
            "Epoch 184/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0341 - val_loss: 0.0857\n",
            "Epoch 185/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0382 - val_loss: 0.0837\n",
            "Epoch 186/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0370 - val_loss: 0.0830\n",
            "Epoch 187/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0347 - val_loss: 0.0833\n",
            "Epoch 188/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0350 - val_loss: 0.0851\n",
            "Epoch 189/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0355 - val_loss: 0.0816\n",
            "Epoch 190/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0359 - val_loss: 0.0863\n",
            "Epoch 191/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0375 - val_loss: 0.0829\n",
            "Epoch 192/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0359 - val_loss: 0.0804\n",
            "Epoch 193/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0360 - val_loss: 0.0854\n",
            "Epoch 194/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0367 - val_loss: 0.0856\n",
            "Epoch 195/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0340 - val_loss: 0.0808\n",
            "Epoch 196/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0356 - val_loss: 0.0851\n",
            "Epoch 197/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0353 - val_loss: 0.0809\n",
            "Epoch 198/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0372 - val_loss: 0.0819\n",
            "Epoch 199/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0346 - val_loss: 0.0947\n",
            "Epoch 200/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0370 - val_loss: 0.0880\n",
            "Epoch 201/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0377 - val_loss: 0.0886\n",
            "Epoch 202/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0348 - val_loss: 0.0816\n",
            "Epoch 203/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0364 - val_loss: 0.0832\n",
            "Epoch 204/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0340 - val_loss: 0.0905\n",
            "Epoch 205/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0352 - val_loss: 0.0893\n",
            "Epoch 206/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0356 - val_loss: 0.0824\n",
            "Epoch 207/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0400 - val_loss: 0.0776\n",
            "Epoch 208/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0359 - val_loss: 0.0828\n",
            "Epoch 209/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0377 - val_loss: 0.0842\n",
            "Epoch 210/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0346 - val_loss: 0.0798\n",
            "Epoch 211/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0365 - val_loss: 0.0793\n",
            "Epoch 212/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0375 - val_loss: 0.0834\n",
            "Epoch 213/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0342 - val_loss: 0.0819\n",
            "Epoch 214/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0322 - val_loss: 0.0851\n",
            "Epoch 215/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0373 - val_loss: 0.0821\n",
            "Epoch 216/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0376 - val_loss: 0.0866\n",
            "Epoch 217/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0319 - val_loss: 0.0822\n",
            "Epoch 218/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0347 - val_loss: 0.0885\n",
            "Epoch 219/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0326 - val_loss: 0.0856\n",
            "Epoch 220/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0344 - val_loss: 0.0797\n",
            "Epoch 221/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0348 - val_loss: 0.0821\n",
            "Epoch 222/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0355 - val_loss: 0.0995\n",
            "Epoch 223/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0349 - val_loss: 0.0847\n",
            "Epoch 224/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0338 - val_loss: 0.0865\n",
            "Epoch 225/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0396 - val_loss: 0.0814\n",
            "Epoch 226/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0341 - val_loss: 0.0788\n",
            "Epoch 227/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0337 - val_loss: 0.0930\n",
            "Epoch 228/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0354 - val_loss: 0.0875\n",
            "Epoch 229/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0344 - val_loss: 0.0818\n",
            "Epoch 230/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0327 - val_loss: 0.0903\n",
            "Epoch 231/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0337 - val_loss: 0.0813\n",
            "Epoch 232/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0358 - val_loss: 0.0829\n",
            "Epoch 233/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0341 - val_loss: 0.0874\n",
            "Epoch 234/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0331 - val_loss: 0.0873\n",
            "Epoch 235/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0324 - val_loss: 0.0947\n",
            "Epoch 236/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0325 - val_loss: 0.0825\n",
            "Epoch 237/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0353 - val_loss: 0.0809\n",
            "Epoch 238/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0336 - val_loss: 0.0958\n",
            "Epoch 239/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0333 - val_loss: 0.0943\n",
            "Epoch 240/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0333 - val_loss: 0.0876\n",
            "Epoch 241/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0349 - val_loss: 0.0942\n",
            "Epoch 242/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0318 - val_loss: 0.0883\n",
            "Epoch 243/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0327 - val_loss: 0.0800\n",
            "Epoch 244/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0348 - val_loss: 0.0768\n",
            "Epoch 245/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0343 - val_loss: 0.0952\n",
            "Epoch 246/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0338 - val_loss: 0.0974\n",
            "Epoch 247/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0349 - val_loss: 0.0921\n",
            "Epoch 248/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0323 - val_loss: 0.0981\n",
            "Epoch 249/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0341 - val_loss: 0.0846\n",
            "Epoch 250/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0379 - val_loss: 0.0788\n",
            "Epoch 251/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0346 - val_loss: 0.0988\n",
            "Epoch 252/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0349 - val_loss: 0.0833\n",
            "Epoch 253/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0327 - val_loss: 0.0974\n",
            "Epoch 254/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0342 - val_loss: 0.0869\n",
            "Epoch 255/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0354 - val_loss: 0.0976\n",
            "Epoch 256/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0336 - val_loss: 0.0949\n",
            "Epoch 257/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0330 - val_loss: 0.0817\n",
            "Epoch 258/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0328 - val_loss: 0.0939\n",
            "Epoch 259/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0330 - val_loss: 0.0909\n",
            "Epoch 260/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0331 - val_loss: 0.0955\n",
            "Epoch 261/1000\n",
            "79/79 [==============================] - 2s 27ms/step - loss: 0.0341 - val_loss: 0.0906\n",
            "Epoch 262/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0326 - val_loss: 0.0852\n",
            "Epoch 263/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0378 - val_loss: 0.0912\n",
            "Epoch 264/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0327 - val_loss: 0.0953\n",
            "Epoch 265/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0331 - val_loss: 0.1001\n",
            "Epoch 266/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0340 - val_loss: 0.1087\n",
            "Epoch 267/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0336 - val_loss: 0.0869\n",
            "Epoch 268/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0323 - val_loss: 0.0945\n",
            "Epoch 269/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0299 - val_loss: 0.0878\n",
            "Epoch 270/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0320 - val_loss: 0.0913\n",
            "Epoch 271/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0352 - val_loss: 0.1025\n",
            "Epoch 272/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0371 - val_loss: 0.0953\n",
            "Epoch 273/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0353 - val_loss: 0.0991\n",
            "Epoch 274/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0333 - val_loss: 0.0813\n",
            "Epoch 275/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0349 - val_loss: 0.0934\n",
            "Epoch 276/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0309 - val_loss: 0.0942\n",
            "Epoch 277/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0342 - val_loss: 0.0811\n",
            "Epoch 278/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0335 - val_loss: 0.0880\n",
            "Epoch 279/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0320 - val_loss: 0.0839\n",
            "Epoch 280/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0322 - val_loss: 0.0875\n",
            "Epoch 281/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0320 - val_loss: 0.1003\n",
            "Epoch 282/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0342 - val_loss: 0.0804\n",
            "Epoch 283/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0350 - val_loss: 0.0805\n",
            "Epoch 284/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0323 - val_loss: 0.0918\n",
            "Epoch 285/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0323 - val_loss: 0.0858\n",
            "Epoch 286/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0322 - val_loss: 0.1028\n",
            "Epoch 287/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0331 - val_loss: 0.1109\n",
            "Epoch 288/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0357 - val_loss: 0.0984\n",
            "Epoch 289/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0331 - val_loss: 0.0997\n",
            "Epoch 290/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0339 - val_loss: 0.0887\n",
            "Epoch 291/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0333 - val_loss: 0.0950\n",
            "Epoch 292/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0320 - val_loss: 0.0961\n",
            "Epoch 293/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0323 - val_loss: 0.1095\n",
            "Epoch 294/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0331 - val_loss: 0.0854\n",
            "Epoch 295/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0311 - val_loss: 0.0926\n",
            "Epoch 296/1000\n",
            "79/79 [==============================] - 2s 28ms/step - loss: 0.0331 - val_loss: 0.0945\n",
            "Epoch 297/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0337 - val_loss: 0.1043\n",
            "Epoch 298/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0331 - val_loss: 0.0982\n",
            "Epoch 299/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0330 - val_loss: 0.0955\n",
            "Epoch 300/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0308 - val_loss: 0.1037\n",
            "Epoch 301/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0325 - val_loss: 0.1063\n",
            "Epoch 302/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0317 - val_loss: 0.0890\n",
            "Epoch 303/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0319 - val_loss: 0.0975\n",
            "Epoch 304/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0323 - val_loss: 0.0962\n",
            "Epoch 305/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0305 - val_loss: 0.0990\n",
            "Epoch 306/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0326 - val_loss: 0.0915\n",
            "Epoch 307/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0325 - val_loss: 0.1068\n",
            "Epoch 308/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0332 - val_loss: 0.1007\n",
            "Epoch 309/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0332 - val_loss: 0.1010\n",
            "Epoch 310/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0321 - val_loss: 0.0851\n",
            "Epoch 311/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0329 - val_loss: 0.0892\n",
            "Epoch 312/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0307 - val_loss: 0.0981\n",
            "Epoch 313/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0312 - val_loss: 0.0943\n",
            "Epoch 314/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0296 - val_loss: 0.1054\n",
            "Epoch 315/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0328 - val_loss: 0.0970\n",
            "Epoch 316/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0344 - val_loss: 0.0899\n",
            "Epoch 317/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0323 - val_loss: 0.0941\n",
            "Epoch 318/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0324 - val_loss: 0.0880\n",
            "Epoch 319/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0331 - val_loss: 0.0989\n",
            "Epoch 320/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0324 - val_loss: 0.0943\n",
            "Epoch 321/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0319 - val_loss: 0.0989\n",
            "Epoch 322/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0318 - val_loss: 0.0948\n",
            "Epoch 323/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0329 - val_loss: 0.0976\n",
            "Epoch 324/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0329 - val_loss: 0.0897\n",
            "Epoch 325/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0312 - val_loss: 0.0954\n",
            "Epoch 326/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0299 - val_loss: 0.1050\n",
            "Epoch 327/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0321 - val_loss: 0.0852\n",
            "Epoch 328/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0306 - val_loss: 0.1044\n",
            "Epoch 329/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0314 - val_loss: 0.0896\n",
            "Epoch 330/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0315 - val_loss: 0.0856\n",
            "Epoch 331/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0361 - val_loss: 0.0946\n",
            "Epoch 332/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0301 - val_loss: 0.1063\n",
            "Epoch 333/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0314 - val_loss: 0.1059\n",
            "Epoch 334/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0312 - val_loss: 0.1032\n",
            "Epoch 335/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0311 - val_loss: 0.1087\n",
            "Epoch 336/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0334 - val_loss: 0.1066\n",
            "Epoch 337/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0307 - val_loss: 0.1159\n",
            "Epoch 338/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0303 - val_loss: 0.0967\n",
            "Epoch 339/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0317 - val_loss: 0.0836\n",
            "Epoch 340/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0328 - val_loss: 0.1067\n",
            "Epoch 341/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0306 - val_loss: 0.0949\n",
            "Epoch 342/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0320 - val_loss: 0.0977\n",
            "Epoch 343/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0315 - val_loss: 0.0988\n",
            "Epoch 344/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0327 - val_loss: 0.1009\n",
            "Epoch 345/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0297 - val_loss: 0.1182\n",
            "Epoch 346/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0326 - val_loss: 0.1024\n",
            "Epoch 347/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0337 - val_loss: 0.1042\n",
            "Epoch 348/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0303 - val_loss: 0.0999\n",
            "Epoch 349/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0315 - val_loss: 0.1098\n",
            "Epoch 350/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0329 - val_loss: 0.1217\n",
            "Epoch 351/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0335 - val_loss: 0.1103\n",
            "Epoch 352/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0321 - val_loss: 0.1029\n",
            "Epoch 353/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0294 - val_loss: 0.0895\n",
            "Epoch 354/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0348 - val_loss: 0.0961\n",
            "Epoch 355/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0306 - val_loss: 0.0918\n",
            "Epoch 356/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0309 - val_loss: 0.0959\n",
            "Epoch 357/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0302 - val_loss: 0.1004\n",
            "Epoch 358/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0306 - val_loss: 0.0986\n",
            "Epoch 359/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0290 - val_loss: 0.1008\n",
            "Epoch 360/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0308 - val_loss: 0.0982\n",
            "Epoch 361/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0298 - val_loss: 0.0983\n",
            "Epoch 362/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0312 - val_loss: 0.1023\n",
            "Epoch 363/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0316 - val_loss: 0.1031\n",
            "Epoch 364/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0298 - val_loss: 0.1026\n",
            "Epoch 365/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0306 - val_loss: 0.0969\n",
            "Epoch 366/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0328 - val_loss: 0.1170\n",
            "Epoch 367/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0324 - val_loss: 0.1063\n",
            "Epoch 368/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0306 - val_loss: 0.1091\n",
            "Epoch 369/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0338 - val_loss: 0.1066\n",
            "Epoch 370/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0316 - val_loss: 0.0980\n",
            "Epoch 371/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0322 - val_loss: 0.1028\n",
            "Epoch 372/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0291 - val_loss: 0.1073\n",
            "Epoch 373/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0318 - val_loss: 0.1140\n",
            "Epoch 374/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0315 - val_loss: 0.0980\n",
            "Epoch 375/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0314 - val_loss: 0.0937\n",
            "Epoch 376/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0300 - val_loss: 0.0982\n",
            "Epoch 377/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0339 - val_loss: 0.1101\n",
            "Epoch 378/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0318 - val_loss: 0.0954\n",
            "Epoch 379/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0349 - val_loss: 0.1112\n",
            "Epoch 380/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0302 - val_loss: 0.0951\n",
            "Epoch 381/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0344 - val_loss: 0.1240\n",
            "Epoch 382/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0294 - val_loss: 0.0973\n",
            "Epoch 383/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0295 - val_loss: 0.0968\n",
            "Epoch 384/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0289 - val_loss: 0.1070\n",
            "Epoch 385/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0297 - val_loss: 0.1060\n",
            "Epoch 386/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0290 - val_loss: 0.1006\n",
            "Epoch 387/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0278 - val_loss: 0.1055\n",
            "Epoch 388/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0314 - val_loss: 0.1027\n",
            "Epoch 389/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0289 - val_loss: 0.1089\n",
            "Epoch 390/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0303 - val_loss: 0.1088\n",
            "Epoch 391/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0335 - val_loss: 0.1007\n",
            "Epoch 392/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0301 - val_loss: 0.0927\n",
            "Epoch 393/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0302 - val_loss: 0.1030\n",
            "Epoch 394/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0299 - val_loss: 0.0968\n",
            "Epoch 395/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0317 - val_loss: 0.0978\n",
            "Epoch 396/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0312 - val_loss: 0.1170\n",
            "Epoch 397/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0282 - val_loss: 0.1153\n",
            "Epoch 398/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0309 - val_loss: 0.0966\n",
            "Epoch 399/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0284 - val_loss: 0.1049\n",
            "Epoch 400/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0312 - val_loss: 0.0855\n",
            "Epoch 401/1000\n",
            "79/79 [==============================] - 2s 27ms/step - loss: 0.0298 - val_loss: 0.0985\n",
            "Epoch 402/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0304 - val_loss: 0.1060\n",
            "Epoch 403/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0294 - val_loss: 0.1047\n",
            "Epoch 404/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0308 - val_loss: 0.0949\n",
            "Epoch 405/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0299 - val_loss: 0.1019\n",
            "Epoch 406/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0283 - val_loss: 0.0981\n",
            "Epoch 407/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0322 - val_loss: 0.1076\n",
            "Epoch 408/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0327 - val_loss: 0.1066\n",
            "Epoch 409/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0289 - val_loss: 0.1027\n",
            "Epoch 410/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0308 - val_loss: 0.1088\n",
            "Epoch 411/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0320 - val_loss: 0.1012\n",
            "Epoch 412/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0309 - val_loss: 0.0934\n",
            "Epoch 413/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0297 - val_loss: 0.0982\n",
            "Epoch 414/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0301 - val_loss: 0.0924\n",
            "Epoch 415/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0319 - val_loss: 0.1061\n",
            "Epoch 416/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0308 - val_loss: 0.1088\n",
            "Epoch 417/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0288 - val_loss: 0.1021\n",
            "Epoch 418/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0293 - val_loss: 0.0992\n",
            "Epoch 419/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0300 - val_loss: 0.1018\n",
            "Epoch 420/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0289 - val_loss: 0.0960\n",
            "Epoch 421/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0298 - val_loss: 0.1184\n",
            "Epoch 422/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0337 - val_loss: 0.1033\n",
            "Epoch 423/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0299 - val_loss: 0.1087\n",
            "Epoch 424/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0310 - val_loss: 0.0972\n",
            "Epoch 425/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0315 - val_loss: 0.0974\n",
            "Epoch 426/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0293 - val_loss: 0.0988\n",
            "Epoch 427/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0292 - val_loss: 0.1092\n",
            "Epoch 428/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0304 - val_loss: 0.0999\n",
            "Epoch 429/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0296 - val_loss: 0.1120\n",
            "Epoch 430/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0295 - val_loss: 0.1096\n",
            "Epoch 431/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0286 - val_loss: 0.1088\n",
            "Epoch 432/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0294 - val_loss: 0.1052\n",
            "Epoch 433/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0282 - val_loss: 0.0973\n",
            "Epoch 434/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0291 - val_loss: 0.0942\n",
            "Epoch 435/1000\n",
            "79/79 [==============================] - 2s 28ms/step - loss: 0.0292 - val_loss: 0.1044\n",
            "Epoch 436/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0315 - val_loss: 0.0970\n",
            "Epoch 437/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0296 - val_loss: 0.1056\n",
            "Epoch 438/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0284 - val_loss: 0.1043\n",
            "Epoch 439/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0303 - val_loss: 0.0929\n",
            "Epoch 440/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0302 - val_loss: 0.1055\n",
            "Epoch 441/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0280 - val_loss: 0.0894\n",
            "Epoch 442/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0291 - val_loss: 0.0985\n",
            "Epoch 443/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0300 - val_loss: 0.1082\n",
            "Epoch 444/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0295 - val_loss: 0.0992\n",
            "Epoch 445/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0281 - val_loss: 0.0981\n",
            "Epoch 446/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0304 - val_loss: 0.0926\n",
            "Epoch 447/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0299 - val_loss: 0.1006\n",
            "Epoch 448/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0296 - val_loss: 0.0913\n",
            "Epoch 449/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0305 - val_loss: 0.0930\n",
            "Epoch 450/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0302 - val_loss: 0.1076\n",
            "Epoch 451/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0296 - val_loss: 0.1002\n",
            "Epoch 452/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0276 - val_loss: 0.0992\n",
            "Epoch 453/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0294 - val_loss: 0.1078\n",
            "Epoch 454/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0316 - val_loss: 0.1096\n",
            "Epoch 455/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0292 - val_loss: 0.1055\n",
            "Epoch 456/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0314 - val_loss: 0.1002\n",
            "Epoch 457/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0293 - val_loss: 0.1090\n",
            "Epoch 458/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0315 - val_loss: 0.0977\n",
            "Epoch 459/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0283 - val_loss: 0.0998\n",
            "Epoch 460/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0295 - val_loss: 0.1042\n",
            "Epoch 461/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0275 - val_loss: 0.0912\n",
            "Epoch 462/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0282 - val_loss: 0.0972\n",
            "Epoch 463/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0293 - val_loss: 0.0896\n",
            "Epoch 464/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0312 - val_loss: 0.0980\n",
            "Epoch 465/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0291 - val_loss: 0.0919\n",
            "Epoch 466/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0298 - val_loss: 0.1047\n",
            "Epoch 467/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0302 - val_loss: 0.0988\n",
            "Epoch 468/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0298 - val_loss: 0.0982\n",
            "Epoch 469/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0286 - val_loss: 0.0945\n",
            "Epoch 470/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0268 - val_loss: 0.1013\n",
            "Epoch 471/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0292 - val_loss: 0.1045\n",
            "Epoch 472/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0287 - val_loss: 0.1105\n",
            "Epoch 473/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0294 - val_loss: 0.0912\n",
            "Epoch 474/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0319 - val_loss: 0.1143\n",
            "Epoch 475/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0311 - val_loss: 0.1019\n",
            "Epoch 476/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0291 - val_loss: 0.0942\n",
            "Epoch 477/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0279 - val_loss: 0.0899\n",
            "Epoch 478/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0301 - val_loss: 0.0959\n",
            "Epoch 479/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0302 - val_loss: 0.0971\n",
            "Epoch 480/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0275 - val_loss: 0.0986\n",
            "Epoch 481/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0312 - val_loss: 0.1077\n",
            "Epoch 482/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0300 - val_loss: 0.0962\n",
            "Epoch 483/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0280 - val_loss: 0.1009\n",
            "Epoch 484/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0296 - val_loss: 0.0905\n",
            "Epoch 485/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0279 - val_loss: 0.0882\n",
            "Epoch 486/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0288 - val_loss: 0.0915\n",
            "Epoch 487/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0289 - val_loss: 0.0907\n",
            "Epoch 488/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0273 - val_loss: 0.0857\n",
            "Epoch 489/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0318 - val_loss: 0.0857\n",
            "Epoch 490/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0308 - val_loss: 0.0846\n",
            "Epoch 491/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0274 - val_loss: 0.1034\n",
            "Epoch 492/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0285 - val_loss: 0.1075\n",
            "Epoch 493/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0302 - val_loss: 0.0980\n",
            "Epoch 494/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0288 - val_loss: 0.1024\n",
            "Epoch 495/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0290 - val_loss: 0.1161\n",
            "Epoch 496/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0331 - val_loss: 0.1039\n",
            "Epoch 497/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0273 - val_loss: 0.0957\n",
            "Epoch 498/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0280 - val_loss: 0.1079\n",
            "Epoch 499/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0293 - val_loss: 0.1011\n",
            "Epoch 500/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0271 - val_loss: 0.1019\n",
            "Epoch 501/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0285 - val_loss: 0.1007\n",
            "Epoch 502/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0288 - val_loss: 0.0939\n",
            "Epoch 503/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0286 - val_loss: 0.0941\n",
            "Epoch 504/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0295 - val_loss: 0.1015\n",
            "Epoch 505/1000\n",
            "79/79 [==============================] - 2s 29ms/step - loss: 0.0285 - val_loss: 0.0959\n",
            "Epoch 506/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0292 - val_loss: 0.0965\n",
            "Epoch 507/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0282 - val_loss: 0.1028\n",
            "Epoch 508/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0326 - val_loss: 0.0931\n",
            "Epoch 509/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0286 - val_loss: 0.0845\n",
            "Epoch 510/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0283 - val_loss: 0.0887\n",
            "Epoch 511/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0282 - val_loss: 0.0806\n",
            "Epoch 512/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0306 - val_loss: 0.0977\n",
            "Epoch 513/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0289 - val_loss: 0.0920\n",
            "Epoch 514/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0282 - val_loss: 0.1042\n",
            "Epoch 515/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0320 - val_loss: 0.0865\n",
            "Epoch 516/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0282 - val_loss: 0.0864\n",
            "Epoch 517/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0286 - val_loss: 0.0806\n",
            "Epoch 518/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0274 - val_loss: 0.0939\n",
            "Epoch 519/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0266 - val_loss: 0.0922\n",
            "Epoch 520/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0266 - val_loss: 0.1023\n",
            "Epoch 521/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0261 - val_loss: 0.0960\n",
            "Epoch 522/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0287 - val_loss: 0.1011\n",
            "Epoch 523/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0278 - val_loss: 0.0964\n",
            "Epoch 524/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0287 - val_loss: 0.0921\n",
            "Epoch 525/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0295 - val_loss: 0.0990\n",
            "Epoch 526/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0291 - val_loss: 0.0996\n",
            "Epoch 527/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0291 - val_loss: 0.0921\n",
            "Epoch 528/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0297 - val_loss: 0.1013\n",
            "Epoch 529/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0285 - val_loss: 0.0975\n",
            "Epoch 530/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0269 - val_loss: 0.0869\n",
            "Epoch 531/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0294 - val_loss: 0.0865\n",
            "Epoch 532/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0283 - val_loss: 0.0991\n",
            "Epoch 533/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0277 - val_loss: 0.0989\n",
            "Epoch 534/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0290 - val_loss: 0.0927\n",
            "Epoch 535/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0297 - val_loss: 0.1048\n",
            "Epoch 536/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0278 - val_loss: 0.0862\n",
            "Epoch 537/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0280 - val_loss: 0.0872\n",
            "Epoch 538/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0259 - val_loss: 0.0949\n",
            "Epoch 539/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0277 - val_loss: 0.0912\n",
            "Epoch 540/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0274 - val_loss: 0.0978\n",
            "Epoch 541/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0286 - val_loss: 0.0943\n",
            "Epoch 542/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0273 - val_loss: 0.0977\n",
            "Epoch 543/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0255 - val_loss: 0.0937\n",
            "Epoch 544/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0277 - val_loss: 0.0997\n",
            "Epoch 545/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0262 - val_loss: 0.0855\n",
            "Epoch 546/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0263 - val_loss: 0.0964\n",
            "Epoch 547/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0275 - val_loss: 0.0839\n",
            "Epoch 548/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0283 - val_loss: 0.0956\n",
            "Epoch 549/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0261 - val_loss: 0.0877\n",
            "Epoch 550/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0259 - val_loss: 0.0946\n",
            "Epoch 551/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0268 - val_loss: 0.0809\n",
            "Epoch 552/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0269 - val_loss: 0.0866\n",
            "Epoch 553/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0274 - val_loss: 0.0918\n",
            "Epoch 554/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0266 - val_loss: 0.0937\n",
            "Epoch 555/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0272 - val_loss: 0.0966\n",
            "Epoch 556/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0266 - val_loss: 0.0998\n",
            "Epoch 557/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0285 - val_loss: 0.0962\n",
            "Epoch 558/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0276 - val_loss: 0.1075\n",
            "Epoch 559/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0274 - val_loss: 0.0862\n",
            "Epoch 560/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0264 - val_loss: 0.0933\n",
            "Epoch 561/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0249 - val_loss: 0.0939\n",
            "Epoch 562/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0257 - val_loss: 0.1017\n",
            "Epoch 563/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0263 - val_loss: 0.0865\n",
            "Epoch 564/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0279 - val_loss: 0.0905\n",
            "Epoch 565/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0254 - val_loss: 0.0956\n",
            "Epoch 566/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0265 - val_loss: 0.0903\n",
            "Epoch 567/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0282 - val_loss: 0.0926\n",
            "Epoch 568/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0279 - val_loss: 0.0971\n",
            "Epoch 569/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0257 - val_loss: 0.1003\n",
            "Epoch 570/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0261 - val_loss: 0.0931\n",
            "Epoch 571/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0265 - val_loss: 0.0890\n",
            "Epoch 572/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0270 - val_loss: 0.0880\n",
            "Epoch 573/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0269 - val_loss: 0.0970\n",
            "Epoch 574/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0263 - val_loss: 0.0891\n",
            "Epoch 575/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0257 - val_loss: 0.0902\n",
            "Epoch 576/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0259 - val_loss: 0.0916\n",
            "Epoch 577/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0258 - val_loss: 0.0843\n",
            "Epoch 578/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0253 - val_loss: 0.0894\n",
            "Epoch 579/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0268 - val_loss: 0.0912\n",
            "Epoch 580/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0250 - val_loss: 0.0880\n",
            "Epoch 581/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0256 - val_loss: 0.0915\n",
            "Epoch 582/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0261 - val_loss: 0.0917\n",
            "Epoch 583/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0257 - val_loss: 0.0907\n",
            "Epoch 584/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0251 - val_loss: 0.0869\n",
            "Epoch 585/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0261 - val_loss: 0.0958\n",
            "Epoch 586/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0242 - val_loss: 0.0892\n",
            "Epoch 587/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0259 - val_loss: 0.0968\n",
            "Epoch 588/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0247 - val_loss: 0.0968\n",
            "Epoch 589/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0276 - val_loss: 0.1049\n",
            "Epoch 590/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0258 - val_loss: 0.0938\n",
            "Epoch 591/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0271 - val_loss: 0.1024\n",
            "Epoch 592/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0257 - val_loss: 0.0990\n",
            "Epoch 593/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0252 - val_loss: 0.0862\n",
            "Epoch 594/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0269 - val_loss: 0.0831\n",
            "Epoch 595/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0253 - val_loss: 0.0875\n",
            "Epoch 596/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0257 - val_loss: 0.0923\n",
            "Epoch 597/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0263 - val_loss: 0.0960\n",
            "Epoch 598/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0257 - val_loss: 0.0826\n",
            "Epoch 599/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0259 - val_loss: 0.0920\n",
            "Epoch 600/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0258 - val_loss: 0.0993\n",
            "Epoch 601/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0262 - val_loss: 0.0987\n",
            "Epoch 602/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0275 - val_loss: 0.0948\n",
            "Epoch 603/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0270 - val_loss: 0.0893\n",
            "Epoch 604/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0254 - val_loss: 0.0838\n",
            "Epoch 605/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0265 - val_loss: 0.0836\n",
            "Epoch 606/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0261 - val_loss: 0.0864\n",
            "Epoch 607/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0248 - val_loss: 0.0885\n",
            "Epoch 608/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0251 - val_loss: 0.0932\n",
            "Epoch 609/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0259 - val_loss: 0.0951\n",
            "Epoch 610/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0259 - val_loss: 0.0815\n",
            "Epoch 611/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0249 - val_loss: 0.0911\n",
            "Epoch 612/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0268 - val_loss: 0.0888\n",
            "Epoch 613/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0249 - val_loss: 0.0915\n",
            "Epoch 614/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0261 - val_loss: 0.0850\n",
            "Epoch 615/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0267 - val_loss: 0.0875\n",
            "Epoch 616/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0261 - val_loss: 0.0914\n",
            "Epoch 617/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0260 - val_loss: 0.0929\n",
            "Epoch 618/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0251 - val_loss: 0.0779\n",
            "Epoch 619/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0269 - val_loss: 0.0882\n",
            "Epoch 620/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0253 - val_loss: 0.0863\n",
            "Epoch 621/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0271 - val_loss: 0.0822\n",
            "Epoch 622/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0266 - val_loss: 0.0886\n",
            "Epoch 623/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0237 - val_loss: 0.0940\n",
            "Epoch 624/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0234 - val_loss: 0.0819\n",
            "Epoch 625/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0255 - val_loss: 0.0830\n",
            "Epoch 626/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0252 - val_loss: 0.0918\n",
            "Epoch 627/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0249 - val_loss: 0.0963\n",
            "Epoch 628/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0263 - val_loss: 0.0952\n",
            "Epoch 629/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0256 - val_loss: 0.0888\n",
            "Epoch 630/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0265 - val_loss: 0.0803\n",
            "Epoch 631/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0259 - val_loss: 0.0949\n",
            "Epoch 632/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0272 - val_loss: 0.0935\n",
            "Epoch 633/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0245 - val_loss: 0.0832\n",
            "Epoch 634/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0237 - val_loss: 0.0906\n",
            "Epoch 635/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0262 - val_loss: 0.0912\n",
            "Epoch 636/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0259 - val_loss: 0.0914\n",
            "Epoch 637/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0237 - val_loss: 0.0865\n",
            "Epoch 638/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0243 - val_loss: 0.0861\n",
            "Epoch 639/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0253 - val_loss: 0.0966\n",
            "Epoch 640/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0240 - val_loss: 0.0878\n",
            "Epoch 641/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0256 - val_loss: 0.0922\n",
            "Epoch 642/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0274 - val_loss: 0.0894\n",
            "Epoch 643/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0257 - val_loss: 0.1000\n",
            "Epoch 644/1000\n",
            "79/79 [==============================] - 2s 28ms/step - loss: 0.0263 - val_loss: 0.0830\n",
            "Epoch 645/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0267 - val_loss: 0.0825\n",
            "Epoch 646/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0241 - val_loss: 0.0872\n",
            "Epoch 647/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0288 - val_loss: 0.0980\n",
            "Epoch 648/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0261 - val_loss: 0.0844\n",
            "Epoch 649/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0249 - val_loss: 0.0813\n",
            "Epoch 650/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0257 - val_loss: 0.0974\n",
            "Epoch 651/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0271 - val_loss: 0.0908\n",
            "Epoch 652/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0244 - val_loss: 0.0918\n",
            "Epoch 653/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0239 - val_loss: 0.0898\n",
            "Epoch 654/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0257 - val_loss: 0.0999\n",
            "Epoch 655/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0250 - val_loss: 0.0859\n",
            "Epoch 656/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0238 - val_loss: 0.0853\n",
            "Epoch 657/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0262 - val_loss: 0.0970\n",
            "Epoch 658/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0252 - val_loss: 0.0911\n",
            "Epoch 659/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0262 - val_loss: 0.0946\n",
            "Epoch 660/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0262 - val_loss: 0.0912\n",
            "Epoch 661/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0243 - val_loss: 0.0860\n",
            "Epoch 662/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0252 - val_loss: 0.0913\n",
            "Epoch 663/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0246 - val_loss: 0.0954\n",
            "Epoch 664/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0255 - val_loss: 0.0910\n",
            "Epoch 665/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0283 - val_loss: 0.0812\n",
            "Epoch 666/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0263 - val_loss: 0.0848\n",
            "Epoch 667/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0235 - val_loss: 0.0821\n",
            "Epoch 668/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0254 - val_loss: 0.0851\n",
            "Epoch 669/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0253 - val_loss: 0.0871\n",
            "Epoch 670/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0248 - val_loss: 0.0867\n",
            "Epoch 671/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0238 - val_loss: 0.0941\n",
            "Epoch 672/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0256 - val_loss: 0.0841\n",
            "Epoch 673/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0248 - val_loss: 0.0803\n",
            "Epoch 674/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0240 - val_loss: 0.0857\n",
            "Epoch 675/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0249 - val_loss: 0.0863\n",
            "Epoch 676/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0239 - val_loss: 0.0874\n",
            "Epoch 677/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0238 - val_loss: 0.0890\n",
            "Epoch 678/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0249 - val_loss: 0.0851\n",
            "Epoch 679/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0241 - val_loss: 0.0842\n",
            "Epoch 680/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0254 - val_loss: 0.0797\n",
            "Epoch 681/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0271 - val_loss: 0.0881\n",
            "Epoch 682/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0234 - val_loss: 0.0847\n",
            "Epoch 683/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0249 - val_loss: 0.0775\n",
            "Epoch 684/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0281 - val_loss: 0.0834\n",
            "Epoch 685/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0233 - val_loss: 0.0880\n",
            "Epoch 686/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0255 - val_loss: 0.0845\n",
            "Epoch 687/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0237 - val_loss: 0.0758\n",
            "Epoch 688/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0268 - val_loss: 0.0866\n",
            "Epoch 689/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0266 - val_loss: 0.0827\n",
            "Epoch 690/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0243 - val_loss: 0.0838\n",
            "Epoch 691/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0244 - val_loss: 0.0904\n",
            "Epoch 692/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0255 - val_loss: 0.0938\n",
            "Epoch 693/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0247 - val_loss: 0.0881\n",
            "Epoch 694/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0232 - val_loss: 0.0821\n",
            "Epoch 695/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0249 - val_loss: 0.0803\n",
            "Epoch 696/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0243 - val_loss: 0.0808\n",
            "Epoch 697/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0241 - val_loss: 0.0793\n",
            "Epoch 698/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0245 - val_loss: 0.0834\n",
            "Epoch 699/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0284 - val_loss: 0.0979\n",
            "Epoch 700/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0236 - val_loss: 0.0868\n",
            "Epoch 701/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0253 - val_loss: 0.0864\n",
            "Epoch 702/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0254 - val_loss: 0.0912\n",
            "Epoch 703/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0242 - val_loss: 0.0818\n",
            "Epoch 704/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0252 - val_loss: 0.0794\n",
            "Epoch 705/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0247 - val_loss: 0.0803\n",
            "Epoch 706/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0238 - val_loss: 0.0975\n",
            "Epoch 707/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0250 - val_loss: 0.0824\n",
            "Epoch 708/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0235 - val_loss: 0.0778\n",
            "Epoch 709/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0240 - val_loss: 0.0838\n",
            "Epoch 710/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0240 - val_loss: 0.0902\n",
            "Epoch 711/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0245 - val_loss: 0.0821\n",
            "Epoch 712/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0251 - val_loss: 0.0812\n",
            "Epoch 713/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0246 - val_loss: 0.0824\n",
            "Epoch 714/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0235 - val_loss: 0.0759\n",
            "Epoch 715/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0232 - val_loss: 0.0897\n",
            "Epoch 716/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0227 - val_loss: 0.0772\n",
            "Epoch 717/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0233 - val_loss: 0.0785\n",
            "Epoch 718/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0249 - val_loss: 0.0862\n",
            "Epoch 719/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0232 - val_loss: 0.0800\n",
            "Epoch 720/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0242 - val_loss: 0.0802\n",
            "Epoch 721/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0247 - val_loss: 0.0898\n",
            "Epoch 722/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0257 - val_loss: 0.0790\n",
            "Epoch 723/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0234 - val_loss: 0.0822\n",
            "Epoch 724/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0229 - val_loss: 0.0828\n",
            "Epoch 725/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0257 - val_loss: 0.0869\n",
            "Epoch 726/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0260 - val_loss: 0.0789\n",
            "Epoch 727/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0242 - val_loss: 0.0764\n",
            "Epoch 728/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0239 - val_loss: 0.0793\n",
            "Epoch 729/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0229 - val_loss: 0.0795\n",
            "Epoch 730/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0244 - val_loss: 0.0786\n",
            "Epoch 731/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0261 - val_loss: 0.0769\n",
            "Epoch 732/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0235 - val_loss: 0.0847\n",
            "Epoch 733/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0247 - val_loss: 0.0765\n",
            "Epoch 734/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0230 - val_loss: 0.0871\n",
            "Epoch 735/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0254 - val_loss: 0.0810\n",
            "Epoch 736/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0228 - val_loss: 0.0760\n",
            "Epoch 737/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0244 - val_loss: 0.0798\n",
            "Epoch 738/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0244 - val_loss: 0.0789\n",
            "Epoch 739/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0242 - val_loss: 0.0869\n",
            "Epoch 740/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0252 - val_loss: 0.0805\n",
            "Epoch 741/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0234 - val_loss: 0.0802\n",
            "Epoch 742/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0251 - val_loss: 0.0818\n",
            "Epoch 743/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0216 - val_loss: 0.0781\n",
            "Epoch 744/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0230 - val_loss: 0.0898\n",
            "Epoch 745/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0223 - val_loss: 0.0786\n",
            "Epoch 746/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0234 - val_loss: 0.0806\n",
            "Epoch 747/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0239 - val_loss: 0.0762\n",
            "Epoch 748/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0232 - val_loss: 0.0797\n",
            "Epoch 749/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0228 - val_loss: 0.0837\n",
            "Epoch 750/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0242 - val_loss: 0.0753\n",
            "Epoch 751/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0238 - val_loss: 0.0802\n",
            "Epoch 752/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0238 - val_loss: 0.0823\n",
            "Epoch 753/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0226 - val_loss: 0.0783\n",
            "Epoch 754/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0231 - val_loss: 0.0865\n",
            "Epoch 755/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0222 - val_loss: 0.0812\n",
            "Epoch 756/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0228 - val_loss: 0.0841\n",
            "Epoch 757/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0235 - val_loss: 0.0777\n",
            "Epoch 758/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0233 - val_loss: 0.0765\n",
            "Epoch 759/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0238 - val_loss: 0.0764\n",
            "Epoch 760/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0229 - val_loss: 0.0809\n",
            "Epoch 761/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0224 - val_loss: 0.0770\n",
            "Epoch 762/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0237 - val_loss: 0.0800\n",
            "Epoch 763/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0256 - val_loss: 0.0762\n",
            "Epoch 764/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0218 - val_loss: 0.0819\n",
            "Epoch 765/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0221 - val_loss: 0.0754\n",
            "Epoch 766/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0250 - val_loss: 0.0746\n",
            "Epoch 767/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0225 - val_loss: 0.0771\n",
            "Epoch 768/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0224 - val_loss: 0.0838\n",
            "Epoch 769/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0230 - val_loss: 0.0780\n",
            "Epoch 770/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0245 - val_loss: 0.0761\n",
            "Epoch 771/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0233 - val_loss: 0.0780\n",
            "Epoch 772/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0233 - val_loss: 0.0795\n",
            "Epoch 773/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0227 - val_loss: 0.0784\n",
            "Epoch 774/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0252 - val_loss: 0.0856\n",
            "Epoch 775/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0248 - val_loss: 0.0787\n",
            "Epoch 776/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0229 - val_loss: 0.0785\n",
            "Epoch 777/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0231 - val_loss: 0.0759\n",
            "Epoch 778/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0228 - val_loss: 0.0810\n",
            "Epoch 779/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0238 - val_loss: 0.0803\n",
            "Epoch 780/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0248 - val_loss: 0.0761\n",
            "Epoch 781/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0221 - val_loss: 0.0834\n",
            "Epoch 782/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0248 - val_loss: 0.0884\n",
            "Epoch 783/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0229 - val_loss: 0.0791\n",
            "Epoch 784/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0224 - val_loss: 0.0790\n",
            "Epoch 785/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0225 - val_loss: 0.0772\n",
            "Epoch 786/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0217 - val_loss: 0.0834\n",
            "Epoch 787/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0220 - val_loss: 0.0779\n",
            "Epoch 788/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0237 - val_loss: 0.0817\n",
            "Epoch 789/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0239 - val_loss: 0.0791\n",
            "Epoch 790/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0220 - val_loss: 0.0758\n",
            "Epoch 791/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0224 - val_loss: 0.0817\n",
            "Epoch 792/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0229 - val_loss: 0.0817\n",
            "Epoch 793/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0222 - val_loss: 0.0774\n",
            "Epoch 794/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0236 - val_loss: 0.0814\n",
            "Epoch 795/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0219 - val_loss: 0.0756\n",
            "Epoch 796/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0224 - val_loss: 0.0788\n",
            "Epoch 797/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0229 - val_loss: 0.0738\n",
            "Epoch 798/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0237 - val_loss: 0.0736\n",
            "Epoch 799/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0256 - val_loss: 0.0743\n",
            "Epoch 800/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0236 - val_loss: 0.0780\n",
            "Epoch 801/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0227 - val_loss: 0.0805\n",
            "Epoch 802/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0240 - val_loss: 0.0807\n",
            "Epoch 803/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0239 - val_loss: 0.0799\n",
            "Epoch 804/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0232 - val_loss: 0.0764\n",
            "Epoch 805/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0232 - val_loss: 0.0774\n",
            "Epoch 806/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0220 - val_loss: 0.0770\n",
            "Epoch 807/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0225 - val_loss: 0.0756\n",
            "Epoch 808/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0221 - val_loss: 0.0766\n",
            "Epoch 809/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0248 - val_loss: 0.0765\n",
            "Epoch 810/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0222 - val_loss: 0.0759\n",
            "Epoch 811/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0234 - val_loss: 0.0766\n",
            "Epoch 812/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0242 - val_loss: 0.0792\n",
            "Epoch 813/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0226 - val_loss: 0.0761\n",
            "Epoch 814/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0228 - val_loss: 0.0775\n",
            "Epoch 815/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0228 - val_loss: 0.0807\n",
            "Epoch 816/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0232 - val_loss: 0.0765\n",
            "Epoch 817/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0226 - val_loss: 0.0810\n",
            "Epoch 818/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0226 - val_loss: 0.0808\n",
            "Epoch 819/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0209 - val_loss: 0.0753\n",
            "Epoch 820/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0227 - val_loss: 0.0782\n",
            "Epoch 821/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0259 - val_loss: 0.0758\n",
            "Epoch 822/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0226 - val_loss: 0.0803\n",
            "Epoch 823/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0218 - val_loss: 0.0762\n",
            "Epoch 824/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0239 - val_loss: 0.0755\n",
            "Epoch 825/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0226 - val_loss: 0.0766\n",
            "Epoch 826/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0223 - val_loss: 0.0762\n",
            "Epoch 827/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0218 - val_loss: 0.0749\n",
            "Epoch 828/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0230 - val_loss: 0.0760\n",
            "Epoch 829/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0238 - val_loss: 0.0756\n",
            "Epoch 830/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0207 - val_loss: 0.0791\n",
            "Epoch 831/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0235 - val_loss: 0.0769\n",
            "Epoch 832/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0226 - val_loss: 0.0765\n",
            "Epoch 833/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0215 - val_loss: 0.0769\n",
            "Epoch 834/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0221 - val_loss: 0.0738\n",
            "Epoch 835/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0225 - val_loss: 0.0755\n",
            "Epoch 836/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0224 - val_loss: 0.0792\n",
            "Epoch 837/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0228 - val_loss: 0.0771\n",
            "Epoch 838/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0233 - val_loss: 0.0794\n",
            "Epoch 839/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0215 - val_loss: 0.0741\n",
            "Epoch 840/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0234 - val_loss: 0.0763\n",
            "Epoch 841/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0225 - val_loss: 0.0762\n",
            "Epoch 842/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0220 - val_loss: 0.0786\n",
            "Epoch 843/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0238 - val_loss: 0.0789\n",
            "Epoch 844/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0220 - val_loss: 0.0768\n",
            "Epoch 845/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0226 - val_loss: 0.0765\n",
            "Epoch 846/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0219 - val_loss: 0.0773\n",
            "Epoch 847/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0220 - val_loss: 0.0765\n",
            "Epoch 848/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0211 - val_loss: 0.0752\n",
            "Epoch 849/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0244 - val_loss: 0.0775\n",
            "Epoch 850/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0240 - val_loss: 0.0762\n",
            "Epoch 851/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0214 - val_loss: 0.0781\n",
            "Epoch 852/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0230 - val_loss: 0.0764\n",
            "Epoch 853/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0211 - val_loss: 0.0794\n",
            "Epoch 854/1000\n",
            "79/79 [==============================] - 2s 28ms/step - loss: 0.0231 - val_loss: 0.0731\n",
            "Epoch 855/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0219 - val_loss: 0.0764\n",
            "Epoch 856/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0213 - val_loss: 0.0760\n",
            "Epoch 857/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0215 - val_loss: 0.0772\n",
            "Epoch 858/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0225 - val_loss: 0.0763\n",
            "Epoch 859/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0226 - val_loss: 0.0752\n",
            "Epoch 860/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0229 - val_loss: 0.0766\n",
            "Epoch 861/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0223 - val_loss: 0.0757\n",
            "Epoch 862/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0219 - val_loss: 0.0761\n",
            "Epoch 863/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0216 - val_loss: 0.0799\n",
            "Epoch 864/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0251 - val_loss: 0.0790\n",
            "Epoch 865/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0215 - val_loss: 0.0769\n",
            "Epoch 866/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0209 - val_loss: 0.0763\n",
            "Epoch 867/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0205 - val_loss: 0.0763\n",
            "Epoch 868/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0213 - val_loss: 0.0778\n",
            "Epoch 869/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0226 - val_loss: 0.0764\n",
            "Epoch 870/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0219 - val_loss: 0.0756\n",
            "Epoch 871/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0226 - val_loss: 0.0770\n",
            "Epoch 872/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0217 - val_loss: 0.0743\n",
            "Epoch 873/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0226 - val_loss: 0.0765\n",
            "Epoch 874/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0213 - val_loss: 0.0757\n",
            "Epoch 875/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0222 - val_loss: 0.0744\n",
            "Epoch 876/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0210 - val_loss: 0.0754\n",
            "Epoch 877/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0210 - val_loss: 0.0774\n",
            "Epoch 878/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0205 - val_loss: 0.0763\n",
            "Epoch 879/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0212 - val_loss: 0.0758\n",
            "Epoch 880/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0219 - val_loss: 0.0767\n",
            "Epoch 881/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0212 - val_loss: 0.0756\n",
            "Epoch 882/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0218 - val_loss: 0.0763\n",
            "Epoch 883/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0226 - val_loss: 0.0787\n",
            "Epoch 884/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0209 - val_loss: 0.0765\n",
            "Epoch 885/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0230 - val_loss: 0.0791\n",
            "Epoch 886/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0224 - val_loss: 0.0774\n",
            "Epoch 887/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0209 - val_loss: 0.0751\n",
            "Epoch 888/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0217 - val_loss: 0.0751\n",
            "Epoch 889/1000\n",
            "79/79 [==============================] - 2s 28ms/step - loss: 0.0209 - val_loss: 0.0742\n",
            "Epoch 890/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0223 - val_loss: 0.0740\n",
            "Epoch 891/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0223 - val_loss: 0.0754\n",
            "Epoch 892/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0215 - val_loss: 0.0740\n",
            "Epoch 893/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0224 - val_loss: 0.0787\n",
            "Epoch 894/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0219 - val_loss: 0.0771\n",
            "Epoch 895/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0220 - val_loss: 0.0803\n",
            "Epoch 896/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0217 - val_loss: 0.0765\n",
            "Epoch 897/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0203 - val_loss: 0.0760\n",
            "Epoch 898/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0217 - val_loss: 0.0770\n",
            "Epoch 899/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0204 - val_loss: 0.0757\n",
            "Epoch 900/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0213 - val_loss: 0.0748\n",
            "Epoch 901/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0219 - val_loss: 0.0752\n",
            "Epoch 902/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0212 - val_loss: 0.0748\n",
            "Epoch 903/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0210 - val_loss: 0.0749\n",
            "Epoch 904/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0215 - val_loss: 0.0754\n",
            "Epoch 905/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0217 - val_loss: 0.0749\n",
            "Epoch 906/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0267 - val_loss: 0.0745\n",
            "Epoch 907/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0215 - val_loss: 0.0744\n",
            "Epoch 908/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0207 - val_loss: 0.0760\n",
            "Epoch 909/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0213 - val_loss: 0.0757\n",
            "Epoch 910/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0212 - val_loss: 0.0743\n",
            "Epoch 911/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0222 - val_loss: 0.0740\n",
            "Epoch 912/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0200 - val_loss: 0.0750\n",
            "Epoch 913/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0218 - val_loss: 0.0772\n",
            "Epoch 914/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0227 - val_loss: 0.0745\n",
            "Epoch 915/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0223 - val_loss: 0.0743\n",
            "Epoch 916/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0213 - val_loss: 0.0750\n",
            "Epoch 917/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0205 - val_loss: 0.0746\n",
            "Epoch 918/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0190 - val_loss: 0.0754\n",
            "Epoch 919/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0216 - val_loss: 0.0740\n",
            "Epoch 920/1000\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0200 - val_loss: 0.0727\n",
            "Epoch 921/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0221 - val_loss: 0.0752\n",
            "Epoch 922/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0198 - val_loss: 0.0731\n",
            "Epoch 923/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0204 - val_loss: 0.0756\n",
            "Epoch 924/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0210 - val_loss: 0.0736\n",
            "Epoch 925/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0203 - val_loss: 0.0751\n",
            "Epoch 926/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0214 - val_loss: 0.0752\n",
            "Epoch 927/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0204 - val_loss: 0.0752\n",
            "Epoch 928/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0201 - val_loss: 0.0749\n",
            "Epoch 929/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0212 - val_loss: 0.0758\n",
            "Epoch 930/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0211 - val_loss: 0.0747\n",
            "Epoch 931/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0224 - val_loss: 0.0741\n",
            "Epoch 932/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0215 - val_loss: 0.0755\n",
            "Epoch 933/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0203 - val_loss: 0.0756\n",
            "Epoch 934/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0217 - val_loss: 0.0736\n",
            "Epoch 935/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0197 - val_loss: 0.0725\n",
            "Epoch 936/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0209 - val_loss: 0.0747\n",
            "Epoch 937/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0214 - val_loss: 0.0752\n",
            "Epoch 938/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0212 - val_loss: 0.0738\n",
            "Epoch 939/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0222 - val_loss: 0.0728\n",
            "Epoch 940/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0204 - val_loss: 0.0742\n",
            "Epoch 941/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0218 - val_loss: 0.0739\n",
            "Epoch 942/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0215 - val_loss: 0.0746\n",
            "Epoch 943/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0203 - val_loss: 0.0731\n",
            "Epoch 944/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0206 - val_loss: 0.0751\n",
            "Epoch 945/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0222 - val_loss: 0.0738\n",
            "Epoch 946/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0197 - val_loss: 0.0767\n",
            "Epoch 947/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0220 - val_loss: 0.0733\n",
            "Epoch 948/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0207 - val_loss: 0.0729\n",
            "Epoch 949/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0213 - val_loss: 0.0738\n",
            "Epoch 950/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0200 - val_loss: 0.0740\n",
            "Epoch 951/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0203 - val_loss: 0.0745\n",
            "Epoch 952/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0202 - val_loss: 0.0738\n",
            "Epoch 953/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0204 - val_loss: 0.0750\n",
            "Epoch 954/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0199 - val_loss: 0.0747\n",
            "Epoch 955/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0209 - val_loss: 0.0752\n",
            "Epoch 956/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0208 - val_loss: 0.0737\n",
            "Epoch 957/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0191 - val_loss: 0.0727\n",
            "Epoch 958/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0208 - val_loss: 0.0747\n",
            "Epoch 959/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0214 - val_loss: 0.0750\n",
            "Epoch 960/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0215 - val_loss: 0.0745\n",
            "Epoch 961/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0232 - val_loss: 0.0769\n",
            "Epoch 962/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0232 - val_loss: 0.0753\n",
            "Epoch 963/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0202 - val_loss: 0.0754\n",
            "Epoch 964/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0203 - val_loss: 0.0747\n",
            "Epoch 965/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0212 - val_loss: 0.0757\n",
            "Epoch 966/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0208 - val_loss: 0.0786\n",
            "Epoch 967/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0224 - val_loss: 0.0760\n",
            "Epoch 968/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0205 - val_loss: 0.0751\n",
            "Epoch 969/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0204 - val_loss: 0.0727\n",
            "Epoch 970/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0212 - val_loss: 0.0745\n",
            "Epoch 971/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0203 - val_loss: 0.0749\n",
            "Epoch 972/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0206 - val_loss: 0.0744\n",
            "Epoch 973/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0200 - val_loss: 0.0737\n",
            "Epoch 974/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0221 - val_loss: 0.0745\n",
            "Epoch 975/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0207 - val_loss: 0.0739\n",
            "Epoch 976/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0220 - val_loss: 0.0741\n",
            "Epoch 977/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0205 - val_loss: 0.0740\n",
            "Epoch 978/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0196 - val_loss: 0.0747\n",
            "Epoch 979/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0209 - val_loss: 0.0737\n",
            "Epoch 980/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0213 - val_loss: 0.0748\n",
            "Epoch 981/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0198 - val_loss: 0.0747\n",
            "Epoch 982/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0202 - val_loss: 0.0748\n",
            "Epoch 983/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0211 - val_loss: 0.0728\n",
            "Epoch 984/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0219 - val_loss: 0.0748\n",
            "Epoch 985/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0197 - val_loss: 0.0736\n",
            "Epoch 986/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0211 - val_loss: 0.0743\n",
            "Epoch 987/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0205 - val_loss: 0.0743\n",
            "Epoch 988/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0217 - val_loss: 0.0734\n",
            "Epoch 989/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0212 - val_loss: 0.0746\n",
            "Epoch 990/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0212 - val_loss: 0.0741\n",
            "Epoch 991/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0209 - val_loss: 0.0733\n",
            "Epoch 992/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0226 - val_loss: 0.0726\n",
            "Epoch 993/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0215 - val_loss: 0.0748\n",
            "Epoch 994/1000\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0228 - val_loss: 0.0736\n",
            "Epoch 995/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0190 - val_loss: 0.0755\n",
            "Epoch 996/1000\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0212 - val_loss: 0.0734\n",
            "Epoch 997/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0217 - val_loss: 0.0750\n",
            "Epoch 998/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0220 - val_loss: 0.0742\n",
            "Epoch 999/1000\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.0209 - val_loss: 0.0732\n",
            "Epoch 1000/1000\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0225 - val_loss: 0.0739\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc432614ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ1TAS_MvqDH",
        "colab_type": "text"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsAWnOs9OJpB",
        "colab_type": "code",
        "outputId": "86f72fd1-3b01-494c-d6bc-6921fe127636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/ml-class/videos/text-gen"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ml-class/videos/text-gen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20ok_uvnOgIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnY9mNnaPKB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"text\", type=str)\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "run = wandb.init()\n",
        "config = run.config\n",
        "config.hidden_nodes = 128\n",
        "config.batch_size = 256\n",
        "config.file = args.text\n",
        "config.maxlen = 200\n",
        "config.step = 3\n",
        "\n",
        "text = io.open(config.file, encoding='utf-8').read()\n",
        "chars = sorted(list(set(text)))\n",
        "\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# build a sequence for every <config.step>-th character in the text\n",
        "\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - config.maxlen, config.step):\n",
        "    sentences.append(text[i: i + config.maxlen])\n",
        "    next_chars.append(text[i + config.maxlen])\n",
        "\n",
        "# build up one-hot encoded input x and output y where x is a character\n",
        "# in the text y is the next character in the text\n",
        "\n",
        "x = np.zeros((len(sentences), config.maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(128, input_shape=(config.maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\")\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "class SampleText(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        start_index = random.randint(0, len(text) - config.maxlen - 1)\n",
        "\n",
        "        for diversity in [0.5, 1.2]:\n",
        "            print()\n",
        "            print('----- diversity:', diversity)\n",
        "\n",
        "            generated = ''\n",
        "            sentence = text[start_index: start_index + config.maxlen]\n",
        "            generated += sentence\n",
        "            print('----- Generating with seed: \"' + sentence + '\"')\n",
        "            sys.stdout.write(generated)\n",
        "\n",
        "            for i in range(200):\n",
        "                x_pred = np.zeros((1, config.maxlen, len(chars)))\n",
        "                for t, char in enumerate(sentence):\n",
        "                    x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "                preds = model.predict(x_pred, verbose=0)[0]\n",
        "                next_index = sample(preds, diversity)\n",
        "                next_char = indices_char[next_index]\n",
        "\n",
        "                generated += next_char\n",
        "                sentence = sentence[1:] + next_char\n",
        "\n",
        "                sys.stdout.write(next_char)\n",
        "                sys.stdout.flush()\n",
        "            print()\n",
        "            \n",
        "model.fit(x, y, batch_size=config.batch_size,\n",
        "              epochs=100, callbacks=[SampleText(), WandbCallback()])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71334mWgQdWi",
        "colab_type": "code",
        "outputId": "6428698a-70cb-4664-c6ff-9edec1228480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "! python char-gen.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "usage: char-gen.py [-h] text\n",
            "char-gen.py: error: the following arguments are required: text\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}